{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-02T03:14:26.145668600Z",
     "start_time": "2023-11-02T03:14:19.021236500Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, InputLayer\n",
    "import statistics\n",
    "from statistics import mode\n",
    "import random\n",
    "import os\n",
    "\n",
    "import math\n",
    "\n",
    "import pylab as p\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import string\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read and process data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculate the power and put it in a dataframe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def concatenate_files_in_folders(base_path, folder_prefix):\n",
    "    # Initialize an empty list to store file location paths\n",
    "    sources = list()\n",
    "    \n",
    "    def recursive_search(base_path):\n",
    "        for root, dirs, files in os.walk(base_path):\n",
    "            for dir in dirs:\n",
    "                if dir.startswith(folder_prefix):\n",
    "                    folder_path = os.path.join(root, dir)\n",
    "                    sources.append(folder_path)\n",
    "                else:\n",
    "                    recursive_search(os.path.join(root, dir))\n",
    "                    break # TODO: Remove to work with all houses (not just H1)\n",
    "            break\n",
    "\n",
    "    recursive_search(base_path)\n",
    "    \n",
    "    return sources"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T03:14:32.072320600Z",
     "start_time": "2023-11-02T03:14:32.012887600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_path = \".\\dataset\"\n",
    "train_folder_prefix = \"Tagged_Training_\"\n",
    "test_folder_prefix = \"Testing_\"\n",
    "\n",
    "file_path_volts1 = r\"LF1V.csv\"\n",
    "file_path_amps1 = r\"LF1I.csv\"\n",
    "file_path_time_ticks1 = r\"TimeTicks1.csv\"\n",
    "\n",
    "file_path_volts2 = r\"LF2V.csv\"\n",
    "file_path_amps2 = r\"LF2I.csv\"\n",
    "file_path_time_ticks2 = r\"TimeTicks2.csv\"\n",
    "\n",
    "file_path_tagging_info = r\".\\dataset\\CompleteTaggingInfo.csv\"\n",
    "file_path_tagging_info_generalized = r\".\\dataset\\AllTaggingInfo_generalized.csv\"\n",
    "\n",
    "sources = concatenate_files_in_folders(base_path, train_folder_prefix)\n",
    "\n",
    "for source in sources:\n",
    "    LF1V = pd.read_csv(os.path.join(source, file_path_volts1))\n",
    "    LF1I = pd.read_csv(os.path.join(source, file_path_amps1))\n",
    "    time_ticks1 = pd.read_csv(os.path.join(source, file_path_time_ticks1))\n",
    "    LF2V = pd.read_csv(os.path.join(source, file_path_volts2))\n",
    "    LF2I = pd.read_csv(os.path.join(source, file_path_amps2))\n",
    "    time_ticks2 = pd.read_csv(os.path.join(source, file_path_time_ticks2))\n",
    "    training_set = calculate_power(LF1V, LF1I, time_ticks1, LF2V, LF2I, time_ticks2)\n",
    "\n",
    "tagging_info = pd.read_csv(file_path_tagging_info)\n",
    "general_tagging_info = pd.read_csv(file_path_tagging_info_generalized)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T03:14:38.875339Z",
     "start_time": "2023-11-02T03:14:33.154141Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "def label_generalization(ids, general_labels):\n",
    "    generalized_ids = np.empty(0)\n",
    "    for id in ids:\n",
    "        generalized_ids = np.append(generalized_ids, general_labels.loc[general_labels['ApplianceID'] == id, 'GeneralID'].unique()[0])\n",
    "    return generalized_ids"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T19:38:55.212098800Z",
     "start_time": "2023-11-01T19:38:55.171655800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 5. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(label_generalization([1, 2, 3], general_tagging_info))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T19:38:55.820467300Z",
     "start_time": "2023-11-01T19:38:55.641769700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "labels = np.empty(0)\n",
    "labels = np.append(labels, 1)\n",
    "labels = np.append(labels, 2)\n",
    "labels = np.append(labels, 3)\n",
    "encoder = OneHotEncoder(sparse_output=False, categories=[list(range(19))])\n",
    "labels_encoded = encoder.fit_transform(np.array(labels).reshape(-1, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T21:17:54.741083400Z",
     "start_time": "2023-11-01T21:17:54.383483500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def calculate_power(LF1V, LF1I, TimeTicks1, LF2V, LF2I, TimeTicks2):\n",
    "    LF1V = np.array(LF1V)\n",
    "    LF1I = np.array(LF1I)\n",
    "    LF1V = np.array([[complex(y.replace(\"i\", \"j\")) for y in x] for x in LF1V])\n",
    "    LF1I = np.array([[complex(y.replace(\"i\", \"j\")) for y in x] for x in LF1I])\n",
    "\n",
    "    LF2V = np.array(LF2V)\n",
    "    LF2I = np.array(LF2I)\n",
    "    LF2V = np.array([[complex(y.replace(\"i\", \"j\")) for y in x] for x in LF2V])\n",
    "    LF2I = np.array([[complex(y.replace(\"i\", \"j\")) for y in x] for x in LF2I])\n",
    "\n",
    "    L1_P = LF1V * np.conjugate(LF1I)\n",
    "    L2_P = LF2V * np.conjugate(LF2I)\n",
    "\n",
    "    L1_ComplexPower = np.sum(L1_P, axis=1)\n",
    "    L2_ComplexPower = np.sum(L2_P, axis=1)\n",
    "\n",
    "    L1_real = np.real(L1_ComplexPower)\n",
    "    L1_imag = np.imag(L1_ComplexPower)\n",
    "    L1_app = np.abs(L1_ComplexPower)\n",
    "\n",
    "    L2_real = np.real(L2_ComplexPower)\n",
    "    L2_imag = np.imag(L2_ComplexPower)\n",
    "    L2_app = np.abs(L2_ComplexPower)\n",
    "\n",
    "    L1_Pf = np.cos(np.angle(L1_P[:, 0]))\n",
    "    L2_Pf = np.cos(np.angle(L2_P[:, 0]))\n",
    "\n",
    "    L1_actual_power = L1_real * L1_Pf\n",
    "    L2_actual_power = L2_real * L2_Pf\n",
    "\n",
    "    time_ticks1 = np.array(TimeTicks1)\n",
    "    time_ticks2 = np.array(TimeTicks2)\n",
    "\n",
    "    data = pd.DataFrame()\n",
    "    len = min(L1_actual_power.size, L2_actual_power.size)\n",
    "\n",
    "    data[\"Phase1_actual\"] = L1_actual_power[:len]\n",
    "    data[\"Phase1_real\"] = L1_real[:len]\n",
    "    data[\"Phase1_img\"] = L1_imag[:len]\n",
    "    data[\"Phase1_app\"] = L1_app[:len]\n",
    "    data[\"Phase1_time\"] = time_ticks1[:len]\n",
    "\n",
    "    data[\"Phase2_actual\"] = L2_actual_power[:len]\n",
    "    data[\"Phase2_real\"] = L2_real[:len]\n",
    "    data[\"Phase2_img\"] = L2_imag[:len]\n",
    "    data[\"Phase2_app\"] = L2_app[:len]\n",
    "    data[\"Phase2_time\"] = time_ticks2[:len]\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T03:14:43.824912800Z",
     "start_time": "2023-11-02T03:14:43.754360700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Go through directory and process the days"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Directory is the path to the directory where to house's information is\n",
    "def read_files_in_directory(directory):\n",
    "    all_tagging_info = pd.DataFrame()\n",
    "    labels = []\n",
    "    data = []\n",
    "\n",
    "    for root, _, files in os.walk(directory):\n",
    "        if \"Testing\" in root:\n",
    "            continue\n",
    "\n",
    "        LF1I = pd.DataFrame()\n",
    "        LF1V = pd.DataFrame()\n",
    "        TimeTicks1 = pd.DataFrame()\n",
    "        LF2I = pd.DataFrame()\n",
    "        LF2V = pd.DataFrame()\n",
    "        TimeTicks2 = pd.DataFrame()\n",
    "        for file in files:\n",
    "\n",
    "            file_path = os.path.join(root, file)\n",
    "            if file == \"CompleteTaggingInfo.csv\":\n",
    "                all_tagging_info = pd.read_csv(file_path)\n",
    "                continue\n",
    "\n",
    "            if file == \"TaggingInfo.csv\":\n",
    "                # labels.append(pd.read_csv(file_path))\n",
    "                continue\n",
    "\n",
    "            if file == \"LF1I.csv\":\n",
    "                LF1I = pd.read_csv(file_path)\n",
    "                continue\n",
    "\n",
    "            if file == \"LF1V.csv\":\n",
    "                LF1V = pd.read_csv(file_path)\n",
    "                continue\n",
    "\n",
    "            if file == \"TimeTicks1.csv\":\n",
    "                TimeTicks1 = pd.read_csv(file_path)\n",
    "                continue\n",
    "\n",
    "            if file == \"LF2I.csv\":\n",
    "                LF2I = pd.read_csv(file_path)\n",
    "                continue\n",
    "\n",
    "            if file == \"LF2V.csv\":\n",
    "                LF2V = pd.read_csv(file_path)\n",
    "                continue\n",
    "\n",
    "            if file == \"TimeTicks2.csv\":\n",
    "                TimeTicks2 = pd.read_csv(file_path)\n",
    "                continue\n",
    "\n",
    "        if not LF1I.empty and not LF1V.empty and not LF2I.empty and not LF2V.empty:\n",
    "            print(f\"{root}: \")\n",
    "            day_data = calculate_power(LF1I, LF1V, TimeTicks1, LF2I, LF2V, TimeTicks2)\n",
    "            data.append(day_data)\n",
    "\n",
    "    return data, labels, all_tagging_info"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T03:14:45.800749700Z",
     "start_time": "2023-11-02T03:14:45.733859400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\dataset\\H1\\Tagged_Training_04_13_1334300401: \n",
      ".\\dataset\\H1\\Tagged_Training_10_22_1350889201: \n",
      ".\\dataset\\H1\\Tagged_Training_10_23_1350975601: \n",
      ".\\dataset\\H1\\Tagged_Training_10_24_1351062001: \n",
      ".\\dataset\\H1\\Tagged_Training_10_25_1351148401: \n",
      ".\\dataset\\H1\\Tagged_Training_12_27_1356595201: \n"
     ]
    }
   ],
   "source": [
    "data, _, all_tagging_info = read_files_in_directory(r\".\\dataset\\H1\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T03:18:40.373408500Z",
     "start_time": "2023-11-02T03:14:46.690292500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[        Phase1_actual  Phase1_real  Phase1_img  Phase1_app   Phase1_time  \\\n",
      "0           19.430857    24.264125   18.475752   30.497560  1.334300e+09   \n",
      "1           19.924720    24.357135   17.474827   29.977318  1.334300e+09   \n",
      "2           19.690603    24.166927   17.523352   29.851436  1.334300e+09   \n",
      "3           19.910825    24.234800   17.153411   29.691161  1.334300e+09   \n",
      "4           20.829979    25.187723   17.446867   30.640081  1.334300e+09   \n",
      "...               ...          ...         ...         ...           ...   \n",
      "518938      19.939808    24.472770   17.732765   30.221969  1.334387e+09   \n",
      "518939      19.792885    24.371436   17.809936   30.185439  1.334387e+09   \n",
      "518940      20.446493    24.783498   17.294649   30.221295  1.334387e+09   \n",
      "518941      20.235556    24.840667   18.001915   30.677804  1.334387e+09   \n",
      "518942      19.618725    24.178684   17.711506   29.971757  1.334387e+09   \n",
      "\n",
      "        Phase2_actual  Phase2_real  Phase2_img  Phase2_app   Phase2_time  \n",
      "0           85.991295   120.168694 -118.877907  169.033937  1.334300e+09  \n",
      "1           85.805116   119.911703 -118.649932  168.690909  1.334300e+09  \n",
      "2           85.714063   119.935873 -118.966573  168.930930  1.334300e+09  \n",
      "3           85.494598   119.680443 -118.825656  168.650363  1.334300e+09  \n",
      "4           86.072731   120.257895 -118.927763  169.132416  1.334300e+09  \n",
      "...               ...          ...         ...         ...           ...  \n",
      "518938      86.780768   121.249157 -119.916436  170.532430  1.334387e+09  \n",
      "518939      87.182371   121.701655 -120.143478  171.013883  1.334387e+09  \n",
      "518940      87.425346   121.899392 -120.032952  171.077092  1.334387e+09  \n",
      "518941      86.774875   121.414595 -120.431602  171.012499  1.334387e+09  \n",
      "518942      87.208919   121.795380 -120.339691  171.218444  1.334387e+09  \n",
      "\n",
      "[518943 rows x 10 columns],         Phase1_actual  Phase1_real  Phase1_img  Phase1_app   Phase1_time  \\\n",
      "0          162.842429   170.978993   53.553154  179.169630  1.350889e+09   \n",
      "1          161.708231   169.737549   53.019500  177.825485  1.350889e+09   \n",
      "2          162.722837   171.018545   54.148461  179.386172  1.350889e+09   \n",
      "3          163.213836   171.296489   53.400786  179.427230  1.350889e+09   \n",
      "4          163.879920   172.037324   53.753454  180.239493  1.350889e+09   \n",
      "...               ...          ...         ...         ...           ...   \n",
      "518928     319.048360   319.120584   -8.038761  319.221817  1.350976e+09   \n",
      "518929     319.326182   319.345330   -4.720951  319.380224  1.350976e+09   \n",
      "518930     317.024258   317.112046   -8.718787  317.231882  1.350976e+09   \n",
      "518931     320.120820   320.161465   -6.363714  320.224703  1.350976e+09   \n",
      "518932     320.024071   320.050636   -5.389470  320.096011  1.350976e+09   \n",
      "\n",
      "        Phase2_actual  Phase2_real  Phase2_img  Phase2_app   Phase2_time  \n",
      "0          110.193319   132.702988  -90.767860  160.775892  1.350889e+09  \n",
      "1          110.585908   133.027111  -90.648608  160.976341  1.350889e+09  \n",
      "2          110.945709   133.218522  -90.241776  160.906037  1.350889e+09  \n",
      "3          110.874637   133.079884  -90.026315  160.670449  1.350889e+09  \n",
      "4          110.561158   132.965243  -90.539954  160.864039  1.350889e+09  \n",
      "...               ...          ...         ...         ...           ...  \n",
      "518928     111.065849   134.343832  -93.066604  163.430896  1.350976e+09  \n",
      "518929     112.235199   135.159068  -92.314340  163.676239  1.350976e+09  \n",
      "518930     112.449953   135.305397  -92.178850  163.720771  1.350976e+09  \n",
      "518931     112.760159   135.699571  -92.494485  164.224247  1.350976e+09  \n",
      "518932     113.922991   136.750410  -92.446043  165.066488  1.350976e+09  \n",
      "\n",
      "[518933 rows x 10 columns],         Phase1_actual  Phase1_real  Phase1_img  Phase1_app   Phase1_time  \\\n",
      "0          319.018772   319.044253   -5.256890  319.087559  1.350976e+09   \n",
      "1          319.213751   319.256349   -6.451634  319.321530  1.350976e+09   \n",
      "2          316.515640   316.596579   -8.335119  316.706280  1.350976e+09   \n",
      "3          318.412590   318.433425   -4.821916  318.469931  1.350976e+09   \n",
      "4          317.942143   318.008844   -7.768583  318.103718  1.350976e+09   \n",
      "...               ...          ...         ...         ...           ...   \n",
      "518928     323.582142   323.887110  -15.176356  324.242474  1.351062e+09   \n",
      "518929     324.623903   324.929969  -15.212867  325.285899  1.351062e+09   \n",
      "518930     323.504176   323.860733  -16.305783  324.270956  1.351062e+09   \n",
      "518931     323.433544   323.702232  -14.260339  324.016191  1.351062e+09   \n",
      "518932     321.480503   321.849754  -16.515759  322.273229  1.351062e+09   \n",
      "\n",
      "        Phase2_actual  Phase2_real  Phase2_img  Phase2_app   Phase2_time  \n",
      "0          109.719113   132.973314  -92.670298  162.079259  1.350976e+09  \n",
      "1          110.130151   133.620571  -93.413665  163.035486  1.350976e+09  \n",
      "2          110.343508   133.514826  -92.568069  162.465554  1.350976e+09  \n",
      "3          109.768600   133.144820  -93.012821  162.415911  1.350976e+09  \n",
      "4          109.333166   132.656299  -92.791682  161.888819  1.350976e+09  \n",
      "...               ...          ...         ...         ...           ...  \n",
      "518928     109.816868   133.303501  -93.282772  162.700642  1.351062e+09  \n",
      "518929     109.529295   133.137171  -93.549460  162.717571  1.351062e+09  \n",
      "518930     110.008565   133.237914  -92.584325  162.247339  1.351062e+09  \n",
      "518931     109.117259   132.744309  -93.524677  162.382008  1.351062e+09  \n",
      "518932     108.572693   132.328297  -93.760688  162.178435  1.351062e+09  \n",
      "\n",
      "[518933 rows x 10 columns],         Phase1_actual  Phase1_real  Phase1_img  Phase1_app   Phase1_time  \\\n",
      "0          324.192609   324.524848  -15.824444  324.910434  1.351062e+09   \n",
      "1          323.342048   323.674768  -15.762378  324.058341  1.351062e+09   \n",
      "2          321.893517   322.190657  -14.909829  322.535459  1.351062e+09   \n",
      "3          322.506852   322.870303  -16.410062  323.287060  1.351062e+09   \n",
      "4          322.487934   322.727525  -13.509429  323.010154  1.351062e+09   \n",
      "...               ...          ...         ...         ...           ...   \n",
      "518927     313.525123   313.734989  -12.605631  313.988129  1.351148e+09   \n",
      "518928     313.553162   313.840496  -14.563728  314.178228  1.351148e+09   \n",
      "518929     314.005817   314.219385  -12.693011  314.475650  1.351148e+09   \n",
      "518930     311.033037   311.340133  -14.958419  311.699266  1.351148e+09   \n",
      "518931     315.104527   315.305010  -12.378610  315.547903  1.351148e+09   \n",
      "\n",
      "        Phase2_actual  Phase2_real  Phase2_img  Phase2_app   Phase2_time  \n",
      "0          109.257317   132.674613  -92.959960  162.000330  1.351062e+09  \n",
      "1          110.044759   133.657454  -93.686648  163.222251  1.351062e+09  \n",
      "2          109.567434   133.116993  -93.400956  162.615720  1.351062e+09  \n",
      "3          109.933433   133.562481  -93.708824  163.157225  1.351062e+09  \n",
      "4          109.259499   132.697151  -93.008810  162.046822  1.351062e+09  \n",
      "...               ...          ...         ...         ...           ...  \n",
      "518927     110.240662   133.490358  -92.789155  162.571532  1.351148e+09  \n",
      "518928     109.480661   132.869235  -93.009351  162.188079  1.351148e+09  \n",
      "518929     109.279563   132.758256  -93.204917  162.209467  1.351148e+09  \n",
      "518930     109.741390   133.311882  -93.584076  162.880438  1.351148e+09  \n",
      "518931     109.377934   132.775823  -93.005661  162.109445  1.351148e+09  \n",
      "\n",
      "[518932 rows x 10 columns],         Phase1_actual  Phase1_real  Phase1_img  Phase1_app   Phase1_time  \\\n",
      "0          311.665714   311.920750  -13.723784  312.222511  1.351148e+09   \n",
      "1          311.554569   311.755130  -12.266120  311.996344  1.351148e+09   \n",
      "2          311.854578   312.118966  -13.976842  312.431755  1.351148e+09   \n",
      "3          313.516127   313.682567  -11.329379  313.887094  1.351148e+09   \n",
      "4          313.325433   313.570320  -13.557534  313.863270  1.351148e+09   \n",
      "...               ...          ...         ...         ...           ...   \n",
      "518927     284.808460   285.199911  -15.747601  285.634340  1.351235e+09   \n",
      "518928     284.716826   285.203089  -17.480431  285.738285  1.351235e+09   \n",
      "518929     284.741717   285.076286  -14.619277  285.450892  1.351235e+09   \n",
      "518930     284.484404   284.956198  -17.241298  285.477314  1.351235e+09   \n",
      "518931     285.758093   286.170299  -16.188564  286.627825  1.351235e+09   \n",
      "\n",
      "        Phase2_actual  Phase2_real  Phase2_img  Phase2_app   Phase2_time  \n",
      "0          109.204813   132.626496  -93.018935  161.994783  1.351148e+09  \n",
      "1          109.557726   133.124294  -93.506425  162.682295  1.351148e+09  \n",
      "2          109.607713   132.910184  -92.770194  162.084626  1.351148e+09  \n",
      "3          109.684553   133.043925  -92.957056  162.301263  1.351148e+09  \n",
      "4          109.460137   132.872893  -93.066628  162.223928  1.351148e+09  \n",
      "...               ...          ...         ...         ...           ...  \n",
      "518927     109.432088   131.940233  -90.513642  160.002951  1.351235e+09  \n",
      "518928     110.540211   132.799819  -90.055855  160.455130  1.351235e+09  \n",
      "518929     110.486644   132.626894  -89.694007  160.109050  1.351235e+09  \n",
      "518930     109.044581   131.537529  -90.387333  159.599472  1.351235e+09  \n",
      "518931     108.918244   131.367643  -90.227552  159.368971  1.351235e+09  \n",
      "\n",
      "[518932 rows x 10 columns],         Phase1_actual  Phase1_real  Phase1_img  Phase1_app   Phase1_time  \\\n",
      "0           44.609250    55.227514   40.225952   68.324267  1.356595e+09   \n",
      "1           44.741972    55.151765   39.675816   67.940323  1.356595e+09   \n",
      "2           43.994370    54.660710   40.216143   67.861118  1.356595e+09   \n",
      "3           44.547050    55.022593   39.808882   67.913421  1.356595e+09   \n",
      "4           44.816486    55.085621   39.294702   67.664609  1.356595e+09   \n",
      "...               ...          ...         ...         ...           ...   \n",
      "347392     225.158724   227.274738  -31.407039  229.434541  1.356653e+09   \n",
      "347393     225.853297   227.633933  -28.809661  229.449786  1.356653e+09   \n",
      "347394     224.763465   226.845789  -31.124008  228.970994  1.356653e+09   \n",
      "347395     224.921932   227.012781  -31.197529  229.146435  1.356653e+09   \n",
      "347396     224.974290   226.849718  -29.510399  228.761138  1.356653e+09   \n",
      "\n",
      "        Phase2_actual  Phase2_real  Phase2_img  Phase2_app   Phase2_time  \n",
      "0          141.325929   191.627758 -177.299085  261.067354  1.356595e+09  \n",
      "1          142.068482   192.100290 -176.662295  260.982926  1.356595e+09  \n",
      "2          142.154960   192.035245 -176.226371  260.640114  1.356595e+09  \n",
      "3          141.547647   191.715512 -176.964719  260.904866  1.356595e+09  \n",
      "4          141.517839   191.866020 -177.474175  261.361153  1.356595e+09  \n",
      "...               ...          ...         ...         ...           ...  \n",
      "347392      90.274768   101.486188  -53.075576  114.527129  1.356653e+09  \n",
      "347393      92.224210   103.251501  -52.952873  116.038266  1.356653e+09  \n",
      "347394      89.412939   100.816766  -53.461022  114.114421  1.356653e+09  \n",
      "347395      90.826572   101.995151  -53.075012  114.978118  1.356653e+09  \n",
      "347396      90.549541   101.801140  -53.251471  114.887733  1.356653e+09  \n",
      "\n",
      "[347397 rows x 10 columns]]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T03:31:51.903943200Z",
     "start_time": "2023-11-02T03:31:51.750266100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Next we need to detect all labeled events"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### All the methods needed to detect, filter and extract spikes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def moving_average(array, window):\n",
    "    moving_avg = np.convolve(array, np.ones(window) / window, mode='valid')\n",
    "    return moving_avg\n",
    "\n",
    "\n",
    "def normalize(array):\n",
    "    min_val = np.min(array)\n",
    "    max_val = np.max(array)\n",
    "    normalized_array = (array - min_val) / (max_val - min_val)\n",
    "    return normalized_array\n",
    "\n",
    "\n",
    "def detect_cusum(array, threshold, drift):\n",
    "    sum_positive = np.zeros(array.size)\n",
    "    sum_negative = np.zeros(array.size)\n",
    "    event_index_start = np.array([[], [], []], dtype=int)\n",
    "    event_index_end = np.array([[], [], []], dtype=int)\n",
    "\n",
    "    for i in range(1, array.size):\n",
    "        sum = array[i] - array[i - 1]\n",
    "\n",
    "        # sums for positive/negative changes\n",
    "        sum_positive[i] = max(0, sum_positive[i - 1] + sum - drift)\n",
    "        sum_negative[i] = max(0, sum_negative[i - 1] - sum - drift)\n",
    "\n",
    "        # if a change is detected\n",
    "        if sum_positive[i] > threshold:\n",
    "            event_index_start = np.append(event_index_start, i)\n",
    "            sum_positive[i], sum_negative[i] = 0, 0\n",
    "            continue\n",
    "\n",
    "        if sum_negative[i] > threshold:\n",
    "            event_index_end = np.append(event_index_end, i)\n",
    "            sum_positive[i], sum_negative[i] = 0, 0\n",
    "\n",
    "    return event_index_start, event_index_end\n",
    "\n",
    "\n",
    "def filter_close_events(event_indices, min_separation):\n",
    "    filtered_indices = [event_indices[0]]\n",
    "\n",
    "    for i in range(1, event_indices.size):\n",
    "        if event_indices[i] - event_indices[i - 1] >= min_separation:\n",
    "            # If the time separation is greater than or equal to the threshold, keep the event\n",
    "            filtered_indices.append(event_indices[i])\n",
    "\n",
    "    return np.array(filtered_indices)\n",
    "\n",
    "\n",
    "# Short spikes in power when an appliance starts up can be detected as an end event, so make sure that start and end events are not too close together\n",
    "def filter_spikes(events_start, events_end, min_separation):\n",
    "    indexes_to_delete = list()\n",
    "\n",
    "    for iter in range(4):\n",
    "        for i in range(events_start.size):\n",
    "            for j in range(events_end.size):\n",
    "                if events_end[j] < events_start[i]:\n",
    "                    continue\n",
    "\n",
    "                if events_end[j] - events_start[i] < min_separation:\n",
    "                    indexes_to_delete.append(j)\n",
    "                    break\n",
    "\n",
    "                break\n",
    "\n",
    "        events_end = np.delete(events_end, indexes_to_delete)\n",
    "        indexes_to_delete = list()\n",
    "    return events_end\n",
    "\n",
    "\n",
    "def group_start_end(events_start, events_end):\n",
    "    start_indexes = list()\n",
    "    end_indexes = list()\n",
    "\n",
    "    for i in range(events_start.size):\n",
    "        for j in range(events_end.size):\n",
    "            if events_end[j] < events_start[i]:\n",
    "                continue\n",
    "\n",
    "            start_indexes.append(events_start[i])\n",
    "            end_indexes.append(events_end[j])\n",
    "            break\n",
    "\n",
    "    return np.array(start_indexes), np.array(end_indexes)\n",
    "\n",
    "\n",
    "def filter_short_events(events_start, events_end, min_event_length):\n",
    "    start_indexes = list()\n",
    "    end_indexes = list()\n",
    "\n",
    "    for i in range(events_start.size):\n",
    "        if events_end[i] - events_start[i] >= min_event_length:\n",
    "            start_indexes.append(events_start[i])\n",
    "            end_indexes.append(events_end[i])\n",
    "\n",
    "    return np.array(start_indexes), np.array(end_indexes)\n",
    "\n",
    "\n",
    "def calculate_overlap(start, end, on, off):\n",
    "    return (min(end, off) - max(start, on)) / (end - start)\n",
    "\n",
    "\n",
    "def find_closest_event(events_start, events_end, time_ticks, label):\n",
    "    start = 0\n",
    "    end = max(events_end)\n",
    "\n",
    "    for event in range(events_start.size):\n",
    "        if events_start[event] > start and time_ticks[int(events_start[event])] <= label[\"OnTime\"]:\n",
    "            start = events_start[event]\n",
    "\n",
    "        if events_end[event] < end and time_ticks[int(events_end[event])] >= label[\"OffTime\"]:\n",
    "            end = events_end[event]\n",
    "\n",
    "    return start, end\n",
    "\n",
    "\n",
    "def extract_labeled_spikes(events_start, events_end, time_ticks, labels):\n",
    "    labeled_events_start = list()\n",
    "    labeled_events_end = list()\n",
    "    event_labels = list()\n",
    "\n",
    "    start_of_day = time_ticks[0][0]\n",
    "    end_of_day = time_ticks[0][time_ticks[0].size - 1]\n",
    "\n",
    "    for index in range(labels.shape[0]):\n",
    "        row = labels.iloc[index]\n",
    "        found = False\n",
    "\n",
    "        if not (start_of_day <= row[\"OnTime\"] <= end_of_day):\n",
    "            continue\n",
    "\n",
    "        last_event = 0\n",
    "        phase_index = 0\n",
    "        for event in range(events_start.size):\n",
    "            start = int(events_start[event])\n",
    "            end = int(events_end[event])\n",
    "\n",
    "            if start < last_event:\n",
    "                phase_index += 1\n",
    "\n",
    "            last_event = start\n",
    "\n",
    "            time = time_ticks[phase_index]\n",
    "\n",
    "            if not (row[\"OnTime\"] <= time[start] <= row[\"OffTime\"] or row[\"OnTime\"] <= time[end] <= row[\"OffTime\"]):\n",
    "                continue\n",
    "\n",
    "            found = True\n",
    "            overlap = calculate_overlap(time[start], time[end], row[\"OnTime\"], row[\"OffTime\"])\n",
    "            if overlap < 0.3:\n",
    "                continue\n",
    "\n",
    "            labeled_events_start.append(start)\n",
    "            labeled_events_end.append(end)\n",
    "            event_labels.append(row[\"ID\"])\n",
    "\n",
    "        if not found:\n",
    "            start, end = find_closest_event(events_start, events_end, time_ticks[phase_index], row)\n",
    "            labeled_events_start.append(start)\n",
    "            labeled_events_end.append(end)\n",
    "            event_labels.append(row[\"ID\"])\n",
    "\n",
    "    return np.array(labeled_events_start), np.array(labeled_events_end), np.array(event_labels)\n",
    "\n",
    "\n",
    "def calculate_events(phase_power):\n",
    "    phase_power = moving_average(phase_power, 7)\n",
    "    phase_power = normalize(phase_power)\n",
    "\n",
    "    events_start, events_end = detect_cusum(phase_power, threshold=0.009, drift=0.0005)\n",
    "    events_start = filter_close_events(events_start, 60)\n",
    "    events_end = filter_close_events(events_end, 60)\n",
    "    events_end = filter_spikes(events_start, events_end, 12)\n",
    "    events_start, events_end = group_start_end(events_start, events_end)\n",
    "    events_start, events_end = filter_short_events(events_start, events_end, 100)\n",
    "\n",
    "    return events_start, events_end\n",
    "\n",
    "\n",
    "def remove_overlapping_events(events_start, events_end, event_labels):\n",
    "    to_remove = list()\n",
    "\n",
    "    for index in range(1, events_start.size):\n",
    "        if events_end[index] == events_end[index - 1]:\n",
    "            to_remove.append(index)\n",
    "\n",
    "    return np.delete(events_start, to_remove), np.delete(events_end, to_remove), np.delete(event_labels, to_remove)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T03:31:55.469782100Z",
     "start_time": "2023-11-02T03:31:55.375257400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def format_events(dataframe):\n",
    "    result = []\n",
    "    act = []\n",
    "    img = []\n",
    "    app = []\n",
    "    for index, row in dataframe:\n",
    "        if row['Phase1_Events']:\n",
    "            act = []\n",
    "            img = []\n",
    "            app = []\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T02:38:12.501415300Z",
     "start_time": "2023-11-02T02:38:12.408603100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def label_generalization(ids, general_labels):\n",
    "    generalized_ids = np.empty(0)\n",
    "    for id in ids:\n",
    "        generalized_ids = np.append(generalized_ids,\n",
    "                                    general_labels.loc[general_labels['ApplianceID'] == id, 'GeneralID'].unique()[0])\n",
    "    return generalized_ids\n",
    "\n",
    "\n",
    "def detect_day_events(dataframe, labels, general_tagging_info):\n",
    "    phases = [\"Phase1\", \"Phase2\"]\n",
    "    events_start = np.empty(0)\n",
    "    events_end = np.empty(0)\n",
    "    time_ticks = np.empty((2, len(dataframe)))\n",
    "    events = list()\n",
    "    i = 0\n",
    "\n",
    "    for phase in phases:\n",
    "        dataframe[phase + \"_eOn\"] = 0\n",
    "        dataframe[phase + \"_eOff\"] = 0\n",
    "        power = dataframe[phase + \"_actual\"]\n",
    "        time = dataframe[phase + \"_time\"]\n",
    "\n",
    "        events_start_temp, events_end_temp = calculate_events(power)\n",
    "        events.append(events_start_temp)\n",
    "        events_start = np.append(events_start, events_start_temp)\n",
    "        events_end = np.append(events_end, events_end_temp)\n",
    "        time_ticks[i] = time\n",
    "        i += 1\n",
    "\n",
    "    events_start, events_end, event_labels = extract_labeled_spikes(events_start, events_end, time_ticks, labels)\n",
    "    events_start, events_end, event_labels = remove_overlapping_events(events_start, events_end, event_labels)\n",
    "    event_labels = label_generalization(event_labels, general_tagging_info)\n",
    "\n",
    "    phase = \"Phase1\"\n",
    "    for index in range(events_start.size):\n",
    "        if events_start[index] in events[0]:\n",
    "            phase = \"Phase1\"\n",
    "        else:\n",
    "            phase = \"Phase2\"\n",
    "\n",
    "        dataframe.loc[events_start[index], phase + \"_eOn\"] = event_labels[index]\n",
    "        dataframe.loc[events_end[index], phase + \"_eOff\"] = event_labels[index]\n",
    "\n",
    "    return dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T03:32:01.193868600Z",
     "start_time": "2023-11-02T03:32:01.105708Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Edit dataframes to have events"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "general_labels = pd.read_csv(r\".\\dataset\\AllTaggingInfo_generalized.csv\")\n",
    "for index in range(len(data)):\n",
    "    data[index] = detect_day_events(data[index], all_tagging_info, general_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T03:32:18.847243200Z",
     "start_time": "2023-11-02T03:32:03.169354Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Phase1_actual  Phase1_real  Phase1_img  Phase1_app   Phase1_time  \\\n",
      "0           19.430857    24.264125   18.475752   30.497560  1.334300e+09   \n",
      "1           19.924720    24.357135   17.474827   29.977318  1.334300e+09   \n",
      "2           19.690603    24.166927   17.523352   29.851436  1.334300e+09   \n",
      "3           19.910825    24.234800   17.153411   29.691161  1.334300e+09   \n",
      "4           20.829979    25.187723   17.446867   30.640081  1.334300e+09   \n",
      "...               ...          ...         ...         ...           ...   \n",
      "518938      19.939808    24.472770   17.732765   30.221969  1.334387e+09   \n",
      "518939      19.792885    24.371436   17.809936   30.185439  1.334387e+09   \n",
      "518940      20.446493    24.783498   17.294649   30.221295  1.334387e+09   \n",
      "518941      20.235556    24.840667   18.001915   30.677804  1.334387e+09   \n",
      "518942      19.618725    24.178684   17.711506   29.971757  1.334387e+09   \n",
      "\n",
      "        Phase2_actual  Phase2_real  Phase2_img  Phase2_app   Phase2_time  \\\n",
      "0           85.991295   120.168694 -118.877907  169.033937  1.334300e+09   \n",
      "1           85.805116   119.911703 -118.649932  168.690909  1.334300e+09   \n",
      "2           85.714063   119.935873 -118.966573  168.930930  1.334300e+09   \n",
      "3           85.494598   119.680443 -118.825656  168.650363  1.334300e+09   \n",
      "4           86.072731   120.257895 -118.927763  169.132416  1.334300e+09   \n",
      "...               ...          ...         ...         ...           ...   \n",
      "518938      86.780768   121.249157 -119.916436  170.532430  1.334387e+09   \n",
      "518939      87.182371   121.701655 -120.143478  171.013883  1.334387e+09   \n",
      "518940      87.425346   121.899392 -120.032952  171.077092  1.334387e+09   \n",
      "518941      86.774875   121.414595 -120.431602  171.012499  1.334387e+09   \n",
      "518942      87.208919   121.795380 -120.339691  171.218444  1.334387e+09   \n",
      "\n",
      "        Phase1_eOn  Phase1_eOff  Phase2_eOn  Phase2_eOff  \n",
      "0                0            0           0            0  \n",
      "1                0            0           0            0  \n",
      "2                0            0           0            0  \n",
      "3                0            0           0            0  \n",
      "4                0            0           0            0  \n",
      "...            ...          ...         ...          ...  \n",
      "518938           0            0           0            0  \n",
      "518939           0            0           0            0  \n",
      "518940           0            0           0            0  \n",
      "518941           0            0           0            0  \n",
      "518942           0            0           0            0  \n",
      "\n",
      "[518943 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T03:32:18.936588Z",
     "start_time": "2023-11-02T03:32:18.853236600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Now we need to process the data, so that it's in a format that we can give to the model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Extract spikes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def get_index(expected, id):\n",
    "    for touple in expected:\n",
    "        if touple[0] == id:\n",
    "            return touple[1]\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "def process_spike(real, imag, app, event_start, event_end, label):\n",
    "    window = 70\n",
    "    length = event_end - event_start + 1\n",
    "    labels = np.empty((length // window) + 1)\n",
    "    spike = np.empty((((length // window) + 1), 3, window))\n",
    "\n",
    "    for index in range(spike.shape[0] - 1):\n",
    "        spike_window = np.empty((3, window))\n",
    "        spike_window[0] = real[(event_start + window * index):(event_start + (window * (index + 1)))]\n",
    "        spike_window[1] = imag[(event_start + window * index):(event_start + (window * (index + 1)))]\n",
    "        spike_window[2] = app[(event_start + window * index):(event_start + (window * (index + 1)))]\n",
    "\n",
    "        spike[index] = spike_window\n",
    "        labels[index] = label\n",
    "\n",
    "    # Last window may be too short, so we add it here, making sure it's the correct length\n",
    "    spike_window = np.empty((3, window))\n",
    "    spike_window[0] = real[(event_end - window):event_end]\n",
    "    spike_window[1] = imag[(event_end - window):event_end]\n",
    "    spike_window[2] = app[(event_end - window):event_end]\n",
    "\n",
    "    spike[spike.shape[0] - 1] = spike_window\n",
    "    labels[spike.shape[0] - 1] = label\n",
    "\n",
    "    return spike, labels\n",
    "\n",
    "\n",
    "def extract_spikes(dataframe):\n",
    "    spikes = np.empty((0, 3, 70))\n",
    "    labels = np.empty(0)\n",
    "    expected1 = list()\n",
    "    expected2 = list()\n",
    "\n",
    "    for index in range(len(dataframe)):\n",
    "        row = dataframe.iloc[index]\n",
    "\n",
    "        if row[\"Phase1_eOff\"] != 0:\n",
    "            start = get_index(expected1, row[\"Phase1_eOff\"])\n",
    "            if start == 0:\n",
    "                continue\n",
    "            expected1.remove((row[\"Phase1_eOff\"], start))\n",
    "\n",
    "            real = dataframe[\"Phase1_real\"]\n",
    "            imag = dataframe[\"Phase1_img\"]\n",
    "            app = dataframe[\"Phase1_app\"]\n",
    "\n",
    "            spike, spike_label = process_spike(real, imag, app, start, index, row[\"Phase1_eOff\"])\n",
    "            spikes = np.vstack([spikes, spike])\n",
    "            labels = np.append(labels, spike_label)\n",
    "\n",
    "        if row[\"Phase2_eOff\"] != 0:\n",
    "            start = get_index(expected2, row[\"Phase2_eOff\"])\n",
    "            if start == 0:\n",
    "                continue\n",
    "            expected2.remove((row[\"Phase2_eOff\"], start))\n",
    "\n",
    "            real = dataframe[\"Phase2_real\"]\n",
    "            imag = dataframe[\"Phase2_img\"]\n",
    "            app = dataframe[\"Phase2_app\"]\n",
    "\n",
    "            spike, spike_label = process_spike(real, imag, app, start, index, row[\"Phase2_eOff\"])\n",
    "            spikes = np.vstack([spikes, spike])\n",
    "            labels = np.append(labels, spike_label)\n",
    "\n",
    "        if row[\"Phase1_eOn\"] != 0:\n",
    "            expected1.append((row[\"Phase1_eOn\"], index))\n",
    "\n",
    "        if row[\"Phase2_eOn\"] != 0:\n",
    "            expected2.append((row[\"Phase2_eOn\"], index))\n",
    "\n",
    "    return spikes, labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T03:32:21.904529500Z",
     "start_time": "2023-11-02T03:32:21.859257800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "spikes = np.empty((0, 3, 70))\n",
    "labels = np.empty(0)\n",
    "for index in range(len(data)):\n",
    "    day_spikes, day_labels = extract_spikes(data[index])\n",
    "    spikes = np.vstack([spikes, day_spikes])\n",
    "    labels = np.append(labels, day_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T03:36:15.259718200Z",
     "start_time": "2023-11-02T03:32:22.852782Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "final_spikes = spikes.reshape(spikes.shape[0], -1)\n",
    "encoder = OneHotEncoder(sparse_output=False, categories=\"auto\")\n",
    "final_labels = encoder.fit_transform(np.array(labels).reshape(-1, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T03:36:17.667079300Z",
     "start_time": "2023-11-02T03:36:17.590726400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2301, 210)\n",
      "(2301, 12)\n"
     ]
    }
   ],
   "source": [
    "print(final_spikes.shape)\n",
    "print(final_labels.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T03:36:18.572447Z",
     "start_time": "2023-11-02T03:36:18.496744600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "print(test_X.shape)\n",
    "print(test_y.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(final_spikes, final_labels, train_size=0.7, shuffle=True)\n",
    "train_X = train_X.reshape(train_X.shape[0], 70, 3)\n",
    "test_X = test_X.reshape(test_X.shape[0], 70, 3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T03:36:30.899709700Z",
     "start_time": "2023-11-02T03:36:30.814612600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Make the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(70, 3)))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(Conv1D(filters=16, kernel_size=3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(12, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T03:36:33.930565300Z",
     "start_time": "2023-11-02T03:36:32.655024500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "51/51 [==============================] - 6s 24ms/step - loss: 26.0941 - accuracy: 0.4292 - val_loss: 1.8576 - val_accuracy: 0.4153\n",
      "Epoch 2/50\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 1.5094 - accuracy: 0.5584 - val_loss: 1.2178 - val_accuracy: 0.5673\n",
      "Epoch 3/50\n",
      "51/51 [==============================] - 2s 29ms/step - loss: 1.1028 - accuracy: 0.6447 - val_loss: 1.1774 - val_accuracy: 0.6585\n",
      "Epoch 4/50\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 1.0048 - accuracy: 0.6925 - val_loss: 0.8576 - val_accuracy: 0.7829\n",
      "Epoch 5/50\n",
      "51/51 [==============================] - 1s 18ms/step - loss: 0.7403 - accuracy: 0.7832 - val_loss: 1.0550 - val_accuracy: 0.5499\n",
      "Epoch 6/50\n",
      "51/51 [==============================] - 1s 18ms/step - loss: 0.6459 - accuracy: 0.8211 - val_loss: 0.7450 - val_accuracy: 0.8249\n",
      "Epoch 7/50\n",
      "51/51 [==============================] - 1s 18ms/step - loss: 0.5639 - accuracy: 0.8379 - val_loss: 0.6956 - val_accuracy: 0.8104\n",
      "Epoch 8/50\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.5282 - accuracy: 0.8534 - val_loss: 0.6482 - val_accuracy: 0.7887\n",
      "Epoch 9/50\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.4952 - accuracy: 0.8311 - val_loss: 0.7337 - val_accuracy: 0.8148\n",
      "Epoch 10/50\n",
      "51/51 [==============================] - 1s 18ms/step - loss: 0.4853 - accuracy: 0.8497 - val_loss: 0.7556 - val_accuracy: 0.7540\n",
      "Epoch 11/50\n",
      "51/51 [==============================] - 1s 18ms/step - loss: 0.5070 - accuracy: 0.8391 - val_loss: 0.6878 - val_accuracy: 0.8148\n",
      "Epoch 12/50\n",
      "51/51 [==============================] - 1s 18ms/step - loss: 0.6222 - accuracy: 0.8037 - val_loss: 0.6831 - val_accuracy: 0.7887\n",
      "Epoch 13/50\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.4844 - accuracy: 0.8478 - val_loss: 0.6516 - val_accuracy: 0.8003\n",
      "Epoch 14/50\n",
      "51/51 [==============================] - 1s 22ms/step - loss: 0.4687 - accuracy: 0.8466 - val_loss: 0.6468 - val_accuracy: 0.7844\n",
      "Epoch 15/50\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.4217 - accuracy: 0.8435 - val_loss: 0.5082 - val_accuracy: 0.8452\n",
      "Epoch 16/50\n",
      "51/51 [==============================] - 1s 23ms/step - loss: 0.4560 - accuracy: 0.8466 - val_loss: 0.7789 - val_accuracy: 0.7569\n",
      "Epoch 17/50\n",
      "51/51 [==============================] - 1s 23ms/step - loss: 0.4485 - accuracy: 0.8286 - val_loss: 0.5280 - val_accuracy: 0.8394\n",
      "Epoch 18/50\n",
      "51/51 [==============================] - 1s 22ms/step - loss: 0.3904 - accuracy: 0.8602 - val_loss: 0.5600 - val_accuracy: 0.8365\n",
      "Epoch 19/50\n",
      "51/51 [==============================] - 1s 23ms/step - loss: 0.3986 - accuracy: 0.8571 - val_loss: 0.4854 - val_accuracy: 0.8698\n",
      "Epoch 20/50\n",
      "51/51 [==============================] - 1s 23ms/step - loss: 0.3809 - accuracy: 0.8565 - val_loss: 0.4886 - val_accuracy: 0.8350\n",
      "Epoch 21/50\n",
      "51/51 [==============================] - 1s 22ms/step - loss: 0.3705 - accuracy: 0.8571 - val_loss: 0.5061 - val_accuracy: 0.8249\n",
      "Epoch 22/50\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 0.3410 - accuracy: 0.8677 - val_loss: 0.5277 - val_accuracy: 0.8220\n",
      "Epoch 23/50\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.3698 - accuracy: 0.8602 - val_loss: 0.5024 - val_accuracy: 0.8365\n",
      "Epoch 24/50\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.3352 - accuracy: 0.8714 - val_loss: 0.5675 - val_accuracy: 0.8133\n",
      "Epoch 25/50\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.3342 - accuracy: 0.8783 - val_loss: 0.5420 - val_accuracy: 0.8379\n",
      "Epoch 26/50\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.3285 - accuracy: 0.8683 - val_loss: 0.5791 - val_accuracy: 0.8205\n",
      "Epoch 27/50\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 0.3621 - accuracy: 0.8658 - val_loss: 0.5886 - val_accuracy: 0.8379\n",
      "Epoch 28/50\n",
      "51/51 [==============================] - 1s 26ms/step - loss: 0.3500 - accuracy: 0.8739 - val_loss: 0.6307 - val_accuracy: 0.8278\n",
      "Epoch 29/50\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 0.3544 - accuracy: 0.8714 - val_loss: 0.5131 - val_accuracy: 0.8524\n",
      "Epoch 30/50\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 0.3198 - accuracy: 0.8801 - val_loss: 0.5853 - val_accuracy: 0.8379\n",
      "Epoch 31/50\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 0.3403 - accuracy: 0.8702 - val_loss: 0.5590 - val_accuracy: 0.8480\n",
      "Epoch 32/50\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 0.3189 - accuracy: 0.8770 - val_loss: 0.6662 - val_accuracy: 0.8162\n",
      "Epoch 33/50\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 0.3566 - accuracy: 0.8745 - val_loss: 0.6244 - val_accuracy: 0.8394\n",
      "Epoch 34/50\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 0.3365 - accuracy: 0.8683 - val_loss: 0.5673 - val_accuracy: 0.8567\n",
      "Epoch 35/50\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.3164 - accuracy: 0.8776 - val_loss: 0.5534 - val_accuracy: 0.8524\n",
      "Epoch 36/50\n",
      "51/51 [==============================] - 1s 22ms/step - loss: 0.2913 - accuracy: 0.9012 - val_loss: 0.5462 - val_accuracy: 0.8480\n",
      "Epoch 37/50\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.2969 - accuracy: 0.8870 - val_loss: 0.5827 - val_accuracy: 0.8669\n",
      "Epoch 38/50\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.3545 - accuracy: 0.8758 - val_loss: 0.6481 - val_accuracy: 0.8249\n",
      "Epoch 39/50\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 0.3834 - accuracy: 0.8534 - val_loss: 0.5946 - val_accuracy: 0.8669\n",
      "Epoch 40/50\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.3809 - accuracy: 0.8627 - val_loss: 0.6331 - val_accuracy: 0.8524\n",
      "Epoch 41/50\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.3262 - accuracy: 0.8739 - val_loss: 0.5988 - val_accuracy: 0.8379\n",
      "Epoch 42/50\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.3291 - accuracy: 0.8826 - val_loss: 0.6327 - val_accuracy: 0.8205\n",
      "Epoch 43/50\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.2972 - accuracy: 0.8870 - val_loss: 0.5786 - val_accuracy: 0.8712\n",
      "Epoch 44/50\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.3556 - accuracy: 0.8714 - val_loss: 0.7031 - val_accuracy: 0.8177\n",
      "Epoch 45/50\n",
      "51/51 [==============================] - 1s 18ms/step - loss: 0.3435 - accuracy: 0.8752 - val_loss: 0.5634 - val_accuracy: 0.8755\n",
      "Epoch 46/50\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.3140 - accuracy: 0.8826 - val_loss: 0.5724 - val_accuracy: 0.8394\n",
      "Epoch 47/50\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.2979 - accuracy: 0.8845 - val_loss: 0.9199 - val_accuracy: 0.6715\n",
      "Epoch 48/50\n",
      "51/51 [==============================] - 1s 18ms/step - loss: 0.3476 - accuracy: 0.8634 - val_loss: 0.5491 - val_accuracy: 0.8611\n",
      "Epoch 49/50\n",
      "51/51 [==============================] - 1s 18ms/step - loss: 0.2979 - accuracy: 0.8826 - val_loss: 0.6722 - val_accuracy: 0.8640\n",
      "Epoch 50/50\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 0.4109 - accuracy: 0.8857 - val_loss: 0.5958 - val_accuracy: 0.8799\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x16f23e41cc0>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_y, epochs=50, batch_size=32, validation_data=(test_X, test_y))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T03:37:38.000914100Z",
     "start_time": "2023-11-02T03:36:41.341638900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test the model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T19:56:35.359083800Z",
     "start_time": "2023-11-01T19:56:35.116546Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get a day"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T19:56:32.224819500Z",
     "start_time": "2023-11-01T19:56:31.858159200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "file_path_volts1 = r\".\\dataset\\H1\\Tagged_Training_12_27_1356595201\\LF1V.csv\"\n",
    "file_path_amps1 = r\".\\dataset\\H1\\Tagged_Training_12_27_1356595201\\LF1I.csv\"\n",
    "file_path_time_ticks1 = r\".\\dataset\\H1\\Tagged_Training_12_27_1356595201\\TimeTicks1.csv\"\n",
    "\n",
    "file_path_volts2 = r\".\\dataset\\H1\\Tagged_Training_12_27_1356595201\\LF2V.csv\"\n",
    "file_path_amps2 = r\".\\dataset\\H1\\Tagged_Training_12_27_1356595201\\LF2I.csv\"\n",
    "file_path_time_ticks2 = r\".\\dataset\\H1\\Tagged_Training_12_27_1356595201\\TimeTicks2.csv\"\n",
    "\n",
    "LF1V = pd.read_csv(file_path_volts1)\n",
    "LF1I = pd.read_csv(file_path_amps1)\n",
    "time_ticks1 = pd.read_csv(file_path_time_ticks1)\n",
    "\n",
    "LF2V = pd.read_csv(file_path_volts2)\n",
    "LF2I = pd.read_csv(file_path_amps2)\n",
    "time_ticks2 = pd.read_csv(file_path_time_ticks2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T03:38:46.549390700Z",
     "start_time": "2023-11-02T03:38:32.182317600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "LF1V = np.array(LF1V)\n",
    "LF1I = np.array(LF1I)\n",
    "LF1V = np.array([[complex(y.replace(\"i\", \"j\")) for y in x] for x in LF1V])\n",
    "LF1I = np.array([[complex(y.replace(\"i\", \"j\")) for y in x] for x in LF1I])\n",
    "\n",
    "LF2V = np.array(LF2V)\n",
    "LF2I = np.array(LF2I)\n",
    "LF2V = np.array([[complex(y.replace(\"i\", \"j\")) for y in x] for x in LF2V])\n",
    "LF2I = np.array([[complex(y.replace(\"i\", \"j\")) for y in x] for x in LF2I])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T03:39:07.975559700Z",
     "start_time": "2023-11-02T03:38:48.602334Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "L1_P = LF1V * np.conjugate(LF1I)\n",
    "L2_P = LF2V * np.conjugate(LF2I)\n",
    "\n",
    "L1_ComplexPower = np.sum(L1_P, axis=1)\n",
    "L2_ComplexPower = np.sum(L2_P, axis=1)\n",
    "\n",
    "L1_real = np.real(L1_ComplexPower)\n",
    "L1_imag = np.imag(L1_ComplexPower)\n",
    "L1_app = np.abs(L1_ComplexPower)\n",
    "\n",
    "L2_real = np.real(L2_ComplexPower)\n",
    "L2_imag = np.imag(L2_ComplexPower)\n",
    "L2_app = np.abs(L2_ComplexPower)\n",
    "\n",
    "L1_Pf = np.cos(np.angle(L1_P[:, 0]))\n",
    "L2_Pf = np.cos(np.angle(L2_P[:, 0]))\n",
    "\n",
    "L1_actual_power = L1_real * L1_Pf\n",
    "L2_actual_power = L2_real * L2_Pf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T03:39:26.879224400Z",
     "start_time": "2023-11-02T03:39:26.658328100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "time_ticks1_datetime = pd.to_datetime(time_ticks1.iloc[:, 0], unit='s')\n",
    "time_ticks1_np = np.array(time_ticks1)\n",
    "TS1_real = np.array(time_ticks1_datetime)\n",
    "\n",
    "time_ticks2_datetime = pd.to_datetime(time_ticks2.iloc[:, 0], unit='s')\n",
    "time_ticks2_np = np.array(time_ticks2)\n",
    "TS2_real = np.array(time_ticks2_datetime)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T03:39:28.852867900Z",
     "start_time": "2023-11-02T03:39:28.768026700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "test = pd.DataFrame()\n",
    "len = min(len(L1_actual_power), len(L2_actual_power))\n",
    "\n",
    "test[\"Phase1_actual\"] = L1_actual_power[:len]\n",
    "test[\"Phase1_real\"] = L1_real[:len]\n",
    "test[\"Phase1_img\"] = L1_imag[:len]\n",
    "test[\"Phase1_app\"] = L1_app[:len]\n",
    "test[\"Phase1_time\"] = time_ticks1_np[:len]\n",
    "\n",
    "test[\"Phase2_actual\"] = L2_actual_power[:len]\n",
    "test[\"Phase2_real\"] = L2_real[:len]\n",
    "test[\"Phase2_img\"] = L2_imag[:len]\n",
    "test[\"Phase2_app\"] = L2_app[:len]\n",
    "test[\"Phase2_time\"] = time_ticks2_np[:len]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T03:39:30.802482200Z",
     "start_time": "2023-11-02T03:39:30.720637Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\test\\AppData\\Local\\Temp\\ipykernel_12216\\3548915574.py:27: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '7.79142848141e-312' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test.loc[events_start[index], phase + \"_eOn\"] = event_labels[index]\n",
      "C:\\Users\\test\\AppData\\Local\\Temp\\ipykernel_12216\\3548915574.py:28: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '7.79142848141e-312' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test.loc[events_end[index], phase + \"_eOff\"] = event_labels[index]\n",
      "C:\\Users\\test\\AppData\\Local\\Temp\\ipykernel_12216\\3548915574.py:27: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '7.791428516705e-312' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test.loc[events_start[index], phase + \"_eOn\"] = event_labels[index]\n",
      "C:\\Users\\test\\AppData\\Local\\Temp\\ipykernel_12216\\3548915574.py:28: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '7.791428516705e-312' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test.loc[events_end[index], phase + \"_eOff\"] = event_labels[index]\n"
     ]
    }
   ],
   "source": [
    "phases = [\"Phase1\", \"Phase2\"]\n",
    "events_start = np.empty(0)\n",
    "events_end = np.empty(0)\n",
    "events = list()\n",
    "\n",
    "for phase in phases:\n",
    "    test[phase + \"_eOn\"] = 0\n",
    "    test[phase + \"_eOff\"] = 0\n",
    "    power = test[phase + \"_actual\"]\n",
    "    time = test[phase + \"_time\"]\n",
    "\n",
    "    events_start_temp, events_end_temp = calculate_events(power)\n",
    "    events.append(events_start_temp)\n",
    "    events_start = np.append(events_start, events_start_temp)\n",
    "    events_end = np.append(events_end, events_end_temp)\n",
    "\n",
    "events_start, events_end, event_labels = remove_overlapping_events(events_start, events_end,\n",
    "                                                                   np.empty(events_start.shape))\n",
    "\n",
    "phase = \"Phase1\"\n",
    "for index in range(events_start.size):\n",
    "    if events_start[index] in events[0]:\n",
    "        phase = \"Phase1\"\n",
    "    else:\n",
    "        phase = \"Phase2\"\n",
    "\n",
    "    test.loc[events_start[index], phase + \"_eOn\"] = event_labels[index]\n",
    "    test.loc[events_end[index], phase + \"_eOff\"] = event_labels[index]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T03:39:36.403774600Z",
     "start_time": "2023-11-02T03:39:31.653193300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def get_index(expected, id):\n",
    "    for touple in expected:\n",
    "        if touple[0] == id:\n",
    "            return touple[1]\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "def process_spike_verification(real, imag, app, event_start, event_end):\n",
    "    window = 70\n",
    "    length = event_end - event_start + 1\n",
    "    spike = np.empty((((length // window) + 1), 3, window))\n",
    "\n",
    "    for index in range(spike.shape[0] - 1):\n",
    "        spike_window = np.empty((3, window))\n",
    "        spike_window[0] = real[(event_start + window * index):(event_start + (window * (index + 1)))]\n",
    "        spike_window[1] = imag[(event_start + window * index):(event_start + (window * (index + 1)))]\n",
    "        spike_window[2] = app[(event_start + window * index):(event_start + (window * (index + 1)))]\n",
    "\n",
    "        spike[index] = spike_window\n",
    "\n",
    "    # Last window may be too short, so we add it here, making sure it's the correct length\n",
    "    spike_window = np.empty((3, window))\n",
    "    spike_window[0] = real[(event_end - window):event_end]\n",
    "    spike_window[1] = imag[(event_end - window):event_end]\n",
    "    spike_window[2] = app[(event_end - window):event_end]\n",
    "\n",
    "    spike[spike.shape[0] - 1] = spike_window\n",
    "\n",
    "    return spike\n",
    "\n",
    "spikes = np.empty((0, 3, 70))\n",
    "expected1 = list()\n",
    "expected2 = list()\n",
    "\n",
    "for index in range(test.shape[0]):\n",
    "    row = test.iloc[index]\n",
    "\n",
    "    if row[\"Phase1_eOff\"] != 0:\n",
    "        start = get_index(expected1, row[\"Phase1_eOff\"])\n",
    "        if start == 0:\n",
    "            continue\n",
    "        expected1.remove((row[\"Phase1_eOff\"], start))\n",
    "\n",
    "        real = test[\"Phase1_real\"]\n",
    "        imag = test[\"Phase1_img\"]\n",
    "        app = test[\"Phase1_app\"]\n",
    "\n",
    "        spike = process_spike_verification(real, imag, app, start, index)\n",
    "        spikes = np.vstack([spikes, spike])\n",
    "\n",
    "    if row[\"Phase2_eOff\"] != 0:\n",
    "        start = get_index(expected2, row[\"Phase2_eOff\"])\n",
    "        if start == 0:\n",
    "            continue\n",
    "        expected2.remove((row[\"Phase2_eOff\"], start))\n",
    "\n",
    "        real = test[\"Phase2_real\"]\n",
    "        imag = test[\"Phase2_img\"]\n",
    "        app = test[\"Phase2_app\"]\n",
    "\n",
    "        spike = process_spike_verification(real, imag, app, start, index)\n",
    "        spikes = np.vstack([spikes, spike])\n",
    "\n",
    "    if row[\"Phase1_eOn\"] != 0:\n",
    "        expected1.append((row[\"Phase1_eOn\"], index))\n",
    "\n",
    "    if row[\"Phase2_eOn\"] != 0:\n",
    "        expected2.append((row[\"Phase2_eOn\"], index))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T03:40:33.187771200Z",
     "start_time": "2023-11-02T03:40:07.305524700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2198, 3, 70)\n"
     ]
    }
   ],
   "source": [
    "print(spikes.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T03:40:40.680272200Z",
     "start_time": "2023-11-02T03:40:40.622375800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2198, 210)\n"
     ]
    }
   ],
   "source": [
    "final_spikes = spikes.reshape(spikes.shape[0], -1)\n",
    "print(final_spikes.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T03:40:41.708841500Z",
     "start_time": "2023-11-02T03:40:41.619476Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 1s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "final_spikes = final_spikes.reshape(final_spikes.shape[0], 70, 3)\n",
    "predictions = model.predict(final_spikes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T03:40:43.369759300Z",
     "start_time": "2023-11-02T03:40:42.326787800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2198,)\n",
      "(91,)\n"
     ]
    }
   ],
   "source": [
    "actual_pred = np.empty(predictions.shape[0])\n",
    "for index in range(predictions.shape[0]):\n",
    "    actual_pred[index] = np.argmax(predictions[index])\n",
    "print(actual_pred.shape)\n",
    "print(events_start.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T03:40:45.011384500Z",
     "start_time": "2023-11-02T03:40:44.885253200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "window = 70\n",
    "num_windows = np.empty(events_start.shape)\n",
    "for index in range(events_start.size):\n",
    "    length = events_end[index] - events_start[index] + 1\n",
    "    num_windows[index] = (length // window) + 1\n",
    "\n",
    "event_prediction = np.empty(0)\n",
    "i = 0\n",
    "for index in range(num_windows.size):\n",
    "    cur_index = num_windows[index]\n",
    "    # for prediction_index in range(i, i + int(cur_index)):\n",
    "    event_prediction = np.append(event_prediction, mode(actual_pred[i : i + int(cur_index)]))\n",
    "    i += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T03:40:46.400919700Z",
     "start_time": "2023-11-02T03:40:46.294073400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2198,)\n",
      "(91,)\n",
      "(91,)\n"
     ]
    }
   ],
   "source": [
    "print(actual_pred.shape)\n",
    "print(events_start.shape)\n",
    "print(event_prediction.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T03:40:47.563203100Z",
     "start_time": "2023-11-02T03:40:47.465786500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualize test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          44.609250\n",
      "1          44.741972\n",
      "2          43.994370\n",
      "3          44.547050\n",
      "4          44.816486\n",
      "             ...    \n",
      "347392    225.158724\n",
      "347393    225.853297\n",
      "347394    224.763465\n",
      "347395    224.921932\n",
      "347396    224.974290\n",
      "Name: Phase1_actual, Length: 347397, dtype: float64\n",
      "0         141.325929\n",
      "1         142.068482\n",
      "2         142.154960\n",
      "3         141.547647\n",
      "4         141.517839\n",
      "             ...    \n",
      "347392     90.274768\n",
      "347393     92.224210\n",
      "347394     89.412939\n",
      "347395     90.826572\n",
      "347396     90.549541\n",
      "Name: Phase2_actual, Length: 347397, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "L1 = test[\"Phase1_actual\"]\n",
    "L2 = test[\"Phase2_actual\"]\n",
    "print(L1)\n",
    "print(L2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T03:40:50.049753200Z",
     "start_time": "2023-11-02T03:40:49.948969900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node sequential/conv1d/Conv1D defined at (most recent call last):\n  File \"C:\\Users\\test\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n\n  File \"C:\\Users\\test\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 1053, in launch_instance\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\Users\\test\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n\n  File \"C:\\Users\\test\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n\n  File \"C:\\Users\\test\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n\n  File \"C:\\Users\\test\\AppData\\Local\\Temp\\ipykernel_12216\\761125643.py\", line 40, in <module>\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2631, in predict\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2416, in predict_function\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2401, in step_function\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2389, in run_step\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2357, in predict_step\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 589, in __call__\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\engine\\sequential.py\", line 398, in call\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\engine\\functional.py\", line 515, in call\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\engine\\functional.py\", line 672, in _run_internal_graph\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py\", line 290, in call\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py\", line 262, in convolution_op\n\ninput depth must be evenly divisible by filter depth: 70 vs 3\n\t [[{{node sequential/conv1d/Conv1D}}]] [Op:__inference_predict_function_19154]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[34], line 40\u001B[0m\n\u001B[0;32m     33\u001B[0m test_windows_array \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([\u001B[38;5;28mlist\u001B[39m(window\u001B[38;5;241m.\u001B[39mvalues()) \u001B[38;5;28;01mfor\u001B[39;00m window \u001B[38;5;129;01min\u001B[39;00m test_windows])\n\u001B[0;32m     35\u001B[0m \u001B[38;5;66;03m# Assuming you have already loaded and compiled your trained CNN model\u001B[39;00m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;66;03m# You should load your trained model here if you haven't already\u001B[39;00m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;66;03m# trained_model = load_model('your_model_path')\u001B[39;00m\n\u001B[0;32m     38\u001B[0m \n\u001B[0;32m     39\u001B[0m \u001B[38;5;66;03m# Make predictions on the test data\u001B[39;00m\n\u001B[1;32m---> 40\u001B[0m predictions \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_windows_array\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;66;03m# Define a color map based on the number of unique labels\u001B[39;00m\n\u001B[0;32m     43\u001B[0m num_labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(predictions[\u001B[38;5;241m0\u001B[39m])\n",
      "File \u001B[1;32mC:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32mC:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     53\u001B[0m   \u001B[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001B[39;00m\n\u001B[0;32m     54\u001B[0m   inputs \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     55\u001B[0m       tensor_conversion_registry\u001B[38;5;241m.\u001B[39mconvert(t)\n\u001B[0;32m     56\u001B[0m       \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(t, core_types\u001B[38;5;241m.\u001B[39mTensor)\n\u001B[0;32m     57\u001B[0m       \u001B[38;5;28;01melse\u001B[39;00m t\n\u001B[0;32m     58\u001B[0m       \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m inputs\n\u001B[0;32m     59\u001B[0m   ]\n\u001B[1;32m---> 60\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[0;32m     61\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     63\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mInvalidArgumentError\u001B[0m: Graph execution error:\n\nDetected at node sequential/conv1d/Conv1D defined at (most recent call last):\n  File \"C:\\Users\\test\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n\n  File \"C:\\Users\\test\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 1053, in launch_instance\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\Users\\test\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n\n  File \"C:\\Users\\test\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n\n  File \"C:\\Users\\test\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n\n  File \"C:\\Users\\test\\AppData\\Local\\Temp\\ipykernel_12216\\761125643.py\", line 40, in <module>\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2631, in predict\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2416, in predict_function\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2401, in step_function\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2389, in run_step\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2357, in predict_step\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 589, in __call__\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\engine\\sequential.py\", line 398, in call\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\engine\\functional.py\", line 515, in call\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\engine\\functional.py\", line 672, in _run_internal_graph\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py\", line 290, in call\n\n  File \"C:\\DSAI\\Sustainable-Energy-Behavior\\venv\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py\", line 262, in convolution_op\n\ninput depth must be evenly divisible by filter depth: 70 vs 3\n\t [[{{node sequential/conv1d/Conv1D}}]] [Op:__inference_predict_function_19154]"
     ]
    }
   ],
   "source": [
    "# Define window size and stride\n",
    "window_size = 70  # Should be the same size you used during training\n",
    "stride = 1\n",
    "\n",
    "# Function to create windows\n",
    "def create_windows(data, window_size, stride):\n",
    "    windows = []\n",
    "    for i in range(0, data.size - window_size + 1, stride):\n",
    "        window = {\n",
    "            'Real': data[i:i + window_size],\n",
    "            'Imaginary': data[i + data.size:i + data.size + window_size],\n",
    "            'Apparent': data[i + 2 * data.size:i + 2 * data.size + window_size]\n",
    "        }\n",
    "        windows.append(window)\n",
    "\n",
    "    return windows\n",
    "\n",
    "# Create windows for the test data\n",
    "test_windows = create_windows(event_prediction, window_size, stride)\n",
    "\n",
    "# Determine the maximum length of data in your dictionaries\n",
    "max_length = max(value.size for window in test_windows for value in window.values())\n",
    "\n",
    "# Pad or truncate data in each dictionary to the maximum length\n",
    "for window in test_windows:\n",
    "    for key in window.keys():\n",
    "        current_length = window[key].size\n",
    "        if current_length < max_length:\n",
    "            padding = max_length - current_length\n",
    "            window[key] = np.pad(window[key], (0, padding), mode='constant', constant_values=0)\n",
    "\n",
    "# Convert test windows to a NumPy array\n",
    "test_windows_array = np.array([list(window.values()) for window in test_windows])\n",
    "\n",
    "# Assuming you have already loaded and compiled your trained CNN model\n",
    "# You should load your trained model here if you haven't already\n",
    "# trained_model = load_model('your_model_path')\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.predict(test_windows_array)\n",
    "\n",
    "# Define a color map based on the number of unique labels\n",
    "num_labels = len(predictions[0])\n",
    "colors = cm.rainbow(np.linspace(0, 1, num_labels))\n",
    "\n",
    "# Plot the predictions with colors based on labels\n",
    "for i, prediction in enumerate(predictions):\n",
    "    label = f\"Window {i + 1}\"\n",
    "    plt.plot(range(len(prediction)), prediction, label=label, color=colors[i % num_labels])\n",
    "\n",
    "# Add labels to the plot\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T03:40:51.707596600Z",
     "start_time": "2023-11-02T03:40:51.038556700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
