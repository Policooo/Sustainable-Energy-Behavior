{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "import random\n",
    "import os\n",
    "\n",
    "import math\n",
    "\n",
    "import pylab as p\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import string\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### First we need to read all the data to the house in question and process the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def process_and_trim(LF1I, LF1V, LF2I, LF2V, TimeTicks1, TimeTicks2):\n",
    "    print(\"Matchine the lengths...\")\n",
    "    min_length = min(len(LF1I), len(LF1V), len(LF2I), len(LF2V))\n",
    "\n",
    "    # Trim the DataFrames to match the size of the smallest DataFrame, this will at most trim one or two entries\n",
    "    LF1I = LF1I.head(min_length)\n",
    "    LF1V = LF1V.head(min_length)\n",
    "    TimeTicks1 = TimeTicks1.head(min_length)\n",
    "    LF2I = LF2I.head(min_length)\n",
    "    LF2V = LF2V.head(min_length)\n",
    "    TimeTicks2 = TimeTicks2.head(min_length)\n",
    "    print(\"Done!\")\n",
    "\n",
    "    print(\"Making volts and amps into complex numbers...\")\n",
    "    LF1V = np.array(LF1V)\n",
    "    LF1I = np.array(LF1I)\n",
    "    LF1V = np.array([[complex(y.replace(\"i\", \"j\")) for y in x] for x in LF1V])\n",
    "    LF1I = np.array([[complex(y.replace(\"i\", \"j\")) for y in x] for x in LF1I])\n",
    "\n",
    "    LF2V = np.array(LF2V)\n",
    "    LF2I = np.array(LF2I)\n",
    "    LF2V = np.array([[complex(y.replace(\"i\", \"j\")) for y in x] for x in LF2V])\n",
    "    LF2I = np.array([[complex(y.replace(\"i\", \"j\")) for y in x] for x in LF2I])\n",
    "    print(\"Done!\")\n",
    "\n",
    "    print(\"Calculating power...\")\n",
    "    L1_P = LF1V * np.conjugate(LF1I)\n",
    "    L2_P = LF2V * np.conjugate(LF2I)\n",
    "\n",
    "    L1_ComplexPower = np.sum(L1_P, axis=1)\n",
    "    L2_ComplexPower = np.sum(L2_P, axis=1)\n",
    "\n",
    "    L1_real = np.real(L1_ComplexPower)\n",
    "    L1_imag = np.imag(L1_ComplexPower)\n",
    "    L1_app = np.abs(L1_ComplexPower)\n",
    "\n",
    "    L2_real = np.real(L2_ComplexPower)\n",
    "    L2_imag = np.imag(L2_ComplexPower)\n",
    "    L2_app = np.abs(L2_ComplexPower)\n",
    "\n",
    "    L1_Pf = np.cos(np.angle(L1_P[:, 0]))\n",
    "    L2_Pf = np.cos(np.angle(L2_P[:, 0]))\n",
    "\n",
    "    L1_actual_power = L1_real * L1_Pf\n",
    "    L2_actual_power = L2_real * L2_Pf\n",
    "\n",
    "    power = L1_actual_power + L2_actual_power[:len(L1_actual_power)]\n",
    "    print(\"Done!\")\n",
    "\n",
    "    return L1_actual_power, L2_actual_power, TimeTicks1, TimeTicks2, power\n",
    "\n",
    "# Directory is the path to the directory where to house's information is\n",
    "def read_files_in_directory(directory):\n",
    "    labels = []\n",
    "    data = []\n",
    "\n",
    "    for root, _, files in os.walk(directory):\n",
    "        if \"Testing\" in root:\n",
    "            continue\n",
    "\n",
    "        day_data = pd.DataFrame()\n",
    "        LF1I = pd.DataFrame()\n",
    "        LF1V = pd.DataFrame()\n",
    "        TimeTicks1 = pd.DataFrame()\n",
    "        LF2I = pd.DataFrame()\n",
    "        LF2V = pd.DataFrame()\n",
    "        TimeTicks2 = pd.DataFrame()\n",
    "        for file in files:\n",
    "            # We don't do anything with these files, so we can just skip\n",
    "            if file == \"TaggingInfo.csv\" or \"HF\" in file:\n",
    "                continue\n",
    "\n",
    "            file_path = os.path.join(root, file)\n",
    "            if file == \"AllTaggingInfo.csv\":\n",
    "                print(\"Added labels\")\n",
    "                labels.append(pd.read_csv(file_path))\n",
    "                continue\n",
    "\n",
    "            if file == \"LF1I.csv\":\n",
    "                LF1I = pd.read_csv(file_path)\n",
    "                continue\n",
    "\n",
    "            if file == \"LF1V.csv\":\n",
    "                LF1V = pd.read_csv(file_path)\n",
    "                continue\n",
    "\n",
    "            if file == \"TimeTicks1.csv\":\n",
    "                TimeTicks1 = pd.read_csv(file_path)\n",
    "                continue\n",
    "\n",
    "            if file == \"LF2I.csv\":\n",
    "                LF2I = pd.read_csv(file_path)\n",
    "                continue\n",
    "\n",
    "            if file == \"LF2V.csv\":\n",
    "                LF2V = pd.read_csv(file_path)\n",
    "                continue\n",
    "\n",
    "            if file == \"TimeTicks2.csv\":\n",
    "                TimeTicks2 = pd.read_csv(file_path)\n",
    "                continue\n",
    "\n",
    "        if not LF1I.empty and not LF1V.empty and not LF2I.empty and not LF2V.empty:\n",
    "            print(f\"{root}: \")\n",
    "            L1_actual_power, L2_actual_power, TimeTicks1, TimeTicks2, power = process_and_trim(LF1I, LF1V, LF2I, LF2V, TimeTicks1, TimeTicks2)\n",
    "            day_data[\"L1_actual_power\"] = L1_actual_power\n",
    "            day_data[\"L2_actual_power\"] = L2_actual_power\n",
    "            day_data[\"TimeTicks1\"] = TimeTicks1\n",
    "            day_data[\"TimeTicks2\"] = TimeTicks2\n",
    "            day_data[\"Power\"] = power\n",
    "            data.append(day_data)\n",
    "\n",
    "    return data, labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added labels\n",
      ".\\dataset\\H1\\Tagged_Training_04_13_1334300401: \n",
      "Matchine the lengths...\n",
      "Done!\n",
      "Making volts and amps into complex numbers...\n",
      "Done!\n",
      "Calculating power...\n",
      "Done!\n",
      ".\\dataset\\H1\\Tagged_Training_10_22_1350889201: \n",
      "Matchine the lengths...\n",
      "Done!\n",
      "Making volts and amps into complex numbers...\n",
      "Done!\n",
      "Calculating power...\n",
      "Done!\n",
      ".\\dataset\\H1\\Tagged_Training_10_23_1350975601: \n",
      "Matchine the lengths...\n",
      "Done!\n",
      "Making volts and amps into complex numbers...\n",
      "Done!\n",
      "Calculating power...\n",
      "Done!\n",
      ".\\dataset\\H1\\Tagged_Training_10_24_1351062001: \n",
      "Matchine the lengths...\n",
      "Done!\n",
      "Making volts and amps into complex numbers...\n",
      "Done!\n",
      "Calculating power...\n",
      "Done!\n",
      ".\\dataset\\H1\\Tagged_Training_10_25_1351148401: \n",
      "Matchine the lengths...\n",
      "Done!\n",
      "Making volts and amps into complex numbers...\n",
      "Done!\n",
      "Calculating power...\n",
      "Done!\n",
      ".\\dataset\\H1\\Tagged_Training_12_27_1356595201: \n",
      "Matchine the lengths...\n",
      "Done!\n",
      "Making volts and amps into complex numbers...\n",
      "Done!\n",
      "Calculating power...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "data, labels = read_files_in_directory(r\".\\dataset\\H1\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ApplianceID               ApplianceName     ON_Time    OFF_Time\n",
      "0             30  Outside Over Garage Lights  1350939540  1350939600\n",
      "1             30  Outside Over Garage Lights  1350939660  1350939720\n",
      "2             30  Outside Over Garage Lights  1350939780  1350939840\n",
      "3             29   Outside Front Door Lights  1350939900  1350939960\n",
      "4             29   Outside Front Door Lights  1350940020  1350940080\n",
      "..           ...                         ...         ...         ...\n",
      "106           32             Portable Vacuum  1334356920  1334357010\n",
      "107            8              Central Vacuum  1334357040  1334357070\n",
      "108           35                     Toaster  1356635820  1356635880\n",
      "109           35                     Toaster  1356635940  1356636000\n",
      "110           35                     Toaster  1356636060  1356636120\n",
      "\n",
      "[111 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(labels[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Now we need to process the data, so that it's in a format that we can give to the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def encode(label, total_labels):\n",
    "    array = np.zeros(total_labels)\n",
    "    array[label - 1] = 1\n",
    "    return array\n",
    "\n",
    "def format_data(power, time_ticks, labels, window):\n",
    "    data = np.empty((len(power) // window, window))\n",
    "    appliances = np.empty((len(power) // window, max(labels[\"ApplianceID\"]) + 1))\n",
    "    time = np.empty((len(power) // window, window))\n",
    "    last_entry_index = 0\n",
    "\n",
    "    for index in range(0, len(power) - window + 1, window):\n",
    "        window_start = index\n",
    "        window_end = index + window\n",
    "\n",
    "        found = False\n",
    "        for label in labels.iterrows():\n",
    "            label = label[1]\n",
    "            start_time = time_ticks[window_start].item()\n",
    "            end_time = time_ticks[window_end].item()\n",
    "\n",
    "            if label[\"ON_Time\"] <= start_time <= label[\"OFF_Time\"] or label[\"ON_Time\"] <= end_time <= label[\"OFF_Time\"]:\n",
    "                found = True\n",
    "                data[last_entry_index] = power[window_start:window_end]\n",
    "                time[last_entry_index] = time_ticks[window_start:window_end]\n",
    "                appliances[last_entry_index] = encode(label[\"ApplianceID\"], max(labels[\"ApplianceID\"]))\n",
    "                last_entry_index += 1\n",
    "                break\n",
    "\n",
    "        # if not found:\n",
    "        #     chance = random.random()\n",
    "        #     if chance > 0.99:\n",
    "        #         data[last_entry_index] = power[window_start:window_end].reshape(window)\n",
    "        #         time[last_entry_index] = time_ticks[window_start:window_end].reshape(window)\n",
    "        #         appliances[last_entry_index] = encode(0, max(labels[\"ApplianceID\"]))\n",
    "        #         last_entry_index += 1\n",
    "\n",
    "    return data[:last_entry_index], time[:last_entry_index], appliances[:last_entry_index]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[33], line 7\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m datapoint, label \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(data, labels):\n\u001B[0;32m      6\u001B[0m     training_datapoint, time_datapoint, appliances_datapoint \u001B[38;5;241m=\u001B[39m format_data(datapoint[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPower\u001B[39m\u001B[38;5;124m\"\u001B[39m], datapoint[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTimeTicks1\u001B[39m\u001B[38;5;124m\"\u001B[39m], label, \u001B[38;5;241m10\u001B[39m)\n\u001B[1;32m----> 7\u001B[0m     training_data \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhstack\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtraining_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining_datapoint\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m     time \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mhstack((time, time_datapoint))\n\u001B[0;32m      9\u001B[0m     appliances \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mhstack((appliances, appliances_datapoint))\n",
      "File \u001B[1;32m~\\PycharmProjects\\Sustainable-Energy-Behavior\\venv\\Lib\\site-packages\\numpy\\core\\shape_base.py:357\u001B[0m, in \u001B[0;36mhstack\u001B[1;34m(tup, dtype, casting)\u001B[0m\n\u001B[0;32m    355\u001B[0m \u001B[38;5;66;03m# As a special case, dimension 0 of 1-dimensional arrays is \"horizontal\"\u001B[39;00m\n\u001B[0;32m    356\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m arrs \u001B[38;5;129;01mand\u001B[39;00m arrs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m--> 357\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_nx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcatenate\u001B[49m\u001B[43m(\u001B[49m\u001B[43marrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcasting\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcasting\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    358\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    359\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _nx\u001B[38;5;241m.\u001B[39mconcatenate(arrs, \u001B[38;5;241m1\u001B[39m, dtype\u001B[38;5;241m=\u001B[39mdtype, casting\u001B[38;5;241m=\u001B[39mcasting)\n",
      "\u001B[1;31mValueError\u001B[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)"
     ]
    }
   ],
   "source": [
    "training_data = np.empty(0)\n",
    "time = np.empty(0)\n",
    "appliances = np.empty(0)\n",
    "\n",
    "for datapoint, label in zip(data, labels):\n",
    "    training_datapoint, time_datapoint, appliances_datapoint = format_data(datapoint[\"Power\"], datapoint[\"TimeTicks1\"], label, 10)\n",
    "    training_data = np.hstack((training_data, training_datapoint))\n",
    "    time = np.hstack((time, time_datapoint))\n",
    "    appliances = np.hstack((appliances, appliances_datapoint))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(appliances)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Build the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=2, activation=\"relu\", input_shape=(10, 1)))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(39, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(training_data, appliances)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "6/6 [==============================] - 2s 63ms/step - loss: 18.1732 - accuracy: 0.2124 - val_loss: 9.9426 - val_accuracy: 0.1724\n",
      "Epoch 2/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.0128 - accuracy: 0.4093 - val_loss: 4.3009 - val_accuracy: 0.0460\n",
      "Epoch 3/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.0205 - accuracy: 0.3320 - val_loss: 4.7060 - val_accuracy: 0.5172\n",
      "Epoch 4/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.9049 - accuracy: 0.3861 - val_loss: 4.2092 - val_accuracy: 0.5172\n",
      "Epoch 5/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.7991 - accuracy: 0.4672 - val_loss: 3.5969 - val_accuracy: 0.5057\n",
      "Epoch 6/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.4666 - accuracy: 0.4672 - val_loss: 3.8843 - val_accuracy: 0.5172\n",
      "Epoch 7/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.4464 - accuracy: 0.4247 - val_loss: 3.5271 - val_accuracy: 0.3103\n",
      "Epoch 8/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.3032 - accuracy: 0.5019 - val_loss: 3.2382 - val_accuracy: 0.3333\n",
      "Epoch 9/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.2529 - accuracy: 0.6139 - val_loss: 3.2130 - val_accuracy: 0.3333\n",
      "Epoch 10/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.3901 - accuracy: 0.4826 - val_loss: 3.2645 - val_accuracy: 0.3333\n",
      "Epoch 11/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.3753 - accuracy: 0.4672 - val_loss: 4.5493 - val_accuracy: 0.5517\n",
      "Epoch 12/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.4731 - accuracy: 0.4633 - val_loss: 3.6282 - val_accuracy: 0.5747\n",
      "Epoch 13/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.3565 - accuracy: 0.5328 - val_loss: 3.8766 - val_accuracy: 0.6552\n",
      "Epoch 14/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.2547 - accuracy: 0.5174 - val_loss: 3.9424 - val_accuracy: 0.3333\n",
      "Epoch 15/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.2236 - accuracy: 0.6255 - val_loss: 3.5102 - val_accuracy: 0.3103\n",
      "Epoch 16/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.2866 - accuracy: 0.4633 - val_loss: 3.2956 - val_accuracy: 0.6437\n",
      "Epoch 17/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.1719 - accuracy: 0.6834 - val_loss: 3.7347 - val_accuracy: 0.5632\n",
      "Epoch 18/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.2707 - accuracy: 0.5058 - val_loss: 3.3011 - val_accuracy: 0.6322\n",
      "Epoch 19/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.1980 - accuracy: 0.7027 - val_loss: 3.0524 - val_accuracy: 0.6782\n",
      "Epoch 20/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0778 - accuracy: 0.7452 - val_loss: 3.1238 - val_accuracy: 0.6207\n",
      "Epoch 21/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0216 - accuracy: 0.7722 - val_loss: 3.4408 - val_accuracy: 0.7241\n",
      "Epoch 22/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.0491 - accuracy: 0.7722 - val_loss: 3.6025 - val_accuracy: 0.7356\n",
      "Epoch 23/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.0008 - accuracy: 0.7683 - val_loss: 3.3772 - val_accuracy: 0.6207\n",
      "Epoch 24/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.0221 - accuracy: 0.7027 - val_loss: 3.4395 - val_accuracy: 0.7471\n",
      "Epoch 25/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9569 - accuracy: 0.7568 - val_loss: 3.5498 - val_accuracy: 0.7471\n",
      "Epoch 26/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.9171 - accuracy: 0.7761 - val_loss: 3.3643 - val_accuracy: 0.7471\n",
      "Epoch 27/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.9893 - accuracy: 0.7529 - val_loss: 3.5218 - val_accuracy: 0.7241\n",
      "Epoch 28/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.9518 - accuracy: 0.7568 - val_loss: 3.8105 - val_accuracy: 0.6207\n",
      "Epoch 29/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.0041 - accuracy: 0.7143 - val_loss: 3.6789 - val_accuracy: 0.7356\n",
      "Epoch 30/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.9357 - accuracy: 0.7529 - val_loss: 3.7129 - val_accuracy: 0.7471\n",
      "Epoch 31/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8772 - accuracy: 0.8147 - val_loss: 4.1286 - val_accuracy: 0.6322\n",
      "Epoch 32/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.0381 - accuracy: 0.7490 - val_loss: 3.6283 - val_accuracy: 0.6437\n",
      "Epoch 33/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.9726 - accuracy: 0.7375 - val_loss: 3.2357 - val_accuracy: 0.7471\n",
      "Epoch 34/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9154 - accuracy: 0.7645 - val_loss: 3.0846 - val_accuracy: 0.7241\n",
      "Epoch 35/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9091 - accuracy: 0.7645 - val_loss: 3.3465 - val_accuracy: 0.7356\n",
      "Epoch 36/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.9191 - accuracy: 0.7799 - val_loss: 3.2324 - val_accuracy: 0.7471\n",
      "Epoch 37/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8718 - accuracy: 0.8185 - val_loss: 3.3639 - val_accuracy: 0.7471\n",
      "Epoch 38/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8571 - accuracy: 0.7915 - val_loss: 3.4234 - val_accuracy: 0.7356\n",
      "Epoch 39/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8817 - accuracy: 0.7645 - val_loss: 3.3734 - val_accuracy: 0.7471\n",
      "Epoch 40/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8187 - accuracy: 0.8224 - val_loss: 3.4772 - val_accuracy: 0.7471\n",
      "Epoch 41/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8352 - accuracy: 0.7722 - val_loss: 3.4513 - val_accuracy: 0.7471\n",
      "Epoch 42/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8719 - accuracy: 0.7761 - val_loss: 3.5870 - val_accuracy: 0.7471\n",
      "Epoch 43/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8606 - accuracy: 0.8069 - val_loss: 3.4068 - val_accuracy: 0.7471\n",
      "Epoch 44/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8533 - accuracy: 0.7606 - val_loss: 3.4175 - val_accuracy: 0.7471\n",
      "Epoch 45/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8274 - accuracy: 0.7722 - val_loss: 3.4788 - val_accuracy: 0.7471\n",
      "Epoch 46/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.7819 - accuracy: 0.8108 - val_loss: 3.4942 - val_accuracy: 0.7471\n",
      "Epoch 47/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.7899 - accuracy: 0.8147 - val_loss: 3.5888 - val_accuracy: 0.7471\n",
      "Epoch 48/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8064 - accuracy: 0.7876 - val_loss: 3.8155 - val_accuracy: 0.7126\n",
      "Epoch 49/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9149 - accuracy: 0.7529 - val_loss: 3.7865 - val_accuracy: 0.7241\n",
      "Epoch 50/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8260 - accuracy: 0.7799 - val_loss: 3.8127 - val_accuracy: 0.7471\n",
      "Epoch 51/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8346 - accuracy: 0.7876 - val_loss: 4.0510 - val_accuracy: 0.6437\n",
      "Epoch 52/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.7853 - accuracy: 0.7876 - val_loss: 3.9312 - val_accuracy: 0.7471\n",
      "Epoch 53/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.7785 - accuracy: 0.7915 - val_loss: 4.1042 - val_accuracy: 0.7471\n",
      "Epoch 54/500\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7588 - accuracy: 0.8224 - val_loss: 4.3168 - val_accuracy: 0.7471\n",
      "Epoch 55/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.7533 - accuracy: 0.8185 - val_loss: 4.2873 - val_accuracy: 0.7471\n",
      "Epoch 56/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.7583 - accuracy: 0.7876 - val_loss: 4.3397 - val_accuracy: 0.7471\n",
      "Epoch 57/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.7410 - accuracy: 0.8185 - val_loss: 4.4334 - val_accuracy: 0.7471\n",
      "Epoch 58/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7389 - accuracy: 0.8224 - val_loss: 4.5872 - val_accuracy: 0.7471\n",
      "Epoch 59/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7016 - accuracy: 0.8224 - val_loss: 4.6580 - val_accuracy: 0.7471\n",
      "Epoch 60/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.7660 - accuracy: 0.7954 - val_loss: 4.7866 - val_accuracy: 0.7471\n",
      "Epoch 61/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.7973 - accuracy: 0.7838 - val_loss: 5.0158 - val_accuracy: 0.7356\n",
      "Epoch 62/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8379 - accuracy: 0.7568 - val_loss: 4.9549 - val_accuracy: 0.7241\n",
      "Epoch 63/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8080 - accuracy: 0.7915 - val_loss: 5.1287 - val_accuracy: 0.7471\n",
      "Epoch 64/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.7929 - accuracy: 0.7683 - val_loss: 4.7161 - val_accuracy: 0.7471\n",
      "Epoch 65/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.7570 - accuracy: 0.8224 - val_loss: 4.9600 - val_accuracy: 0.6092\n",
      "Epoch 66/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.9207 - accuracy: 0.7297 - val_loss: 5.0810 - val_accuracy: 0.7011\n",
      "Epoch 67/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8754 - accuracy: 0.7606 - val_loss: 5.0530 - val_accuracy: 0.7471\n",
      "Epoch 68/500\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.7981 - accuracy: 0.7761 - val_loss: 5.4740 - val_accuracy: 0.7241\n",
      "Epoch 69/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8321 - accuracy: 0.7992 - val_loss: 5.8087 - val_accuracy: 0.7356\n",
      "Epoch 70/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8574 - accuracy: 0.7683 - val_loss: 5.6372 - val_accuracy: 0.7241\n",
      "Epoch 71/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8260 - accuracy: 0.7799 - val_loss: 5.7937 - val_accuracy: 0.7356\n",
      "Epoch 72/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8087 - accuracy: 0.7915 - val_loss: 5.8041 - val_accuracy: 0.7471\n",
      "Epoch 73/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.7596 - accuracy: 0.7992 - val_loss: 6.1919 - val_accuracy: 0.7241\n",
      "Epoch 74/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.7529 - accuracy: 0.8069 - val_loss: 6.3079 - val_accuracy: 0.7356\n",
      "Epoch 75/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.7062 - accuracy: 0.8224 - val_loss: 6.4291 - val_accuracy: 0.7471\n",
      "Epoch 76/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.7340 - accuracy: 0.8069 - val_loss: 6.5110 - val_accuracy: 0.7471\n",
      "Epoch 77/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.7217 - accuracy: 0.8224 - val_loss: 6.3978 - val_accuracy: 0.7471\n",
      "Epoch 78/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.7089 - accuracy: 0.8108 - val_loss: 6.5439 - val_accuracy: 0.7471\n",
      "Epoch 79/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6864 - accuracy: 0.8224 - val_loss: 6.6945 - val_accuracy: 0.7471\n",
      "Epoch 80/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6912 - accuracy: 0.8224 - val_loss: 6.5035 - val_accuracy: 0.6897\n",
      "Epoch 81/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.7357 - accuracy: 0.7568 - val_loss: 6.5403 - val_accuracy: 0.7471\n",
      "Epoch 82/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.7050 - accuracy: 0.8185 - val_loss: 6.3926 - val_accuracy: 0.7471\n",
      "Epoch 83/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6955 - accuracy: 0.8147 - val_loss: 6.4605 - val_accuracy: 0.7356\n",
      "Epoch 84/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.7021 - accuracy: 0.8185 - val_loss: 6.5360 - val_accuracy: 0.6552\n",
      "Epoch 85/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.7233 - accuracy: 0.7838 - val_loss: 6.4048 - val_accuracy: 0.7471\n",
      "Epoch 86/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.7449 - accuracy: 0.7799 - val_loss: 6.8302 - val_accuracy: 0.7356\n",
      "Epoch 87/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.7495 - accuracy: 0.7954 - val_loss: 6.6758 - val_accuracy: 0.7471\n",
      "Epoch 88/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6899 - accuracy: 0.8185 - val_loss: 6.8185 - val_accuracy: 0.7471\n",
      "Epoch 89/500\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6872 - accuracy: 0.8224 - val_loss: 7.0102 - val_accuracy: 0.7471\n",
      "Epoch 90/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6763 - accuracy: 0.8185 - val_loss: 7.1582 - val_accuracy: 0.7471\n",
      "Epoch 91/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6798 - accuracy: 0.8185 - val_loss: 7.1091 - val_accuracy: 0.7471\n",
      "Epoch 92/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6803 - accuracy: 0.8185 - val_loss: 7.1934 - val_accuracy: 0.7471\n",
      "Epoch 93/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6659 - accuracy: 0.8224 - val_loss: 7.0725 - val_accuracy: 0.7471\n",
      "Epoch 94/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6563 - accuracy: 0.8224 - val_loss: 7.0980 - val_accuracy: 0.7471\n",
      "Epoch 95/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6529 - accuracy: 0.8224 - val_loss: 7.1732 - val_accuracy: 0.7471\n",
      "Epoch 96/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6566 - accuracy: 0.8224 - val_loss: 7.3600 - val_accuracy: 0.7471\n",
      "Epoch 97/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6813 - accuracy: 0.8224 - val_loss: 7.4013 - val_accuracy: 0.7471\n",
      "Epoch 98/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6574 - accuracy: 0.8185 - val_loss: 7.7562 - val_accuracy: 0.7471\n",
      "Epoch 99/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6614 - accuracy: 0.8224 - val_loss: 8.2863 - val_accuracy: 0.7471\n",
      "Epoch 100/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6845 - accuracy: 0.8224 - val_loss: 8.0797 - val_accuracy: 0.7471\n",
      "Epoch 101/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6648 - accuracy: 0.8224 - val_loss: 8.0707 - val_accuracy: 0.7471\n",
      "Epoch 102/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6911 - accuracy: 0.7954 - val_loss: 7.9971 - val_accuracy: 0.7471\n",
      "Epoch 103/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.7163 - accuracy: 0.8108 - val_loss: 8.2737 - val_accuracy: 0.7471\n",
      "Epoch 104/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6860 - accuracy: 0.8185 - val_loss: 8.1452 - val_accuracy: 0.7471\n",
      "Epoch 105/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6651 - accuracy: 0.8224 - val_loss: 8.0373 - val_accuracy: 0.7471\n",
      "Epoch 106/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6831 - accuracy: 0.8224 - val_loss: 8.3718 - val_accuracy: 0.7471\n",
      "Epoch 107/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7132 - accuracy: 0.7683 - val_loss: 8.7583 - val_accuracy: 0.7471\n",
      "Epoch 108/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6800 - accuracy: 0.8224 - val_loss: 9.3377 - val_accuracy: 0.7471\n",
      "Epoch 109/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6777 - accuracy: 0.8224 - val_loss: 9.5154 - val_accuracy: 0.7471\n",
      "Epoch 110/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.7009 - accuracy: 0.8185 - val_loss: 9.0558 - val_accuracy: 0.7471\n",
      "Epoch 111/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6579 - accuracy: 0.8224 - val_loss: 8.9659 - val_accuracy: 0.7471\n",
      "Epoch 112/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6583 - accuracy: 0.8224 - val_loss: 9.0788 - val_accuracy: 0.7471\n",
      "Epoch 113/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6509 - accuracy: 0.8224 - val_loss: 9.1351 - val_accuracy: 0.7471\n",
      "Epoch 114/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6461 - accuracy: 0.8224 - val_loss: 9.0517 - val_accuracy: 0.7471\n",
      "Epoch 115/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6359 - accuracy: 0.8224 - val_loss: 9.2360 - val_accuracy: 0.7471\n",
      "Epoch 116/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6337 - accuracy: 0.8224 - val_loss: 9.3302 - val_accuracy: 0.7471\n",
      "Epoch 117/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6287 - accuracy: 0.8224 - val_loss: 9.4668 - val_accuracy: 0.7471\n",
      "Epoch 118/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6436 - accuracy: 0.8224 - val_loss: 9.5707 - val_accuracy: 0.7471\n",
      "Epoch 119/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6445 - accuracy: 0.8224 - val_loss: 9.5166 - val_accuracy: 0.7471\n",
      "Epoch 120/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6330 - accuracy: 0.8185 - val_loss: 9.3554 - val_accuracy: 0.7471\n",
      "Epoch 121/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6335 - accuracy: 0.8224 - val_loss: 9.3686 - val_accuracy: 0.7471\n",
      "Epoch 122/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6431 - accuracy: 0.8224 - val_loss: 9.2673 - val_accuracy: 0.7471\n",
      "Epoch 123/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6362 - accuracy: 0.8224 - val_loss: 9.2753 - val_accuracy: 0.7471\n",
      "Epoch 124/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6374 - accuracy: 0.8224 - val_loss: 9.2489 - val_accuracy: 0.7471\n",
      "Epoch 125/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6253 - accuracy: 0.8224 - val_loss: 9.2280 - val_accuracy: 0.7471\n",
      "Epoch 126/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6377 - accuracy: 0.8263 - val_loss: 9.3551 - val_accuracy: 0.7471\n",
      "Epoch 127/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6286 - accuracy: 0.8224 - val_loss: 9.3573 - val_accuracy: 0.7471\n",
      "Epoch 128/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6339 - accuracy: 0.8224 - val_loss: 9.1184 - val_accuracy: 0.7471\n",
      "Epoch 129/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6238 - accuracy: 0.8224 - val_loss: 9.2871 - val_accuracy: 0.7356\n",
      "Epoch 130/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6526 - accuracy: 0.8224 - val_loss: 9.3154 - val_accuracy: 0.7471\n",
      "Epoch 131/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6276 - accuracy: 0.8224 - val_loss: 9.5690 - val_accuracy: 0.7471\n",
      "Epoch 132/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6169 - accuracy: 0.8224 - val_loss: 9.8775 - val_accuracy: 0.7471\n",
      "Epoch 133/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6295 - accuracy: 0.8224 - val_loss: 9.7307 - val_accuracy: 0.7471\n",
      "Epoch 134/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6184 - accuracy: 0.8224 - val_loss: 10.0185 - val_accuracy: 0.7471\n",
      "Epoch 135/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6165 - accuracy: 0.8224 - val_loss: 10.1743 - val_accuracy: 0.7471\n",
      "Epoch 136/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6130 - accuracy: 0.8224 - val_loss: 9.9752 - val_accuracy: 0.7471\n",
      "Epoch 137/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6091 - accuracy: 0.8224 - val_loss: 9.6097 - val_accuracy: 0.7471\n",
      "Epoch 138/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6271 - accuracy: 0.8224 - val_loss: 9.4321 - val_accuracy: 0.7471\n",
      "Epoch 139/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6285 - accuracy: 0.8224 - val_loss: 9.3871 - val_accuracy: 0.7471\n",
      "Epoch 140/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6264 - accuracy: 0.8224 - val_loss: 8.9237 - val_accuracy: 0.7356\n",
      "Epoch 141/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6116 - accuracy: 0.8224 - val_loss: 9.1778 - val_accuracy: 0.7471\n",
      "Epoch 142/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6086 - accuracy: 0.8224 - val_loss: 9.5294 - val_accuracy: 0.7471\n",
      "Epoch 143/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6000 - accuracy: 0.8224 - val_loss: 9.3365 - val_accuracy: 0.7471\n",
      "Epoch 144/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6024 - accuracy: 0.8224 - val_loss: 9.2663 - val_accuracy: 0.7471\n",
      "Epoch 145/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6042 - accuracy: 0.8224 - val_loss: 9.3246 - val_accuracy: 0.7471\n",
      "Epoch 146/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5964 - accuracy: 0.8224 - val_loss: 9.3326 - val_accuracy: 0.7471\n",
      "Epoch 147/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5995 - accuracy: 0.8224 - val_loss: 9.2746 - val_accuracy: 0.7471\n",
      "Epoch 148/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5936 - accuracy: 0.8224 - val_loss: 9.3994 - val_accuracy: 0.7471\n",
      "Epoch 149/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6160 - accuracy: 0.8224 - val_loss: 9.5022 - val_accuracy: 0.7471\n",
      "Epoch 150/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6150 - accuracy: 0.8224 - val_loss: 9.3644 - val_accuracy: 0.7471\n",
      "Epoch 151/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6086 - accuracy: 0.8224 - val_loss: 9.2020 - val_accuracy: 0.7471\n",
      "Epoch 152/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6166 - accuracy: 0.8185 - val_loss: 9.4523 - val_accuracy: 0.7356\n",
      "Epoch 153/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7270 - accuracy: 0.7799 - val_loss: 9.0247 - val_accuracy: 0.7356\n",
      "Epoch 154/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8109 - accuracy: 0.7722 - val_loss: 8.5308 - val_accuracy: 0.6667\n",
      "Epoch 155/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.0191 - accuracy: 0.6834 - val_loss: 10.5676 - val_accuracy: 0.6322\n",
      "Epoch 156/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.4821 - accuracy: 0.5753 - val_loss: 9.9668 - val_accuracy: 0.6207\n",
      "Epoch 157/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9596 - accuracy: 0.7683 - val_loss: 8.3647 - val_accuracy: 0.7126\n",
      "Epoch 158/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.5002 - accuracy: 0.5174 - val_loss: 7.3407 - val_accuracy: 0.6207\n",
      "Epoch 159/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8618 - accuracy: 0.7606 - val_loss: 6.4855 - val_accuracy: 0.7126\n",
      "Epoch 160/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6921 - accuracy: 0.8147 - val_loss: 6.3039 - val_accuracy: 0.6782\n",
      "Epoch 161/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8743 - accuracy: 0.7683 - val_loss: 5.3307 - val_accuracy: 0.6552\n",
      "Epoch 162/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.7816 - accuracy: 0.7876 - val_loss: 6.2919 - val_accuracy: 0.7356\n",
      "Epoch 163/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.7216 - accuracy: 0.8147 - val_loss: 6.3928 - val_accuracy: 0.7356\n",
      "Epoch 164/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6813 - accuracy: 0.8224 - val_loss: 6.6002 - val_accuracy: 0.7471\n",
      "Epoch 165/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6587 - accuracy: 0.8224 - val_loss: 6.6506 - val_accuracy: 0.7471\n",
      "Epoch 166/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6631 - accuracy: 0.8185 - val_loss: 7.2382 - val_accuracy: 0.7471\n",
      "Epoch 167/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6460 - accuracy: 0.8224 - val_loss: 7.6585 - val_accuracy: 0.7471\n",
      "Epoch 168/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6547 - accuracy: 0.8224 - val_loss: 7.6554 - val_accuracy: 0.7471\n",
      "Epoch 169/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6102 - accuracy: 0.8224 - val_loss: 7.6949 - val_accuracy: 0.7471\n",
      "Epoch 170/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5975 - accuracy: 0.8224 - val_loss: 7.9450 - val_accuracy: 0.7471\n",
      "Epoch 171/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5967 - accuracy: 0.8224 - val_loss: 7.8836 - val_accuracy: 0.7471\n",
      "Epoch 172/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5915 - accuracy: 0.8224 - val_loss: 7.9671 - val_accuracy: 0.7471\n",
      "Epoch 173/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5905 - accuracy: 0.8224 - val_loss: 7.9209 - val_accuracy: 0.7471\n",
      "Epoch 174/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6090 - accuracy: 0.8031 - val_loss: 7.8896 - val_accuracy: 0.7471\n",
      "Epoch 175/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5727 - accuracy: 0.8224 - val_loss: 7.9955 - val_accuracy: 0.7471\n",
      "Epoch 176/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5749 - accuracy: 0.8224 - val_loss: 8.0018 - val_accuracy: 0.7471\n",
      "Epoch 177/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5699 - accuracy: 0.8224 - val_loss: 8.0396 - val_accuracy: 0.7471\n",
      "Epoch 178/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5639 - accuracy: 0.8224 - val_loss: 7.8367 - val_accuracy: 0.7471\n",
      "Epoch 179/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5786 - accuracy: 0.8224 - val_loss: 7.9026 - val_accuracy: 0.7471\n",
      "Epoch 180/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5742 - accuracy: 0.8224 - val_loss: 7.7113 - val_accuracy: 0.7471\n",
      "Epoch 181/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5634 - accuracy: 0.8185 - val_loss: 7.6998 - val_accuracy: 0.7471\n",
      "Epoch 182/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5724 - accuracy: 0.8185 - val_loss: 7.1189 - val_accuracy: 0.7471\n",
      "Epoch 183/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5567 - accuracy: 0.8224 - val_loss: 6.9489 - val_accuracy: 0.7471\n",
      "Epoch 184/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5641 - accuracy: 0.8224 - val_loss: 7.1941 - val_accuracy: 0.7471\n",
      "Epoch 185/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5546 - accuracy: 0.8224 - val_loss: 7.4569 - val_accuracy: 0.7471\n",
      "Epoch 186/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5487 - accuracy: 0.8224 - val_loss: 7.2791 - val_accuracy: 0.7471\n",
      "Epoch 187/500\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5409 - accuracy: 0.8224 - val_loss: 7.3600 - val_accuracy: 0.7471\n",
      "Epoch 188/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5306 - accuracy: 0.8224 - val_loss: 7.8429 - val_accuracy: 0.7471\n",
      "Epoch 189/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5196 - accuracy: 0.8224 - val_loss: 8.1512 - val_accuracy: 0.7356\n",
      "Epoch 190/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5435 - accuracy: 0.8224 - val_loss: 8.0947 - val_accuracy: 0.7356\n",
      "Epoch 191/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5060 - accuracy: 0.8224 - val_loss: 8.2336 - val_accuracy: 0.7356\n",
      "Epoch 192/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5211 - accuracy: 0.8301 - val_loss: 8.1957 - val_accuracy: 0.7356\n",
      "Epoch 193/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4924 - accuracy: 0.8340 - val_loss: 8.3204 - val_accuracy: 0.7356\n",
      "Epoch 194/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4987 - accuracy: 0.8301 - val_loss: 8.2045 - val_accuracy: 0.7471\n",
      "Epoch 195/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4723 - accuracy: 0.8263 - val_loss: 8.5387 - val_accuracy: 0.7356\n",
      "Epoch 196/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4634 - accuracy: 0.8301 - val_loss: 8.6031 - val_accuracy: 0.7356\n",
      "Epoch 197/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4643 - accuracy: 0.8417 - val_loss: 8.6267 - val_accuracy: 0.7356\n",
      "Epoch 198/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4661 - accuracy: 0.8378 - val_loss: 8.7675 - val_accuracy: 0.7471\n",
      "Epoch 199/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4282 - accuracy: 0.8533 - val_loss: 8.7413 - val_accuracy: 0.7471\n",
      "Epoch 200/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4206 - accuracy: 0.8571 - val_loss: 8.8421 - val_accuracy: 0.7471\n",
      "Epoch 201/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4345 - accuracy: 0.8533 - val_loss: 9.0276 - val_accuracy: 0.7356\n",
      "Epoch 202/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4581 - accuracy: 0.8378 - val_loss: 8.9656 - val_accuracy: 0.7471\n",
      "Epoch 203/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4244 - accuracy: 0.8571 - val_loss: 9.0540 - val_accuracy: 0.7471\n",
      "Epoch 204/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4037 - accuracy: 0.8533 - val_loss: 9.2489 - val_accuracy: 0.7356\n",
      "Epoch 205/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4466 - accuracy: 0.8340 - val_loss: 9.0722 - val_accuracy: 0.7356\n",
      "Epoch 206/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4316 - accuracy: 0.8494 - val_loss: 9.8120 - val_accuracy: 0.7356\n",
      "Epoch 207/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4107 - accuracy: 0.8571 - val_loss: 9.9511 - val_accuracy: 0.7356\n",
      "Epoch 208/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4196 - accuracy: 0.8610 - val_loss: 9.9653 - val_accuracy: 0.7356\n",
      "Epoch 209/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4444 - accuracy: 0.8494 - val_loss: 10.5551 - val_accuracy: 0.7356\n",
      "Epoch 210/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4201 - accuracy: 0.8494 - val_loss: 11.4698 - val_accuracy: 0.5057\n",
      "Epoch 211/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8768 - accuracy: 0.7413 - val_loss: 11.1095 - val_accuracy: 0.7356\n",
      "Epoch 212/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8988 - accuracy: 0.8108 - val_loss: 9.6667 - val_accuracy: 0.7126\n",
      "Epoch 213/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.8370 - accuracy: 0.7954 - val_loss: 7.6577 - val_accuracy: 0.6667\n",
      "Epoch 214/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.8792 - accuracy: 0.7375 - val_loss: 8.3935 - val_accuracy: 0.5747\n",
      "Epoch 215/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.7982 - accuracy: 0.7799 - val_loss: 5.6156 - val_accuracy: 0.7356\n",
      "Epoch 216/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5848 - accuracy: 0.8456 - val_loss: 7.8340 - val_accuracy: 0.7126\n",
      "Epoch 217/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5606 - accuracy: 0.8301 - val_loss: 8.5745 - val_accuracy: 0.7586\n",
      "Epoch 218/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5060 - accuracy: 0.8340 - val_loss: 9.1894 - val_accuracy: 0.7241\n",
      "Epoch 219/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6449 - accuracy: 0.8224 - val_loss: 10.3104 - val_accuracy: 0.7126\n",
      "Epoch 220/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.7568 - accuracy: 0.7992 - val_loss: 12.1870 - val_accuracy: 0.7356\n",
      "Epoch 221/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6724 - accuracy: 0.8185 - val_loss: 12.2564 - val_accuracy: 0.6897\n",
      "Epoch 222/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6688 - accuracy: 0.7683 - val_loss: 12.3278 - val_accuracy: 0.7241\n",
      "Epoch 223/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5858 - accuracy: 0.8108 - val_loss: 9.9896 - val_accuracy: 0.7471\n",
      "Epoch 224/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5833 - accuracy: 0.8301 - val_loss: 9.9244 - val_accuracy: 0.7241\n",
      "Epoch 225/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6210 - accuracy: 0.8147 - val_loss: 10.5350 - val_accuracy: 0.7471\n",
      "Epoch 226/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.5215 - accuracy: 0.8340 - val_loss: 10.4551 - val_accuracy: 0.7471\n",
      "Epoch 227/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4829 - accuracy: 0.8456 - val_loss: 10.6118 - val_accuracy: 0.7701\n",
      "Epoch 228/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4529 - accuracy: 0.8571 - val_loss: 10.9120 - val_accuracy: 0.7356\n",
      "Epoch 229/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4780 - accuracy: 0.8378 - val_loss: 11.2372 - val_accuracy: 0.7356\n",
      "Epoch 230/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4787 - accuracy: 0.8378 - val_loss: 11.1177 - val_accuracy: 0.7356\n",
      "Epoch 231/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6134 - accuracy: 0.8031 - val_loss: 10.9780 - val_accuracy: 0.7241\n",
      "Epoch 232/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5236 - accuracy: 0.8224 - val_loss: 10.9562 - val_accuracy: 0.7126\n",
      "Epoch 233/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4589 - accuracy: 0.8301 - val_loss: 10.4575 - val_accuracy: 0.8046\n",
      "Epoch 234/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4228 - accuracy: 0.8571 - val_loss: 10.5995 - val_accuracy: 0.8161\n",
      "Epoch 235/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4278 - accuracy: 0.8533 - val_loss: 10.7343 - val_accuracy: 0.7471\n",
      "Epoch 236/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4363 - accuracy: 0.8533 - val_loss: 11.0843 - val_accuracy: 0.8161\n",
      "Epoch 237/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4084 - accuracy: 0.8533 - val_loss: 11.4166 - val_accuracy: 0.8046\n",
      "Epoch 238/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4015 - accuracy: 0.8571 - val_loss: 11.5311 - val_accuracy: 0.7586\n",
      "Epoch 239/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4329 - accuracy: 0.8456 - val_loss: 11.3430 - val_accuracy: 0.7471\n",
      "Epoch 240/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4802 - accuracy: 0.8378 - val_loss: 11.3160 - val_accuracy: 0.7471\n",
      "Epoch 241/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4817 - accuracy: 0.7915 - val_loss: 11.4433 - val_accuracy: 0.8046\n",
      "Epoch 242/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4227 - accuracy: 0.8726 - val_loss: 11.5606 - val_accuracy: 0.8046\n",
      "Epoch 243/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4332 - accuracy: 0.8726 - val_loss: 11.0847 - val_accuracy: 0.7931\n",
      "Epoch 244/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3913 - accuracy: 0.8649 - val_loss: 10.9446 - val_accuracy: 0.8046\n",
      "Epoch 245/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3931 - accuracy: 0.8494 - val_loss: 11.1091 - val_accuracy: 0.8046\n",
      "Epoch 246/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4014 - accuracy: 0.8649 - val_loss: 11.4952 - val_accuracy: 0.8161\n",
      "Epoch 247/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3893 - accuracy: 0.8687 - val_loss: 11.6534 - val_accuracy: 0.7816\n",
      "Epoch 248/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3731 - accuracy: 0.8571 - val_loss: 11.9084 - val_accuracy: 0.7816\n",
      "Epoch 249/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3664 - accuracy: 0.8610 - val_loss: 11.9294 - val_accuracy: 0.7701\n",
      "Epoch 250/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3767 - accuracy: 0.8610 - val_loss: 12.1629 - val_accuracy: 0.8161\n",
      "Epoch 251/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3611 - accuracy: 0.8533 - val_loss: 12.2168 - val_accuracy: 0.8161\n",
      "Epoch 252/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3743 - accuracy: 0.8687 - val_loss: 12.2362 - val_accuracy: 0.8161\n",
      "Epoch 253/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3647 - accuracy: 0.8649 - val_loss: 12.3006 - val_accuracy: 0.7471\n",
      "Epoch 254/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3534 - accuracy: 0.8726 - val_loss: 12.5684 - val_accuracy: 0.8161\n",
      "Epoch 255/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3803 - accuracy: 0.8726 - val_loss: 12.5914 - val_accuracy: 0.8161\n",
      "Epoch 256/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3544 - accuracy: 0.8764 - val_loss: 12.5555 - val_accuracy: 0.8046\n",
      "Epoch 257/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3530 - accuracy: 0.8764 - val_loss: 12.8239 - val_accuracy: 0.8161\n",
      "Epoch 258/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3593 - accuracy: 0.8687 - val_loss: 12.7569 - val_accuracy: 0.8161\n",
      "Epoch 259/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3672 - accuracy: 0.8649 - val_loss: 12.8662 - val_accuracy: 0.8046\n",
      "Epoch 260/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3705 - accuracy: 0.8764 - val_loss: 13.0439 - val_accuracy: 0.7471\n",
      "Epoch 261/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3812 - accuracy: 0.8610 - val_loss: 12.7555 - val_accuracy: 0.8161\n",
      "Epoch 262/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3774 - accuracy: 0.8687 - val_loss: 12.8294 - val_accuracy: 0.8046\n",
      "Epoch 263/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3692 - accuracy: 0.8726 - val_loss: 12.8884 - val_accuracy: 0.7471\n",
      "Epoch 264/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3597 - accuracy: 0.8687 - val_loss: 12.9449 - val_accuracy: 0.8046\n",
      "Epoch 265/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3546 - accuracy: 0.8687 - val_loss: 13.1505 - val_accuracy: 0.8161\n",
      "Epoch 266/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3413 - accuracy: 0.8764 - val_loss: 13.2915 - val_accuracy: 0.8161\n",
      "Epoch 267/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3707 - accuracy: 0.8649 - val_loss: 13.3925 - val_accuracy: 0.8046\n",
      "Epoch 268/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3765 - accuracy: 0.8610 - val_loss: 13.2902 - val_accuracy: 0.8046\n",
      "Epoch 269/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3502 - accuracy: 0.8726 - val_loss: 13.4967 - val_accuracy: 0.8046\n",
      "Epoch 270/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3494 - accuracy: 0.8687 - val_loss: 13.5960 - val_accuracy: 0.8046\n",
      "Epoch 271/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3775 - accuracy: 0.8494 - val_loss: 13.4514 - val_accuracy: 0.8046\n",
      "Epoch 272/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3585 - accuracy: 0.8649 - val_loss: 13.6743 - val_accuracy: 0.8161\n",
      "Epoch 273/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3676 - accuracy: 0.8649 - val_loss: 13.7624 - val_accuracy: 0.8161\n",
      "Epoch 274/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3951 - accuracy: 0.8185 - val_loss: 13.9109 - val_accuracy: 0.8161\n",
      "Epoch 275/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3582 - accuracy: 0.8803 - val_loss: 13.9257 - val_accuracy: 0.8161\n",
      "Epoch 276/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3705 - accuracy: 0.8687 - val_loss: 13.7848 - val_accuracy: 0.7931\n",
      "Epoch 277/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3635 - accuracy: 0.8649 - val_loss: 13.9858 - val_accuracy: 0.7471\n",
      "Epoch 278/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3416 - accuracy: 0.8764 - val_loss: 14.1667 - val_accuracy: 0.8161\n",
      "Epoch 279/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3449 - accuracy: 0.8687 - val_loss: 14.1969 - val_accuracy: 0.8046\n",
      "Epoch 280/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3580 - accuracy: 0.8687 - val_loss: 14.6298 - val_accuracy: 0.7356\n",
      "Epoch 281/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4285 - accuracy: 0.8494 - val_loss: 14.3836 - val_accuracy: 0.8046\n",
      "Epoch 282/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3810 - accuracy: 0.8571 - val_loss: 14.2534 - val_accuracy: 0.8046\n",
      "Epoch 283/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3908 - accuracy: 0.8456 - val_loss: 14.3390 - val_accuracy: 0.8161\n",
      "Epoch 284/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3690 - accuracy: 0.8726 - val_loss: 14.5285 - val_accuracy: 0.8046\n",
      "Epoch 285/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3842 - accuracy: 0.8417 - val_loss: 14.5945 - val_accuracy: 0.8046\n",
      "Epoch 286/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3787 - accuracy: 0.8649 - val_loss: 14.5933 - val_accuracy: 0.8046\n",
      "Epoch 287/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3421 - accuracy: 0.8649 - val_loss: 14.5310 - val_accuracy: 0.8046\n",
      "Epoch 288/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3454 - accuracy: 0.8803 - val_loss: 14.5699 - val_accuracy: 0.8046\n",
      "Epoch 289/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3621 - accuracy: 0.8687 - val_loss: 14.7173 - val_accuracy: 0.8046\n",
      "Epoch 290/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3426 - accuracy: 0.8649 - val_loss: 14.7630 - val_accuracy: 0.8161\n",
      "Epoch 291/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3511 - accuracy: 0.8764 - val_loss: 14.6533 - val_accuracy: 0.8046\n",
      "Epoch 292/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3436 - accuracy: 0.8687 - val_loss: 14.8541 - val_accuracy: 0.8161\n",
      "Epoch 293/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3364 - accuracy: 0.8764 - val_loss: 14.8897 - val_accuracy: 0.7816\n",
      "Epoch 294/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3315 - accuracy: 0.8571 - val_loss: 15.0283 - val_accuracy: 0.8161\n",
      "Epoch 295/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3677 - accuracy: 0.8687 - val_loss: 15.2358 - val_accuracy: 0.8046\n",
      "Epoch 296/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3975 - accuracy: 0.8571 - val_loss: 14.9408 - val_accuracy: 0.8161\n",
      "Epoch 297/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3585 - accuracy: 0.8649 - val_loss: 14.9593 - val_accuracy: 0.7471\n",
      "Epoch 298/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3549 - accuracy: 0.8649 - val_loss: 15.0353 - val_accuracy: 0.8046\n",
      "Epoch 299/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3232 - accuracy: 0.8803 - val_loss: 15.4119 - val_accuracy: 0.8046\n",
      "Epoch 300/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3525 - accuracy: 0.8687 - val_loss: 15.4618 - val_accuracy: 0.8046\n",
      "Epoch 301/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3664 - accuracy: 0.8108 - val_loss: 15.6035 - val_accuracy: 0.8161\n",
      "Epoch 302/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3545 - accuracy: 0.8649 - val_loss: 15.9068 - val_accuracy: 0.8046\n",
      "Epoch 303/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3750 - accuracy: 0.8764 - val_loss: 15.9093 - val_accuracy: 0.8046\n",
      "Epoch 304/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3546 - accuracy: 0.8649 - val_loss: 16.4171 - val_accuracy: 0.8046\n",
      "Epoch 305/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3588 - accuracy: 0.8687 - val_loss: 16.2822 - val_accuracy: 0.8161\n",
      "Epoch 306/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3551 - accuracy: 0.8687 - val_loss: 15.9778 - val_accuracy: 0.7241\n",
      "Epoch 307/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4666 - accuracy: 0.8456 - val_loss: 15.9101 - val_accuracy: 0.6437\n",
      "Epoch 308/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.9047 - accuracy: 0.7954 - val_loss: 17.9436 - val_accuracy: 0.7241\n",
      "Epoch 309/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0885 - accuracy: 0.7838 - val_loss: 20.5775 - val_accuracy: 0.7241\n",
      "Epoch 310/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.1575 - accuracy: 0.7220 - val_loss: 18.0526 - val_accuracy: 0.8046\n",
      "Epoch 311/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.7836 - accuracy: 0.7876 - val_loss: 18.3615 - val_accuracy: 0.7011\n",
      "Epoch 312/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.8610 - accuracy: 0.7761 - val_loss: 23.3813 - val_accuracy: 0.6667\n",
      "Epoch 313/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.7165 - accuracy: 0.7799 - val_loss: 22.9217 - val_accuracy: 0.7356\n",
      "Epoch 314/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6467 - accuracy: 0.8185 - val_loss: 21.5556 - val_accuracy: 0.7356\n",
      "Epoch 315/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5713 - accuracy: 0.8224 - val_loss: 20.2276 - val_accuracy: 0.7356\n",
      "Epoch 316/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5151 - accuracy: 0.8417 - val_loss: 21.7774 - val_accuracy: 0.7356\n",
      "Epoch 317/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4886 - accuracy: 0.8263 - val_loss: 22.3930 - val_accuracy: 0.8046\n",
      "Epoch 318/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4637 - accuracy: 0.8571 - val_loss: 22.9258 - val_accuracy: 0.7816\n",
      "Epoch 319/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4476 - accuracy: 0.8610 - val_loss: 23.0997 - val_accuracy: 0.8046\n",
      "Epoch 320/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4296 - accuracy: 0.8649 - val_loss: 23.0995 - val_accuracy: 0.8046\n",
      "Epoch 321/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4048 - accuracy: 0.8649 - val_loss: 22.9578 - val_accuracy: 0.8161\n",
      "Epoch 322/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3876 - accuracy: 0.8726 - val_loss: 23.4203 - val_accuracy: 0.8046\n",
      "Epoch 323/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3813 - accuracy: 0.8726 - val_loss: 23.5184 - val_accuracy: 0.8046\n",
      "Epoch 324/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3697 - accuracy: 0.8726 - val_loss: 23.6186 - val_accuracy: 0.8046\n",
      "Epoch 325/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3612 - accuracy: 0.8726 - val_loss: 23.9019 - val_accuracy: 0.8046\n",
      "Epoch 326/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3707 - accuracy: 0.8610 - val_loss: 23.5897 - val_accuracy: 0.8161\n",
      "Epoch 327/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3575 - accuracy: 0.8687 - val_loss: 23.7066 - val_accuracy: 0.8046\n",
      "Epoch 328/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3526 - accuracy: 0.8726 - val_loss: 23.4103 - val_accuracy: 0.7931\n",
      "Epoch 329/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3511 - accuracy: 0.8726 - val_loss: 23.6315 - val_accuracy: 0.8046\n",
      "Epoch 330/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3501 - accuracy: 0.8726 - val_loss: 23.6531 - val_accuracy: 0.7586\n",
      "Epoch 331/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3456 - accuracy: 0.8764 - val_loss: 23.6068 - val_accuracy: 0.8046\n",
      "Epoch 332/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3526 - accuracy: 0.8610 - val_loss: 23.8791 - val_accuracy: 0.8046\n",
      "Epoch 333/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3560 - accuracy: 0.8726 - val_loss: 24.1762 - val_accuracy: 0.8046\n",
      "Epoch 334/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3494 - accuracy: 0.8649 - val_loss: 24.3018 - val_accuracy: 0.8161\n",
      "Epoch 335/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3482 - accuracy: 0.8649 - val_loss: 24.0634 - val_accuracy: 0.7586\n",
      "Epoch 336/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3481 - accuracy: 0.8726 - val_loss: 24.6934 - val_accuracy: 0.8046\n",
      "Epoch 337/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3482 - accuracy: 0.8726 - val_loss: 24.6031 - val_accuracy: 0.8161\n",
      "Epoch 338/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3532 - accuracy: 0.8687 - val_loss: 24.1276 - val_accuracy: 0.7816\n",
      "Epoch 339/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3547 - accuracy: 0.8764 - val_loss: 24.1513 - val_accuracy: 0.7586\n",
      "Epoch 340/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3451 - accuracy: 0.8726 - val_loss: 25.0786 - val_accuracy: 0.8046\n",
      "Epoch 341/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3547 - accuracy: 0.8764 - val_loss: 25.1097 - val_accuracy: 0.8046\n",
      "Epoch 342/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3392 - accuracy: 0.8649 - val_loss: 24.7664 - val_accuracy: 0.8161\n",
      "Epoch 343/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3415 - accuracy: 0.8726 - val_loss: 24.5788 - val_accuracy: 0.7471\n",
      "Epoch 344/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3472 - accuracy: 0.8687 - val_loss: 25.5580 - val_accuracy: 0.8046\n",
      "Epoch 345/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3451 - accuracy: 0.8649 - val_loss: 25.8811 - val_accuracy: 0.8161\n",
      "Epoch 346/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3382 - accuracy: 0.8803 - val_loss: 25.7789 - val_accuracy: 0.7471\n",
      "Epoch 347/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3643 - accuracy: 0.8494 - val_loss: 25.9680 - val_accuracy: 0.8161\n",
      "Epoch 348/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3527 - accuracy: 0.8571 - val_loss: 26.2371 - val_accuracy: 0.8161\n",
      "Epoch 349/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3827 - accuracy: 0.8687 - val_loss: 23.1000 - val_accuracy: 0.8046\n",
      "Epoch 350/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3806 - accuracy: 0.8533 - val_loss: 20.2947 - val_accuracy: 0.7931\n",
      "Epoch 351/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3787 - accuracy: 0.8687 - val_loss: 19.1049 - val_accuracy: 0.8046\n",
      "Epoch 352/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3601 - accuracy: 0.8687 - val_loss: 18.4114 - val_accuracy: 0.7356\n",
      "Epoch 353/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3774 - accuracy: 0.8571 - val_loss: 17.6506 - val_accuracy: 0.7701\n",
      "Epoch 354/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3499 - accuracy: 0.8726 - val_loss: 18.0972 - val_accuracy: 0.8046\n",
      "Epoch 355/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3497 - accuracy: 0.8687 - val_loss: 17.8483 - val_accuracy: 0.8046\n",
      "Epoch 356/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3311 - accuracy: 0.8726 - val_loss: 18.1056 - val_accuracy: 0.8046\n",
      "Epoch 357/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3299 - accuracy: 0.8649 - val_loss: 18.3246 - val_accuracy: 0.7471\n",
      "Epoch 358/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3603 - accuracy: 0.8610 - val_loss: 18.7104 - val_accuracy: 0.8046\n",
      "Epoch 359/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3505 - accuracy: 0.8649 - val_loss: 18.8749 - val_accuracy: 0.8161\n",
      "Epoch 360/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3460 - accuracy: 0.8726 - val_loss: 18.9142 - val_accuracy: 0.8046\n",
      "Epoch 361/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3841 - accuracy: 0.8494 - val_loss: 19.4829 - val_accuracy: 0.7356\n",
      "Epoch 362/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.2289 - accuracy: 0.7683 - val_loss: 27.2504 - val_accuracy: 0.3793\n",
      "Epoch 363/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.8771 - accuracy: 0.5560 - val_loss: 24.3307 - val_accuracy: 0.7126\n",
      "Epoch 364/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.9930 - accuracy: 0.7838 - val_loss: 24.8785 - val_accuracy: 0.6782\n",
      "Epoch 365/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6673 - accuracy: 0.7452 - val_loss: 23.1007 - val_accuracy: 0.7356\n",
      "Epoch 366/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4267 - accuracy: 0.8610 - val_loss: 22.0793 - val_accuracy: 0.7241\n",
      "Epoch 367/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4315 - accuracy: 0.8533 - val_loss: 20.7166 - val_accuracy: 0.8161\n",
      "Epoch 368/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3823 - accuracy: 0.8649 - val_loss: 20.2906 - val_accuracy: 0.7931\n",
      "Epoch 369/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3756 - accuracy: 0.8610 - val_loss: 19.8983 - val_accuracy: 0.7471\n",
      "Epoch 370/500\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3634 - accuracy: 0.8571 - val_loss: 19.5736 - val_accuracy: 0.8046\n",
      "Epoch 371/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3582 - accuracy: 0.8610 - val_loss: 19.5720 - val_accuracy: 0.8046\n",
      "Epoch 372/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3572 - accuracy: 0.8687 - val_loss: 19.6406 - val_accuracy: 0.7816\n",
      "Epoch 373/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3564 - accuracy: 0.8726 - val_loss: 19.5229 - val_accuracy: 0.8161\n",
      "Epoch 374/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3515 - accuracy: 0.8649 - val_loss: 19.6588 - val_accuracy: 0.7931\n",
      "Epoch 375/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3458 - accuracy: 0.8649 - val_loss: 19.4465 - val_accuracy: 0.8161\n",
      "Epoch 376/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3464 - accuracy: 0.8726 - val_loss: 19.5400 - val_accuracy: 0.8046\n",
      "Epoch 377/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3344 - accuracy: 0.8764 - val_loss: 19.6719 - val_accuracy: 0.8161\n",
      "Epoch 378/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3438 - accuracy: 0.8803 - val_loss: 19.4425 - val_accuracy: 0.8161\n",
      "Epoch 379/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3396 - accuracy: 0.8764 - val_loss: 19.3134 - val_accuracy: 0.8046\n",
      "Epoch 380/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3418 - accuracy: 0.8610 - val_loss: 19.2358 - val_accuracy: 0.8161\n",
      "Epoch 381/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3371 - accuracy: 0.8610 - val_loss: 19.3160 - val_accuracy: 0.8161\n",
      "Epoch 382/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3457 - accuracy: 0.8687 - val_loss: 19.5975 - val_accuracy: 0.7931\n",
      "Epoch 383/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3295 - accuracy: 0.8726 - val_loss: 19.5195 - val_accuracy: 0.8161\n",
      "Epoch 384/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3299 - accuracy: 0.8803 - val_loss: 19.8063 - val_accuracy: 0.7816\n",
      "Epoch 385/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3341 - accuracy: 0.8571 - val_loss: 19.5160 - val_accuracy: 0.8161\n",
      "Epoch 386/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3296 - accuracy: 0.8649 - val_loss: 19.8297 - val_accuracy: 0.7471\n",
      "Epoch 387/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3420 - accuracy: 0.8649 - val_loss: 19.7637 - val_accuracy: 0.8161\n",
      "Epoch 388/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3320 - accuracy: 0.8687 - val_loss: 19.9698 - val_accuracy: 0.8161\n",
      "Epoch 389/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3309 - accuracy: 0.8687 - val_loss: 20.1471 - val_accuracy: 0.8161\n",
      "Epoch 390/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3248 - accuracy: 0.8764 - val_loss: 19.9733 - val_accuracy: 0.8046\n",
      "Epoch 391/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3521 - accuracy: 0.8842 - val_loss: 20.4234 - val_accuracy: 0.8161\n",
      "Epoch 392/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3505 - accuracy: 0.8571 - val_loss: 20.7490 - val_accuracy: 0.8046\n",
      "Epoch 393/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3352 - accuracy: 0.8649 - val_loss: 20.2440 - val_accuracy: 0.8161\n",
      "Epoch 394/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3250 - accuracy: 0.8803 - val_loss: 20.0324 - val_accuracy: 0.8161\n",
      "Epoch 395/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3348 - accuracy: 0.8764 - val_loss: 19.9430 - val_accuracy: 0.8046\n",
      "Epoch 396/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3306 - accuracy: 0.8687 - val_loss: 19.9274 - val_accuracy: 0.7931\n",
      "Epoch 397/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3290 - accuracy: 0.8687 - val_loss: 19.4912 - val_accuracy: 0.8161\n",
      "Epoch 398/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3334 - accuracy: 0.8764 - val_loss: 19.8918 - val_accuracy: 0.7471\n",
      "Epoch 399/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3377 - accuracy: 0.8571 - val_loss: 19.5234 - val_accuracy: 0.8161\n",
      "Epoch 400/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3254 - accuracy: 0.8687 - val_loss: 19.7013 - val_accuracy: 0.8161\n",
      "Epoch 401/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3298 - accuracy: 0.8764 - val_loss: 19.9948 - val_accuracy: 0.8046\n",
      "Epoch 402/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3183 - accuracy: 0.8803 - val_loss: 20.0784 - val_accuracy: 0.7701\n",
      "Epoch 403/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3226 - accuracy: 0.8726 - val_loss: 19.8332 - val_accuracy: 0.8161\n",
      "Epoch 404/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3277 - accuracy: 0.8726 - val_loss: 20.1212 - val_accuracy: 0.7816\n",
      "Epoch 405/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3152 - accuracy: 0.8610 - val_loss: 20.2613 - val_accuracy: 0.8046\n",
      "Epoch 406/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3187 - accuracy: 0.8687 - val_loss: 20.1257 - val_accuracy: 0.8161\n",
      "Epoch 407/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3399 - accuracy: 0.8687 - val_loss: 20.1253 - val_accuracy: 0.8161\n",
      "Epoch 408/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3444 - accuracy: 0.8687 - val_loss: 20.7753 - val_accuracy: 0.7241\n",
      "Epoch 409/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3705 - accuracy: 0.8649 - val_loss: 20.3362 - val_accuracy: 0.8161\n",
      "Epoch 410/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3733 - accuracy: 0.8533 - val_loss: 20.2122 - val_accuracy: 0.7356\n",
      "Epoch 411/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4335 - accuracy: 0.8340 - val_loss: 20.4884 - val_accuracy: 0.7356\n",
      "Epoch 412/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4163 - accuracy: 0.8533 - val_loss: 20.5926 - val_accuracy: 0.7586\n",
      "Epoch 413/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3350 - accuracy: 0.8649 - val_loss: 20.8277 - val_accuracy: 0.8161\n",
      "Epoch 414/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3517 - accuracy: 0.8726 - val_loss: 20.8005 - val_accuracy: 0.8161\n",
      "Epoch 415/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3278 - accuracy: 0.8726 - val_loss: 20.8544 - val_accuracy: 0.7931\n",
      "Epoch 416/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3168 - accuracy: 0.8726 - val_loss: 20.7620 - val_accuracy: 0.8161\n",
      "Epoch 417/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3210 - accuracy: 0.8687 - val_loss: 20.6546 - val_accuracy: 0.8161\n",
      "Epoch 418/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3233 - accuracy: 0.8726 - val_loss: 20.9951 - val_accuracy: 0.8046\n",
      "Epoch 419/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3291 - accuracy: 0.8803 - val_loss: 20.8743 - val_accuracy: 0.8046\n",
      "Epoch 420/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3286 - accuracy: 0.8571 - val_loss: 21.1963 - val_accuracy: 0.8046\n",
      "Epoch 421/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3147 - accuracy: 0.8687 - val_loss: 21.2769 - val_accuracy: 0.8046\n",
      "Epoch 422/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3123 - accuracy: 0.8726 - val_loss: 21.3576 - val_accuracy: 0.8161\n",
      "Epoch 423/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3350 - accuracy: 0.8687 - val_loss: 21.6504 - val_accuracy: 0.7241\n",
      "Epoch 424/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3416 - accuracy: 0.8687 - val_loss: 21.1620 - val_accuracy: 0.8046\n",
      "Epoch 425/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3463 - accuracy: 0.8726 - val_loss: 21.8466 - val_accuracy: 0.7701\n",
      "Epoch 426/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3311 - accuracy: 0.8726 - val_loss: 21.4852 - val_accuracy: 0.8046\n",
      "Epoch 427/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3218 - accuracy: 0.8726 - val_loss: 21.4330 - val_accuracy: 0.8161\n",
      "Epoch 428/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3316 - accuracy: 0.8571 - val_loss: 21.7613 - val_accuracy: 0.7701\n",
      "Epoch 429/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3105 - accuracy: 0.8726 - val_loss: 21.7990 - val_accuracy: 0.8046\n",
      "Epoch 430/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3069 - accuracy: 0.8764 - val_loss: 21.6063 - val_accuracy: 0.8161\n",
      "Epoch 431/500\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3290 - accuracy: 0.8649 - val_loss: 21.7067 - val_accuracy: 0.8046\n",
      "Epoch 432/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3238 - accuracy: 0.8803 - val_loss: 21.2883 - val_accuracy: 0.8046\n",
      "Epoch 433/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3254 - accuracy: 0.8726 - val_loss: 21.6801 - val_accuracy: 0.7931\n",
      "Epoch 434/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3603 - accuracy: 0.8649 - val_loss: 21.6839 - val_accuracy: 0.8161\n",
      "Epoch 435/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3228 - accuracy: 0.8842 - val_loss: 21.3603 - val_accuracy: 0.8046\n",
      "Epoch 436/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3429 - accuracy: 0.8687 - val_loss: 22.0406 - val_accuracy: 0.8161\n",
      "Epoch 437/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3362 - accuracy: 0.8726 - val_loss: 21.6259 - val_accuracy: 0.8161\n",
      "Epoch 438/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3119 - accuracy: 0.8803 - val_loss: 21.6163 - val_accuracy: 0.8046\n",
      "Epoch 439/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3127 - accuracy: 0.8803 - val_loss: 22.0043 - val_accuracy: 0.7586\n",
      "Epoch 440/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3028 - accuracy: 0.8764 - val_loss: 22.0136 - val_accuracy: 0.8161\n",
      "Epoch 441/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3082 - accuracy: 0.8842 - val_loss: 22.4633 - val_accuracy: 0.7241\n",
      "Epoch 442/500\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3027 - accuracy: 0.8726 - val_loss: 22.2565 - val_accuracy: 0.8161\n",
      "Epoch 443/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3245 - accuracy: 0.8610 - val_loss: 22.1898 - val_accuracy: 0.8161\n",
      "Epoch 444/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3164 - accuracy: 0.8764 - val_loss: 22.5785 - val_accuracy: 0.7586\n",
      "Epoch 445/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3113 - accuracy: 0.8764 - val_loss: 22.4257 - val_accuracy: 0.8161\n",
      "Epoch 446/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3068 - accuracy: 0.8803 - val_loss: 22.5159 - val_accuracy: 0.7816\n",
      "Epoch 447/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2983 - accuracy: 0.8764 - val_loss: 22.5050 - val_accuracy: 0.8046\n",
      "Epoch 448/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3017 - accuracy: 0.8649 - val_loss: 22.5478 - val_accuracy: 0.8161\n",
      "Epoch 449/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3104 - accuracy: 0.8842 - val_loss: 22.6784 - val_accuracy: 0.7586\n",
      "Epoch 450/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3180 - accuracy: 0.8726 - val_loss: 22.3883 - val_accuracy: 0.8161\n",
      "Epoch 451/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3316 - accuracy: 0.8842 - val_loss: 22.5394 - val_accuracy: 0.8161\n",
      "Epoch 452/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3462 - accuracy: 0.8687 - val_loss: 22.9108 - val_accuracy: 0.7471\n",
      "Epoch 453/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3354 - accuracy: 0.8803 - val_loss: 22.8462 - val_accuracy: 0.8161\n",
      "Epoch 454/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3184 - accuracy: 0.8842 - val_loss: 22.6278 - val_accuracy: 0.8046\n",
      "Epoch 455/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3347 - accuracy: 0.8687 - val_loss: 23.1213 - val_accuracy: 0.7816\n",
      "Epoch 456/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3480 - accuracy: 0.8687 - val_loss: 23.1281 - val_accuracy: 0.8046\n",
      "Epoch 457/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3158 - accuracy: 0.8803 - val_loss: 22.8402 - val_accuracy: 0.8161\n",
      "Epoch 458/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3135 - accuracy: 0.8842 - val_loss: 23.1831 - val_accuracy: 0.8161\n",
      "Epoch 459/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3543 - accuracy: 0.8649 - val_loss: 23.3808 - val_accuracy: 0.7586\n",
      "Epoch 460/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3535 - accuracy: 0.8726 - val_loss: 23.0510 - val_accuracy: 0.8161\n",
      "Epoch 461/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2966 - accuracy: 0.8726 - val_loss: 23.5457 - val_accuracy: 0.8161\n",
      "Epoch 462/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3187 - accuracy: 0.8842 - val_loss: 23.5043 - val_accuracy: 0.8046\n",
      "Epoch 463/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2964 - accuracy: 0.8803 - val_loss: 23.3973 - val_accuracy: 0.8046\n",
      "Epoch 464/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2936 - accuracy: 0.8803 - val_loss: 23.6168 - val_accuracy: 0.7816\n",
      "Epoch 465/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2990 - accuracy: 0.8726 - val_loss: 23.4216 - val_accuracy: 0.8161\n",
      "Epoch 466/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2899 - accuracy: 0.8764 - val_loss: 23.8050 - val_accuracy: 0.7356\n",
      "Epoch 467/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3228 - accuracy: 0.8803 - val_loss: 23.5961 - val_accuracy: 0.8161\n",
      "Epoch 468/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3249 - accuracy: 0.8764 - val_loss: 23.7961 - val_accuracy: 0.8161\n",
      "Epoch 469/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3096 - accuracy: 0.8649 - val_loss: 24.0226 - val_accuracy: 0.7931\n",
      "Epoch 470/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3071 - accuracy: 0.8803 - val_loss: 24.1043 - val_accuracy: 0.8161\n",
      "Epoch 471/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3055 - accuracy: 0.8803 - val_loss: 24.5285 - val_accuracy: 0.7816\n",
      "Epoch 472/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2842 - accuracy: 0.8842 - val_loss: 24.1685 - val_accuracy: 0.8161\n",
      "Epoch 473/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3256 - accuracy: 0.8803 - val_loss: 24.1527 - val_accuracy: 0.8161\n",
      "Epoch 474/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3338 - accuracy: 0.8610 - val_loss: 24.4074 - val_accuracy: 0.8046\n",
      "Epoch 475/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3316 - accuracy: 0.8687 - val_loss: 24.5206 - val_accuracy: 0.7931\n",
      "Epoch 476/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3483 - accuracy: 0.8610 - val_loss: 23.9488 - val_accuracy: 0.8161\n",
      "Epoch 477/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5461 - accuracy: 0.8456 - val_loss: 23.1941 - val_accuracy: 0.7126\n",
      "Epoch 478/500\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1111 - accuracy: 0.7838 - val_loss: 21.4885 - val_accuracy: 0.7241\n",
      "Epoch 479/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.2311 - accuracy: 0.8031 - val_loss: 28.1117 - val_accuracy: 0.7356\n",
      "Epoch 480/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.2203 - accuracy: 0.7452 - val_loss: 36.8812 - val_accuracy: 0.6667\n",
      "Epoch 481/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.8525 - accuracy: 0.7876 - val_loss: 41.4611 - val_accuracy: 0.7701\n",
      "Epoch 482/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5446 - accuracy: 0.8301 - val_loss: 37.6769 - val_accuracy: 0.7241\n",
      "Epoch 483/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.7636 - accuracy: 0.8147 - val_loss: 38.1141 - val_accuracy: 0.7356\n",
      "Epoch 484/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5566 - accuracy: 0.8378 - val_loss: 40.0698 - val_accuracy: 0.7816\n",
      "Epoch 485/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4337 - accuracy: 0.8571 - val_loss: 36.8244 - val_accuracy: 0.7586\n",
      "Epoch 486/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3849 - accuracy: 0.8880 - val_loss: 36.2717 - val_accuracy: 0.7931\n",
      "Epoch 487/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3847 - accuracy: 0.8687 - val_loss: 36.6769 - val_accuracy: 0.7931\n",
      "Epoch 488/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3589 - accuracy: 0.8726 - val_loss: 37.1311 - val_accuracy: 0.7931\n",
      "Epoch 489/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3504 - accuracy: 0.8764 - val_loss: 35.5400 - val_accuracy: 0.7931\n",
      "Epoch 490/500\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3403 - accuracy: 0.8726 - val_loss: 35.5456 - val_accuracy: 0.8046\n",
      "Epoch 491/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3513 - accuracy: 0.8764 - val_loss: 35.2723 - val_accuracy: 0.8161\n",
      "Epoch 492/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3446 - accuracy: 0.8687 - val_loss: 36.3416 - val_accuracy: 0.7816\n",
      "Epoch 493/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3232 - accuracy: 0.8726 - val_loss: 36.8287 - val_accuracy: 0.8046\n",
      "Epoch 494/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3308 - accuracy: 0.8803 - val_loss: 36.8867 - val_accuracy: 0.8046\n",
      "Epoch 495/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3434 - accuracy: 0.8687 - val_loss: 38.3360 - val_accuracy: 0.7471\n",
      "Epoch 496/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3632 - accuracy: 0.8649 - val_loss: 37.4269 - val_accuracy: 0.7816\n",
      "Epoch 497/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3496 - accuracy: 0.8880 - val_loss: 36.3501 - val_accuracy: 0.8161\n",
      "Epoch 498/500\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3341 - accuracy: 0.8803 - val_loss: 36.9148 - val_accuracy: 0.8161\n",
      "Epoch 499/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3419 - accuracy: 0.8649 - val_loss: 38.2782 - val_accuracy: 0.7241\n",
      "Epoch 500/500\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3738 - accuracy: 0.8649 - val_loss: 36.2491 - val_accuracy: 0.7931\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x255e3db8250>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=500, batch_size=48, validation_data=(X_test, y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "file_path_volts1 = r\".\\dataset\\H2\\Tagged_Training_02_15_1360915201\\LF1V.csv\"\n",
    "file_path_amps1 = r\".\\dataset\\H2\\Tagged_Training_02_15_1360915201\\LF1I.csv\"\n",
    "file_path_time_ticks1 = r\".\\dataset\\H2\\Tagged_Training_02_15_1360915201\\TimeTicks1.csv\"\n",
    "\n",
    "file_path_volts2 = r\".\\dataset\\H2\\Tagged_Training_02_15_1360915201\\LF2V.csv\"\n",
    "file_path_amps2 = r\".\\dataset\\H2\\Tagged_Training_02_15_1360915201\\LF2I.csv\"\n",
    "file_path_time_ticks2 = r\".\\dataset\\H2\\Tagged_Training_02_15_1360915201\\TimeTicks2.csv\"\n",
    "\n",
    "file_path_labels = r\".\\dataset\\H2\\AllTaggingInfo.csv\"\n",
    "\n",
    "LF1V = pd.read_csv(file_path_volts1)\n",
    "LF1I = pd.read_csv(file_path_amps1)\n",
    "time_ticks1 = pd.read_csv(file_path_time_ticks1)\n",
    "\n",
    "LF2V = pd.read_csv(file_path_volts2)\n",
    "LF2I = pd.read_csv(file_path_amps2)\n",
    "time_ticks2 = pd.read_csv(file_path_time_ticks2)\n",
    "\n",
    "labels = pd.read_csv(file_path_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "LF1V = np.array(LF1V)\n",
    "LF1I = np.array(LF1I)\n",
    "LF1V = np.array([[complex(y.replace(\"i\", \"j\")) for y in x] for x in LF1V])\n",
    "LF1I = np.array([[complex(y.replace(\"i\", \"j\")) for y in x] for x in LF1I])\n",
    "\n",
    "LF2V = np.array(LF2V)\n",
    "LF2I = np.array(LF2I)\n",
    "LF2V = np.array([[complex(y.replace(\"i\", \"j\")) for y in x] for x in LF2V])\n",
    "LF2I = np.array([[complex(y.replace(\"i\", \"j\")) for y in x] for x in LF2I])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "L1_P = LF1V * np.conjugate(LF1I)\n",
    "L2_P = LF2V * np.conjugate(LF2I)\n",
    "\n",
    "L1_ComplexPower = np.sum(L1_P, axis=1)\n",
    "L2_ComplexPower = np.sum(L2_P, axis=1)\n",
    "\n",
    "L1_real = np.real(L1_ComplexPower)\n",
    "L1_imag = np.imag(L1_ComplexPower)\n",
    "L1_app = np.abs(L1_ComplexPower)\n",
    "\n",
    "L2_real = np.real(L2_ComplexPower)\n",
    "L2_imag = np.imag(L2_ComplexPower)\n",
    "L2_app = np.abs(L2_ComplexPower)\n",
    "\n",
    "L1_Pf = np.cos(np.angle(L1_P[:, 0]))\n",
    "L2_Pf = np.cos(np.angle(L2_P[:, 0]))\n",
    "\n",
    "L1_actual_power = L1_real * L1_Pf\n",
    "L2_actual_power = L2_real * L2_Pf\n",
    "\n",
    "power = L1_actual_power + L2_actual_power[:len(L1_actual_power)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "time_ticks1_datetime = pd.to_datetime(time_ticks1.iloc[:, 0], unit='s')\n",
    "time_ticks1_np = np.array(time_ticks1)\n",
    "TS1_real = np.array(time_ticks1_datetime)\n",
    "\n",
    "time_ticks2_datetime = pd.to_datetime(time_ticks2.iloc[:, 0], unit='s')\n",
    "TS2_real = np.array(time_ticks2_datetime)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-02-15T08:00:01.179514880\n",
      "2013-02-16T07:59:58.976457984\n",
      "2013-02-15T08:00:01.258717952\n",
      "2013-02-16T07:59:58.607661056\n"
     ]
    }
   ],
   "source": [
    "print(TS1_real[0])\n",
    "print(TS1_real[len(TS1_real) - 1])\n",
    "\n",
    "print(TS2_real[0])\n",
    "print(TS2_real[len(TS1_real) - 1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "labels[\"ON_Time\"] = pd.to_datetime(labels[\"ON_Time\"], unit='s')\n",
    "labels[\"OFF_Time\"] = pd.to_datetime(labels[\"OFF_Time\"], unit='s')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "     ApplianceID         ApplianceName             ON_Time            OFF_Time\n0             16        Kitchen Lights 2012-06-13 17:00:00 2012-06-13 17:01:00\n1             16        Kitchen Lights 2012-06-13 17:02:00 2012-06-13 17:02:30\n2             16        Kitchen Lights 2012-06-13 17:03:30 2012-06-13 17:04:30\n3             16        Kitchen Lights 2012-06-13 17:05:30 2012-06-13 17:06:00\n4             17  Kitchen Table Lights 2012-06-13 17:06:30 2012-06-13 17:07:00\n..           ...                   ...                 ...                 ...\n113            6              Computer 2013-02-15 19:36:00 2013-02-15 19:37:00\n114           29               Printer 2013-02-15 19:38:00 2013-02-15 19:40:30\n115           29               Printer 2013-02-15 19:41:30 2013-02-15 19:43:00\n116           29               Printer 2013-02-15 19:44:00 2013-02-15 19:45:00\n117           29               Printer 2013-02-15 19:46:30 2013-02-15 19:47:30\n\n[118 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ApplianceID</th>\n      <th>ApplianceName</th>\n      <th>ON_Time</th>\n      <th>OFF_Time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>16</td>\n      <td>Kitchen Lights</td>\n      <td>2012-06-13 17:00:00</td>\n      <td>2012-06-13 17:01:00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>16</td>\n      <td>Kitchen Lights</td>\n      <td>2012-06-13 17:02:00</td>\n      <td>2012-06-13 17:02:30</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>16</td>\n      <td>Kitchen Lights</td>\n      <td>2012-06-13 17:03:30</td>\n      <td>2012-06-13 17:04:30</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>16</td>\n      <td>Kitchen Lights</td>\n      <td>2012-06-13 17:05:30</td>\n      <td>2012-06-13 17:06:00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17</td>\n      <td>Kitchen Table Lights</td>\n      <td>2012-06-13 17:06:30</td>\n      <td>2012-06-13 17:07:00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>113</th>\n      <td>6</td>\n      <td>Computer</td>\n      <td>2013-02-15 19:36:00</td>\n      <td>2013-02-15 19:37:00</td>\n    </tr>\n    <tr>\n      <th>114</th>\n      <td>29</td>\n      <td>Printer</td>\n      <td>2013-02-15 19:38:00</td>\n      <td>2013-02-15 19:40:30</td>\n    </tr>\n    <tr>\n      <th>115</th>\n      <td>29</td>\n      <td>Printer</td>\n      <td>2013-02-15 19:41:30</td>\n      <td>2013-02-15 19:43:00</td>\n    </tr>\n    <tr>\n      <th>116</th>\n      <td>29</td>\n      <td>Printer</td>\n      <td>2013-02-15 19:44:00</td>\n      <td>2013-02-15 19:45:00</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <td>29</td>\n      <td>Printer</td>\n      <td>2013-02-15 19:46:30</td>\n      <td>2013-02-15 19:47:30</td>\n    </tr>\n  </tbody>\n</table>\n<p>118 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head(1000)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x700 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example date: 2023-10-10 12:00:00\n",
    "def zoomIn(start_time: string, end_time: string, time_ticks):\n",
    "    date_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "    # We add two hours because for some reason the start/end index are two hours short\n",
    "    start_time = (datetime.strptime(start_time, date_format) + timedelta(hours=1)).timestamp()\n",
    "    end_time = (datetime.strptime(end_time, date_format) + timedelta(hours=1)).timestamp()\n",
    "\n",
    "    start_index = -1\n",
    "    end_index = -1\n",
    "    for index in range(len(TS1_real)):\n",
    "        if time_ticks[index] > start_time and start_index == -1:\n",
    "            start_index = index\n",
    "        if time_ticks[index] > end_time and end_index == -1:\n",
    "            end_index = index\n",
    "    return start_index, end_index\n",
    "\n",
    "\n",
    "start_index, end_index = zoomIn(\"2013-02-15 18:45:00\", \"2013-02-15 18:55:00\", time_ticks1_np)\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "#This plots total power consumption (zoomed in)\n",
    "# plt.plot(TS2_real[start_index:end_index], power[start_index:end_index], linestyle='-', color='g', label='phase 1 + phase 2')\n",
    "\n",
    "#This plots total power consumption\n",
    "plt.plot(TS1_real, power, linestyle='-', color='g', label='phase 1 + phase 2')\n",
    "\n",
    "# This plots phase 1 and phase 2 separately (zoomed in)\n",
    "# plt.plot(TS1_real[start_index:end_index], L1_actual_power[start_index:end_index], linestyle='-', color='b', label='L1')\n",
    "# plt.plot(TS2_real[start_index:end_index], L2_actual_power[start_index:end_index], linestyle='-', color='r', label='L2')\n",
    "\n",
    "# This plots phase 1 and phase 2 separately (whole thing)\n",
    "# plt.plot(TS1_real, L1_actual_power, linestyle='-', color='b', label='L1')\n",
    "# plt.plot(TS2_real, L2_actual_power, linestyle='-', color='r', label='L2')\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "moving_average() missing 1 required positional argument: 'power'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 6\u001B[0m\n\u001B[0;32m      3\u001B[0m     df \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mrolling(window\u001B[38;5;241m=\u001B[39mwindow)\u001B[38;5;241m.\u001B[39mmean()\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m df\u001B[38;5;241m.\u001B[39mto_numpy()\n\u001B[1;32m----> 6\u001B[0m test \u001B[38;5;241m=\u001B[39m \u001B[43mmoving_average\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpower\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m plt\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m7\u001B[39m))\n\u001B[0;32m      8\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(TS1_real, test, linestyle\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m'\u001B[39m, color\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mg\u001B[39m\u001B[38;5;124m'\u001B[39m, label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mphase 1 + phase 2\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mTypeError\u001B[0m: moving_average() missing 1 required positional argument: 'power'"
     ]
    }
   ],
   "source": [
    "def moving_average(window: int, threshold: int, power):\n",
    "    df = pd.DataFrame(power)\n",
    "    df = df.rolling(window=window).mean()\n",
    "    return df.to_numpy()\n",
    "\n",
    "test = moving_average(20, power)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(TS1_real, test, linestyle='-', color='g', label='phase 1 + phase 2')\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def encode(label, total_labels):\n",
    "    array = np.zeros(total_labels + 1)\n",
    "    array[label] = 1\n",
    "    return array\n",
    "\n",
    "def format_data(power, time_ticks, labels, window):\n",
    "    data = np.empty((len(power) // window, window))\n",
    "    appliances = np.empty((len(power) // window, max(labels[\"ApplianceID\"]) + 1))\n",
    "    time = np.empty((len(power) // window, window))\n",
    "    last_entry_index = 0\n",
    "\n",
    "    for index in range(0, len(power) - window + 1, window):\n",
    "        window_start = index\n",
    "        window_end = index + window\n",
    "\n",
    "        found = False\n",
    "        for label in labels.iterrows():\n",
    "            label = label[1]\n",
    "            start_time = datetime.utcfromtimestamp(time_ticks[window_start].item())\n",
    "            end_time = datetime.utcfromtimestamp(time_ticks[window_end].item())\n",
    "\n",
    "            if label[\"ON_Time\"] <= start_time <= label[\"OFF_Time\"] or label[\"ON_Time\"] <= end_time <= label[\"OFF_Time\"]:\n",
    "                found = True\n",
    "                data[last_entry_index] = power[window_start:window_end].reshape(window)\n",
    "                time[last_entry_index] = time_ticks[window_start:window_end].reshape(window)\n",
    "                appliances[last_entry_index] = encode(label[\"ApplianceID\"], max(labels[\"ApplianceID\"]))\n",
    "                last_entry_index += 1\n",
    "                break\n",
    "\n",
    "        # if not found:\n",
    "        #     chance = random.random()\n",
    "        #     if chance > 0.99:\n",
    "        #         data[last_entry_index] = power[window_start:window_end].reshape(window)\n",
    "        #         time[last_entry_index] = time_ticks[window_start:window_end].reshape(window)\n",
    "        #         appliances[last_entry_index] = encode(0, max(labels[\"ApplianceID\"]))\n",
    "        #         last_entry_index += 1\n",
    "\n",
    "    return data[:last_entry_index], time[:last_entry_index], appliances[:last_entry_index]\n",
    "\n",
    "data, time, appliances = process_data(power, time_ticks1_np, labels, 10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[227.01128249 226.97864164 229.18759796 ... 227.36862706 226.51124187\n",
      "  229.0585733 ]\n",
      " [233.88943465 227.0682311  226.624764   ... 228.01646653 228.07221639\n",
      "  227.07364906]\n",
      " [226.7405476  229.17390162 227.57545939 ... 229.80850454 227.61660306\n",
      "  227.27179919]\n",
      " ...\n",
      " [257.82555045 256.37532101 254.0490028  ... 247.44726288 255.30634211\n",
      "  255.72174899]\n",
      " [253.18286489 258.52368351 250.83950772 ... 249.56506619 248.14645594\n",
      "  247.17518501]\n",
      " [247.51432482 247.69578722 253.49514395 ... 245.26098514 245.16106357\n",
      "  252.73071368]]\n",
      "(1545, 38)\n"
     ]
    }
   ],
   "source": [
    "print(data)\n",
    "print(appliances.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1169.59068747 1173.06503406 1168.25841473 ... 1169.4250345\n",
      "  1167.91739477 1167.81830915]\n",
      " [1347.63535086 1342.86682073 1344.85626716 ... 1342.98060145\n",
      "  1343.95337127 1341.7469311 ]\n",
      " [ 234.6962654   235.18923433  235.14923044 ...  239.99873544\n",
      "   234.8488575   228.01369362]\n",
      " ...\n",
      " [ 231.56137215  235.89275541  238.06208049 ...  235.94101108\n",
      "   236.60048765  234.46935943]\n",
      " [ 226.4378199   227.23576958  228.9738267  ...  228.48407752\n",
      "   228.78074519  230.62463554]\n",
      " [ 248.26781285  248.03429699  244.04835821 ...  246.85250753\n",
      "   246.30576173  245.75636026]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, appliances)\n",
    "print(X_train)\n",
    "print(y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1545\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for index in range(len(appliances)):\n",
    "    if appliances[index][0] != 1:\n",
    "        count += 1\n",
    "\n",
    "print(count)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=2, activation=\"relu\", input_shape=(10, 1)))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(38, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.8365 - accuracy: 0.6900 - val_loss: 3.2745 - val_accuracy: 0.5866\n",
      "Epoch 2/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7467 - accuracy: 0.7202 - val_loss: 3.2043 - val_accuracy: 0.6796\n",
      "Epoch 3/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7233 - accuracy: 0.7314 - val_loss: 3.2729 - val_accuracy: 0.6382\n",
      "Epoch 4/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7176 - accuracy: 0.7280 - val_loss: 3.3531 - val_accuracy: 0.6744\n",
      "Epoch 5/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7283 - accuracy: 0.7306 - val_loss: 3.3349 - val_accuracy: 0.6408\n",
      "Epoch 6/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7550 - accuracy: 0.7142 - val_loss: 3.2759 - val_accuracy: 0.6434\n",
      "Epoch 7/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6802 - accuracy: 0.7366 - val_loss: 3.4485 - val_accuracy: 0.6563\n",
      "Epoch 8/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.8059 - accuracy: 0.7150 - val_loss: 3.3030 - val_accuracy: 0.6718\n",
      "Epoch 9/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7494 - accuracy: 0.7055 - val_loss: 3.3024 - val_accuracy: 0.6460\n",
      "Epoch 10/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7127 - accuracy: 0.7340 - val_loss: 3.2995 - val_accuracy: 0.6770\n",
      "Epoch 11/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6786 - accuracy: 0.7366 - val_loss: 3.4471 - val_accuracy: 0.6047\n",
      "Epoch 12/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7175 - accuracy: 0.7280 - val_loss: 3.4249 - val_accuracy: 0.6047\n",
      "Epoch 13/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7444 - accuracy: 0.7168 - val_loss: 3.7712 - val_accuracy: 0.4780\n",
      "Epoch 14/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7225 - accuracy: 0.7073 - val_loss: 3.3813 - val_accuracy: 0.6150\n",
      "Epoch 15/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7334 - accuracy: 0.7211 - val_loss: 3.8473 - val_accuracy: 0.5323\n",
      "Epoch 16/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.1476 - accuracy: 0.6140 - val_loss: 4.0241 - val_accuracy: 0.4264\n",
      "Epoch 17/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7973 - accuracy: 0.6969 - val_loss: 3.3936 - val_accuracy: 0.6460\n",
      "Epoch 18/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6917 - accuracy: 0.7383 - val_loss: 3.4271 - val_accuracy: 0.6615\n",
      "Epoch 19/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7489 - accuracy: 0.7193 - val_loss: 3.6922 - val_accuracy: 0.5659\n",
      "Epoch 20/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7541 - accuracy: 0.7228 - val_loss: 3.3841 - val_accuracy: 0.6460\n",
      "Epoch 21/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7143 - accuracy: 0.7185 - val_loss: 3.4004 - val_accuracy: 0.6848\n",
      "Epoch 22/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7124 - accuracy: 0.7237 - val_loss: 3.3809 - val_accuracy: 0.6615\n",
      "Epoch 23/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6811 - accuracy: 0.7332 - val_loss: 3.3568 - val_accuracy: 0.6693\n",
      "Epoch 24/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7184 - accuracy: 0.7340 - val_loss: 3.4100 - val_accuracy: 0.6331\n",
      "Epoch 25/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7804 - accuracy: 0.7116 - val_loss: 4.3327 - val_accuracy: 0.4522\n",
      "Epoch 26/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.1802 - accuracy: 0.6054 - val_loss: 3.5899 - val_accuracy: 0.6563\n",
      "Epoch 27/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8271 - accuracy: 0.7107 - val_loss: 3.4732 - val_accuracy: 0.6305\n",
      "Epoch 28/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7505 - accuracy: 0.7332 - val_loss: 3.5436 - val_accuracy: 0.5891\n",
      "Epoch 29/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7027 - accuracy: 0.7332 - val_loss: 3.3836 - val_accuracy: 0.6537\n",
      "Epoch 30/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7285 - accuracy: 0.7237 - val_loss: 3.5900 - val_accuracy: 0.5969\n",
      "Epoch 31/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8595 - accuracy: 0.6762 - val_loss: 3.6252 - val_accuracy: 0.6021\n",
      "Epoch 32/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7221 - accuracy: 0.7375 - val_loss: 3.4692 - val_accuracy: 0.6512\n",
      "Epoch 33/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6903 - accuracy: 0.7401 - val_loss: 3.4011 - val_accuracy: 0.6848\n",
      "Epoch 34/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7090 - accuracy: 0.7375 - val_loss: 3.5545 - val_accuracy: 0.6899\n",
      "Epoch 35/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7244 - accuracy: 0.7271 - val_loss: 3.7349 - val_accuracy: 0.5917\n",
      "Epoch 36/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7274 - accuracy: 0.7219 - val_loss: 3.4679 - val_accuracy: 0.6641\n",
      "Epoch 37/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7064 - accuracy: 0.7366 - val_loss: 3.5307 - val_accuracy: 0.6615\n",
      "Epoch 38/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7691 - accuracy: 0.7168 - val_loss: 3.5563 - val_accuracy: 0.6227\n",
      "Epoch 39/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7361 - accuracy: 0.7280 - val_loss: 3.5330 - val_accuracy: 0.6279\n",
      "Epoch 40/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6804 - accuracy: 0.7418 - val_loss: 3.5295 - val_accuracy: 0.6434\n",
      "Epoch 41/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6710 - accuracy: 0.7453 - val_loss: 3.5504 - val_accuracy: 0.6718\n",
      "Epoch 42/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6483 - accuracy: 0.7513 - val_loss: 3.6559 - val_accuracy: 0.6563\n",
      "Epoch 43/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7245 - accuracy: 0.7168 - val_loss: 3.4679 - val_accuracy: 0.6589\n",
      "Epoch 44/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6660 - accuracy: 0.7375 - val_loss: 3.5519 - val_accuracy: 0.6150\n",
      "Epoch 45/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9060 - accuracy: 0.6520 - val_loss: 3.8966 - val_accuracy: 0.5504\n",
      "Epoch 46/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8704 - accuracy: 0.6796 - val_loss: 3.6011 - val_accuracy: 0.6537\n",
      "Epoch 47/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7190 - accuracy: 0.7358 - val_loss: 3.6139 - val_accuracy: 0.6460\n",
      "Epoch 48/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7004 - accuracy: 0.7375 - val_loss: 3.5838 - val_accuracy: 0.6693\n",
      "Epoch 49/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7097 - accuracy: 0.7237 - val_loss: 3.7464 - val_accuracy: 0.6098\n",
      "Epoch 50/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8316 - accuracy: 0.6891 - val_loss: 3.4927 - val_accuracy: 0.6486\n",
      "Epoch 51/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6602 - accuracy: 0.7453 - val_loss: 3.4842 - val_accuracy: 0.6770\n",
      "Epoch 52/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6748 - accuracy: 0.7461 - val_loss: 3.5541 - val_accuracy: 0.6822\n",
      "Epoch 53/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6837 - accuracy: 0.7530 - val_loss: 3.4949 - val_accuracy: 0.6537\n",
      "Epoch 54/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6711 - accuracy: 0.7375 - val_loss: 4.0554 - val_accuracy: 0.4367\n",
      "Epoch 55/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7996 - accuracy: 0.6978 - val_loss: 3.5111 - val_accuracy: 0.6641\n",
      "Epoch 56/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6659 - accuracy: 0.7427 - val_loss: 3.6703 - val_accuracy: 0.6667\n",
      "Epoch 57/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6739 - accuracy: 0.7478 - val_loss: 3.6669 - val_accuracy: 0.6718\n",
      "Epoch 58/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6642 - accuracy: 0.7487 - val_loss: 4.0278 - val_accuracy: 0.4367\n",
      "Epoch 59/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7923 - accuracy: 0.7021 - val_loss: 3.5489 - val_accuracy: 0.6848\n",
      "Epoch 60/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6836 - accuracy: 0.7392 - val_loss: 3.7482 - val_accuracy: 0.5788\n",
      "Epoch 61/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7728 - accuracy: 0.7142 - val_loss: 3.5560 - val_accuracy: 0.7106\n",
      "Epoch 62/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6367 - accuracy: 0.7487 - val_loss: 3.5308 - val_accuracy: 0.6822\n",
      "Epoch 63/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6611 - accuracy: 0.7487 - val_loss: 3.7049 - val_accuracy: 0.6925\n",
      "Epoch 64/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6807 - accuracy: 0.7435 - val_loss: 3.7851 - val_accuracy: 0.6047\n",
      "Epoch 65/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8460 - accuracy: 0.6960 - val_loss: 4.3057 - val_accuracy: 0.5168\n",
      "Epoch 66/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.0807 - accuracy: 0.6347 - val_loss: 3.6352 - val_accuracy: 0.6537\n",
      "Epoch 67/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7005 - accuracy: 0.7478 - val_loss: 3.6539 - val_accuracy: 0.6202\n",
      "Epoch 68/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.0669 - accuracy: 0.6321 - val_loss: 4.0492 - val_accuracy: 0.5297\n",
      "Epoch 69/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.0906 - accuracy: 0.6036 - val_loss: 3.6945 - val_accuracy: 0.6744\n",
      "Epoch 70/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8714 - accuracy: 0.7003 - val_loss: 3.4225 - val_accuracy: 0.6641\n",
      "Epoch 71/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7437 - accuracy: 0.7245 - val_loss: 3.3522 - val_accuracy: 0.6408\n",
      "Epoch 72/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6894 - accuracy: 0.7461 - val_loss: 3.6300 - val_accuracy: 0.6227\n",
      "Epoch 73/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7668 - accuracy: 0.7142 - val_loss: 3.8739 - val_accuracy: 0.4470\n",
      "Epoch 74/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8711 - accuracy: 0.6822 - val_loss: 3.5353 - val_accuracy: 0.6822\n",
      "Epoch 75/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6977 - accuracy: 0.7504 - val_loss: 3.5070 - val_accuracy: 0.6486\n",
      "Epoch 76/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6738 - accuracy: 0.7427 - val_loss: 3.3310 - val_accuracy: 0.6899\n",
      "Epoch 77/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6475 - accuracy: 0.7530 - val_loss: 3.3733 - val_accuracy: 0.6512\n",
      "Epoch 78/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6708 - accuracy: 0.7392 - val_loss: 3.4543 - val_accuracy: 0.6408\n",
      "Epoch 79/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7062 - accuracy: 0.7522 - val_loss: 3.4131 - val_accuracy: 0.6770\n",
      "Epoch 80/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6389 - accuracy: 0.7453 - val_loss: 3.4315 - val_accuracy: 0.6951\n",
      "Epoch 81/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6458 - accuracy: 0.7556 - val_loss: 3.4179 - val_accuracy: 0.6667\n",
      "Epoch 82/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6716 - accuracy: 0.7418 - val_loss: 3.3858 - val_accuracy: 0.6925\n",
      "Epoch 83/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6403 - accuracy: 0.7582 - val_loss: 3.4855 - val_accuracy: 0.6486\n",
      "Epoch 84/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6363 - accuracy: 0.7556 - val_loss: 3.7452 - val_accuracy: 0.6150\n",
      "Epoch 85/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6564 - accuracy: 0.7453 - val_loss: 3.6550 - val_accuracy: 0.6512\n",
      "Epoch 86/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.7118 - accuracy: 0.7340 - val_loss: 3.5533 - val_accuracy: 0.6641\n",
      "Epoch 87/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7982 - accuracy: 0.7021 - val_loss: 3.5800 - val_accuracy: 0.6744\n",
      "Epoch 88/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6961 - accuracy: 0.7263 - val_loss: 3.6288 - val_accuracy: 0.6744\n",
      "Epoch 89/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6482 - accuracy: 0.7461 - val_loss: 3.6129 - val_accuracy: 0.6589\n",
      "Epoch 90/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6774 - accuracy: 0.7487 - val_loss: 3.7220 - val_accuracy: 0.6486\n",
      "Epoch 91/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6526 - accuracy: 0.7478 - val_loss: 3.6080 - val_accuracy: 0.6951\n",
      "Epoch 92/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6716 - accuracy: 0.7478 - val_loss: 3.6448 - val_accuracy: 0.6925\n",
      "Epoch 93/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6614 - accuracy: 0.7530 - val_loss: 3.6381 - val_accuracy: 0.6589\n",
      "Epoch 94/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7136 - accuracy: 0.7211 - val_loss: 3.9810 - val_accuracy: 0.6434\n",
      "Epoch 95/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7030 - accuracy: 0.7435 - val_loss: 4.1184 - val_accuracy: 0.5530\n",
      "Epoch 96/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6888 - accuracy: 0.7383 - val_loss: 3.6577 - val_accuracy: 0.6770\n",
      "Epoch 97/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.7065 - accuracy: 0.7237 - val_loss: 3.6291 - val_accuracy: 0.6641\n",
      "Epoch 98/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6993 - accuracy: 0.7470 - val_loss: 3.7568 - val_accuracy: 0.6770\n",
      "Epoch 99/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6862 - accuracy: 0.7366 - val_loss: 3.8012 - val_accuracy: 0.6848\n",
      "Epoch 100/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6634 - accuracy: 0.7496 - val_loss: 3.8779 - val_accuracy: 0.6047\n",
      "Epoch 101/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6382 - accuracy: 0.7720 - val_loss: 3.6923 - val_accuracy: 0.6486\n",
      "Epoch 102/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6215 - accuracy: 0.7686 - val_loss: 3.6625 - val_accuracy: 0.6615\n",
      "Epoch 103/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6972 - accuracy: 0.7401 - val_loss: 3.6659 - val_accuracy: 0.6589\n",
      "Epoch 104/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7008 - accuracy: 0.7383 - val_loss: 3.9556 - val_accuracy: 0.5013\n",
      "Epoch 105/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8181 - accuracy: 0.7090 - val_loss: 3.7641 - val_accuracy: 0.6460\n",
      "Epoch 106/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6912 - accuracy: 0.7427 - val_loss: 3.7564 - val_accuracy: 0.6486\n",
      "Epoch 107/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6943 - accuracy: 0.7487 - val_loss: 3.8422 - val_accuracy: 0.6072\n",
      "Epoch 108/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8419 - accuracy: 0.6805 - val_loss: 3.7123 - val_accuracy: 0.6512\n",
      "Epoch 109/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7548 - accuracy: 0.7211 - val_loss: 3.5687 - val_accuracy: 0.6460\n",
      "Epoch 110/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7266 - accuracy: 0.7263 - val_loss: 3.6676 - val_accuracy: 0.6667\n",
      "Epoch 111/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6319 - accuracy: 0.7617 - val_loss: 3.7149 - val_accuracy: 0.6796\n",
      "Epoch 112/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6469 - accuracy: 0.7487 - val_loss: 3.6304 - val_accuracy: 0.6563\n",
      "Epoch 113/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6209 - accuracy: 0.7547 - val_loss: 3.8610 - val_accuracy: 0.5840\n",
      "Epoch 114/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9646 - accuracy: 0.6408 - val_loss: 3.9858 - val_accuracy: 0.5762\n",
      "Epoch 115/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6841 - accuracy: 0.7444 - val_loss: 3.7000 - val_accuracy: 0.6563\n",
      "Epoch 116/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7668 - accuracy: 0.7280 - val_loss: 3.6220 - val_accuracy: 0.6563\n",
      "Epoch 117/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7002 - accuracy: 0.7271 - val_loss: 3.7593 - val_accuracy: 0.6589\n",
      "Epoch 118/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8461 - accuracy: 0.6874 - val_loss: 4.0082 - val_accuracy: 0.5581\n",
      "Epoch 119/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8888 - accuracy: 0.6632 - val_loss: 3.7329 - val_accuracy: 0.6253\n",
      "Epoch 120/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6868 - accuracy: 0.7392 - val_loss: 3.5923 - val_accuracy: 0.6512\n",
      "Epoch 121/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6365 - accuracy: 0.7435 - val_loss: 3.5281 - val_accuracy: 0.6589\n",
      "Epoch 122/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6145 - accuracy: 0.7599 - val_loss: 3.5647 - val_accuracy: 0.6589\n",
      "Epoch 123/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6027 - accuracy: 0.7660 - val_loss: 3.5628 - val_accuracy: 0.6460\n",
      "Epoch 124/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6454 - accuracy: 0.7703 - val_loss: 3.5396 - val_accuracy: 0.6693\n",
      "Epoch 125/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6313 - accuracy: 0.7565 - val_loss: 3.4389 - val_accuracy: 0.6641\n",
      "Epoch 126/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5918 - accuracy: 0.7798 - val_loss: 3.5321 - val_accuracy: 0.6770\n",
      "Epoch 127/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6264 - accuracy: 0.7694 - val_loss: 3.5620 - val_accuracy: 0.6899\n",
      "Epoch 128/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6691 - accuracy: 0.7625 - val_loss: 3.6151 - val_accuracy: 0.6589\n",
      "Epoch 129/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6602 - accuracy: 0.7444 - val_loss: 3.7086 - val_accuracy: 0.6537\n",
      "Epoch 130/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6183 - accuracy: 0.7660 - val_loss: 3.5776 - val_accuracy: 0.6899\n",
      "Epoch 131/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6068 - accuracy: 0.7729 - val_loss: 3.6612 - val_accuracy: 0.6693\n",
      "Epoch 132/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9851 - accuracy: 0.6356 - val_loss: 4.9224 - val_accuracy: 0.4961\n",
      "Epoch 133/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9768 - accuracy: 0.6969 - val_loss: 3.7197 - val_accuracy: 0.6460\n",
      "Epoch 134/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6873 - accuracy: 0.7504 - val_loss: 3.6033 - val_accuracy: 0.6667\n",
      "Epoch 135/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6360 - accuracy: 0.7435 - val_loss: 3.6395 - val_accuracy: 0.6718\n",
      "Epoch 136/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6143 - accuracy: 0.7703 - val_loss: 3.7915 - val_accuracy: 0.6512\n",
      "Epoch 137/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8107 - accuracy: 0.7107 - val_loss: 4.7186 - val_accuracy: 0.4677\n",
      "Epoch 138/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9819 - accuracy: 0.6598 - val_loss: 3.8123 - val_accuracy: 0.5840\n",
      "Epoch 139/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.1724 - accuracy: 0.5984 - val_loss: 3.5915 - val_accuracy: 0.6822\n",
      "Epoch 140/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7003 - accuracy: 0.7608 - val_loss: 3.4016 - val_accuracy: 0.6641\n",
      "Epoch 141/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6550 - accuracy: 0.7547 - val_loss: 3.3835 - val_accuracy: 0.6615\n",
      "Epoch 142/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6366 - accuracy: 0.7573 - val_loss: 3.3543 - val_accuracy: 0.6563\n",
      "Epoch 143/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6193 - accuracy: 0.7599 - val_loss: 3.2436 - val_accuracy: 0.6873\n",
      "Epoch 144/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6272 - accuracy: 0.7565 - val_loss: 3.2567 - val_accuracy: 0.6744\n",
      "Epoch 145/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6165 - accuracy: 0.7496 - val_loss: 3.1833 - val_accuracy: 0.6770\n",
      "Epoch 146/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6089 - accuracy: 0.7591 - val_loss: 3.5173 - val_accuracy: 0.5142\n",
      "Epoch 147/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7907 - accuracy: 0.7003 - val_loss: 3.2901 - val_accuracy: 0.6641\n",
      "Epoch 148/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6912 - accuracy: 0.7427 - val_loss: 3.4802 - val_accuracy: 0.5814\n",
      "Epoch 149/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6553 - accuracy: 0.7504 - val_loss: 3.2182 - val_accuracy: 0.6796\n",
      "Epoch 150/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6157 - accuracy: 0.7547 - val_loss: 3.1554 - val_accuracy: 0.6718\n",
      "Epoch 151/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6339 - accuracy: 0.7625 - val_loss: 3.0607 - val_accuracy: 0.6615\n",
      "Epoch 152/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5881 - accuracy: 0.7642 - val_loss: 3.1462 - val_accuracy: 0.6486\n",
      "Epoch 153/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8183 - accuracy: 0.6952 - val_loss: 4.5099 - val_accuracy: 0.4755\n",
      "Epoch 154/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.4094 - accuracy: 0.6209 - val_loss: 4.8712 - val_accuracy: 0.2119\n",
      "Epoch 155/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.0010 - accuracy: 0.6649 - val_loss: 4.0140 - val_accuracy: 0.6486\n",
      "Epoch 156/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.1299 - accuracy: 0.6330 - val_loss: 1.9880 - val_accuracy: 0.6047\n",
      "Epoch 157/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9600 - accuracy: 0.6710 - val_loss: 6.5912 - val_accuracy: 0.6770\n",
      "Epoch 158/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6732 - accuracy: 0.7556 - val_loss: 5.6888 - val_accuracy: 0.6357\n",
      "Epoch 159/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7798 - accuracy: 0.7375 - val_loss: 7.2042 - val_accuracy: 0.4599\n",
      "Epoch 160/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8206 - accuracy: 0.7185 - val_loss: 5.4384 - val_accuracy: 0.6563\n",
      "Epoch 161/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6562 - accuracy: 0.7306 - val_loss: 5.0731 - val_accuracy: 0.6693\n",
      "Epoch 162/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7481 - accuracy: 0.7254 - val_loss: 5.1489 - val_accuracy: 0.6563\n",
      "Epoch 163/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8433 - accuracy: 0.6926 - val_loss: 5.5386 - val_accuracy: 0.5685\n",
      "Epoch 164/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8884 - accuracy: 0.6693 - val_loss: 5.0661 - val_accuracy: 0.6641\n",
      "Epoch 165/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6875 - accuracy: 0.7547 - val_loss: 5.1902 - val_accuracy: 0.6434\n",
      "Epoch 166/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7473 - accuracy: 0.7081 - val_loss: 5.3799 - val_accuracy: 0.5891\n",
      "Epoch 167/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6943 - accuracy: 0.7340 - val_loss: 5.2274 - val_accuracy: 0.6744\n",
      "Epoch 168/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6223 - accuracy: 0.7694 - val_loss: 5.1336 - val_accuracy: 0.6770\n",
      "Epoch 169/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6195 - accuracy: 0.7453 - val_loss: 5.2083 - val_accuracy: 0.7080\n",
      "Epoch 170/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6055 - accuracy: 0.7642 - val_loss: 5.3191 - val_accuracy: 0.6641\n",
      "Epoch 171/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6624 - accuracy: 0.7496 - val_loss: 5.2865 - val_accuracy: 0.6770\n",
      "Epoch 172/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6626 - accuracy: 0.7453 - val_loss: 5.4942 - val_accuracy: 0.6873\n",
      "Epoch 173/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7148 - accuracy: 0.7340 - val_loss: 5.4322 - val_accuracy: 0.6770\n",
      "Epoch 174/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6817 - accuracy: 0.7608 - val_loss: 5.4123 - val_accuracy: 0.6951\n",
      "Epoch 175/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6957 - accuracy: 0.7530 - val_loss: 5.4975 - val_accuracy: 0.6382\n",
      "Epoch 176/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6458 - accuracy: 0.7435 - val_loss: 5.3901 - val_accuracy: 0.7106\n",
      "Epoch 177/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6453 - accuracy: 0.7496 - val_loss: 5.4215 - val_accuracy: 0.6615\n",
      "Epoch 178/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6534 - accuracy: 0.7522 - val_loss: 5.3019 - val_accuracy: 0.6718\n",
      "Epoch 179/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6571 - accuracy: 0.7522 - val_loss: 6.0700 - val_accuracy: 0.4393\n",
      "Epoch 180/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8174 - accuracy: 0.6788 - val_loss: 5.3512 - val_accuracy: 0.7003\n",
      "Epoch 181/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6636 - accuracy: 0.7461 - val_loss: 5.5087 - val_accuracy: 0.7003\n",
      "Epoch 182/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6212 - accuracy: 0.7712 - val_loss: 5.3212 - val_accuracy: 0.6925\n",
      "Epoch 183/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5912 - accuracy: 0.7746 - val_loss: 5.2617 - val_accuracy: 0.7235\n",
      "Epoch 184/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6251 - accuracy: 0.7625 - val_loss: 5.3454 - val_accuracy: 0.6563\n",
      "Epoch 185/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6087 - accuracy: 0.7668 - val_loss: 5.4338 - val_accuracy: 0.6589\n",
      "Epoch 186/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6220 - accuracy: 0.7625 - val_loss: 5.3876 - val_accuracy: 0.6848\n",
      "Epoch 187/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5844 - accuracy: 0.7660 - val_loss: 5.3625 - val_accuracy: 0.7054\n",
      "Epoch 188/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6168 - accuracy: 0.7694 - val_loss: 5.5319 - val_accuracy: 0.6460\n",
      "Epoch 189/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6270 - accuracy: 0.7522 - val_loss: 5.7713 - val_accuracy: 0.5711\n",
      "Epoch 190/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9906 - accuracy: 0.6278 - val_loss: 6.2557 - val_accuracy: 0.4961\n",
      "Epoch 191/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.1669 - accuracy: 0.6157 - val_loss: 6.1188 - val_accuracy: 0.5013\n",
      "Epoch 192/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8241 - accuracy: 0.6978 - val_loss: 5.4061 - val_accuracy: 0.6718\n",
      "Epoch 193/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6465 - accuracy: 0.7418 - val_loss: 5.3593 - val_accuracy: 0.6718\n",
      "Epoch 194/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6387 - accuracy: 0.7677 - val_loss: 5.4062 - val_accuracy: 0.6537\n",
      "Epoch 195/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6109 - accuracy: 0.7755 - val_loss: 5.3102 - val_accuracy: 0.6770\n",
      "Epoch 196/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5934 - accuracy: 0.7798 - val_loss: 5.3217 - val_accuracy: 0.6925\n",
      "Epoch 197/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5991 - accuracy: 0.7608 - val_loss: 5.3226 - val_accuracy: 0.7054\n",
      "Epoch 198/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5652 - accuracy: 0.7729 - val_loss: 5.5328 - val_accuracy: 0.6512\n",
      "Epoch 199/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5974 - accuracy: 0.7807 - val_loss: 5.5545 - val_accuracy: 0.6770\n",
      "Epoch 200/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5809 - accuracy: 0.7815 - val_loss: 5.5270 - val_accuracy: 0.6848\n",
      "Epoch 201/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5898 - accuracy: 0.7850 - val_loss: 5.7156 - val_accuracy: 0.5478\n",
      "Epoch 202/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9127 - accuracy: 0.6598 - val_loss: 6.0598 - val_accuracy: 0.5917\n",
      "Epoch 203/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6611 - accuracy: 0.7504 - val_loss: 5.7774 - val_accuracy: 0.6899\n",
      "Epoch 204/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5833 - accuracy: 0.7746 - val_loss: 5.7067 - val_accuracy: 0.6951\n",
      "Epoch 205/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6125 - accuracy: 0.7686 - val_loss: 5.7443 - val_accuracy: 0.7209\n",
      "Epoch 206/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5770 - accuracy: 0.7841 - val_loss: 5.8719 - val_accuracy: 0.6667\n",
      "Epoch 207/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5952 - accuracy: 0.7789 - val_loss: 5.9460 - val_accuracy: 0.6641\n",
      "Epoch 208/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6962 - accuracy: 0.7522 - val_loss: 6.5645 - val_accuracy: 0.5788\n",
      "Epoch 209/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7705 - accuracy: 0.7254 - val_loss: 6.6791 - val_accuracy: 0.4832\n",
      "Epoch 210/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7528 - accuracy: 0.7116 - val_loss: 6.5441 - val_accuracy: 0.4341\n",
      "Epoch 211/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8024 - accuracy: 0.7047 - val_loss: 6.2207 - val_accuracy: 0.7158\n",
      "Epoch 212/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6163 - accuracy: 0.7487 - val_loss: 6.2980 - val_accuracy: 0.6589\n",
      "Epoch 213/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6298 - accuracy: 0.7617 - val_loss: 6.1461 - val_accuracy: 0.7132\n",
      "Epoch 214/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7062 - accuracy: 0.7383 - val_loss: 6.4715 - val_accuracy: 0.5814\n",
      "Epoch 215/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6759 - accuracy: 0.7513 - val_loss: 6.0119 - val_accuracy: 0.6770\n",
      "Epoch 216/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6120 - accuracy: 0.7634 - val_loss: 6.3930 - val_accuracy: 0.6150\n",
      "Epoch 217/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5976 - accuracy: 0.7824 - val_loss: 6.4562 - val_accuracy: 0.6589\n",
      "Epoch 218/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6806 - accuracy: 0.7444 - val_loss: 6.3414 - val_accuracy: 0.6822\n",
      "Epoch 219/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5736 - accuracy: 0.7720 - val_loss: 6.3109 - val_accuracy: 0.7209\n",
      "Epoch 220/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5915 - accuracy: 0.7634 - val_loss: 6.2666 - val_accuracy: 0.6977\n",
      "Epoch 221/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6298 - accuracy: 0.7660 - val_loss: 6.1974 - val_accuracy: 0.7158\n",
      "Epoch 222/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5813 - accuracy: 0.7807 - val_loss: 6.1576 - val_accuracy: 0.6899\n",
      "Epoch 223/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5637 - accuracy: 0.7832 - val_loss: 6.2589 - val_accuracy: 0.6796\n",
      "Epoch 224/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5673 - accuracy: 0.8022 - val_loss: 6.1030 - val_accuracy: 0.7106\n",
      "Epoch 225/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5784 - accuracy: 0.7763 - val_loss: 6.1923 - val_accuracy: 0.6925\n",
      "Epoch 226/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5554 - accuracy: 0.7755 - val_loss: 6.3209 - val_accuracy: 0.6693\n",
      "Epoch 227/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6228 - accuracy: 0.7625 - val_loss: 6.2261 - val_accuracy: 0.6951\n",
      "Epoch 228/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5905 - accuracy: 0.7807 - val_loss: 6.3095 - val_accuracy: 0.7235\n",
      "Epoch 229/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5552 - accuracy: 0.7945 - val_loss: 6.4789 - val_accuracy: 0.6615\n",
      "Epoch 230/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5956 - accuracy: 0.7772 - val_loss: 6.3611 - val_accuracy: 0.7054\n",
      "Epoch 231/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5654 - accuracy: 0.7772 - val_loss: 6.6598 - val_accuracy: 0.6460\n",
      "Epoch 232/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7109 - accuracy: 0.7383 - val_loss: 6.7298 - val_accuracy: 0.6408\n",
      "Epoch 233/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6501 - accuracy: 0.7245 - val_loss: 6.5807 - val_accuracy: 0.7003\n",
      "Epoch 234/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6212 - accuracy: 0.7781 - val_loss: 6.5390 - val_accuracy: 0.7132\n",
      "Epoch 235/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5428 - accuracy: 0.8014 - val_loss: 6.5916 - val_accuracy: 0.7054\n",
      "Epoch 236/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5454 - accuracy: 0.7850 - val_loss: 7.0223 - val_accuracy: 0.5762\n",
      "Epoch 237/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5718 - accuracy: 0.7720 - val_loss: 6.6399 - val_accuracy: 0.6718\n",
      "Epoch 238/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6858 - accuracy: 0.7332 - val_loss: 6.5646 - val_accuracy: 0.7158\n",
      "Epoch 239/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5875 - accuracy: 0.7781 - val_loss: 7.0836 - val_accuracy: 0.5039\n",
      "Epoch 240/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6034 - accuracy: 0.7746 - val_loss: 6.7812 - val_accuracy: 0.6331\n",
      "Epoch 241/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5779 - accuracy: 0.7815 - val_loss: 6.7065 - val_accuracy: 0.6667\n",
      "Epoch 242/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6441 - accuracy: 0.7617 - val_loss: 6.7869 - val_accuracy: 0.6822\n",
      "Epoch 243/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7176 - accuracy: 0.7254 - val_loss: 6.7334 - val_accuracy: 0.7132\n",
      "Epoch 244/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6717 - accuracy: 0.7383 - val_loss: 6.5559 - val_accuracy: 0.7106\n",
      "Epoch 245/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.8347 - accuracy: 0.6943 - val_loss: 6.5116 - val_accuracy: 0.7003\n",
      "Epoch 246/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6636 - accuracy: 0.7461 - val_loss: 6.2816 - val_accuracy: 0.6718\n",
      "Epoch 247/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5654 - accuracy: 0.7850 - val_loss: 6.5609 - val_accuracy: 0.7209\n",
      "Epoch 248/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5897 - accuracy: 0.7953 - val_loss: 6.6811 - val_accuracy: 0.6925\n",
      "Epoch 249/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6194 - accuracy: 0.7677 - val_loss: 6.4923 - val_accuracy: 0.7183\n",
      "Epoch 250/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5730 - accuracy: 0.7884 - val_loss: 6.8254 - val_accuracy: 0.6693\n",
      "Epoch 251/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6399 - accuracy: 0.7599 - val_loss: 6.8483 - val_accuracy: 0.7183\n",
      "Epoch 252/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5600 - accuracy: 0.7945 - val_loss: 6.9438 - val_accuracy: 0.7106\n",
      "Epoch 253/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5307 - accuracy: 0.7927 - val_loss: 7.0925 - val_accuracy: 0.6563\n",
      "Epoch 254/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5821 - accuracy: 0.7694 - val_loss: 7.1387 - val_accuracy: 0.6434\n",
      "Epoch 255/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5997 - accuracy: 0.7772 - val_loss: 7.1209 - val_accuracy: 0.6873\n",
      "Epoch 256/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6068 - accuracy: 0.7634 - val_loss: 7.0512 - val_accuracy: 0.6822\n",
      "Epoch 257/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5286 - accuracy: 0.7927 - val_loss: 7.0234 - val_accuracy: 0.7003\n",
      "Epoch 258/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5493 - accuracy: 0.7945 - val_loss: 7.1480 - val_accuracy: 0.7209\n",
      "Epoch 259/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6814 - accuracy: 0.7306 - val_loss: 7.6509 - val_accuracy: 0.5116\n",
      "Epoch 260/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6126 - accuracy: 0.7651 - val_loss: 7.2632 - val_accuracy: 0.6537\n",
      "Epoch 261/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5306 - accuracy: 0.7979 - val_loss: 7.1912 - val_accuracy: 0.7054\n",
      "Epoch 262/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5567 - accuracy: 0.7884 - val_loss: 7.1034 - val_accuracy: 0.6977\n",
      "Epoch 263/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5831 - accuracy: 0.7642 - val_loss: 7.0559 - val_accuracy: 0.6667\n",
      "Epoch 264/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5593 - accuracy: 0.7876 - val_loss: 7.2417 - val_accuracy: 0.7313\n",
      "Epoch 265/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5686 - accuracy: 0.7858 - val_loss: 7.2815 - val_accuracy: 0.6718\n",
      "Epoch 266/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5510 - accuracy: 0.7945 - val_loss: 7.0687 - val_accuracy: 0.7313\n",
      "Epoch 267/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5116 - accuracy: 0.8109 - val_loss: 7.1372 - val_accuracy: 0.7339\n",
      "Epoch 268/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5179 - accuracy: 0.8109 - val_loss: 7.2339 - val_accuracy: 0.6925\n",
      "Epoch 269/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5025 - accuracy: 0.8066 - val_loss: 7.2390 - val_accuracy: 0.7158\n",
      "Epoch 270/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5070 - accuracy: 0.8048 - val_loss: 7.2157 - val_accuracy: 0.7028\n",
      "Epoch 271/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5024 - accuracy: 0.8169 - val_loss: 7.4266 - val_accuracy: 0.6537\n",
      "Epoch 272/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6337 - accuracy: 0.7556 - val_loss: 7.9987 - val_accuracy: 0.4341\n",
      "Epoch 273/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9121 - accuracy: 0.6649 - val_loss: 7.3536 - val_accuracy: 0.6615\n",
      "Epoch 274/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6566 - accuracy: 0.7556 - val_loss: 7.5972 - val_accuracy: 0.6253\n",
      "Epoch 275/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5964 - accuracy: 0.7660 - val_loss: 7.5981 - val_accuracy: 0.6279\n",
      "Epoch 276/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6245 - accuracy: 0.7720 - val_loss: 7.5241 - val_accuracy: 0.6589\n",
      "Epoch 277/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5876 - accuracy: 0.7694 - val_loss: 7.5618 - val_accuracy: 0.6615\n",
      "Epoch 278/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5901 - accuracy: 0.7703 - val_loss: 7.5240 - val_accuracy: 0.6512\n",
      "Epoch 279/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7304 - accuracy: 0.7038 - val_loss: 8.2566 - val_accuracy: 0.4651\n",
      "Epoch 280/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.1752 - accuracy: 0.6727 - val_loss: 7.5230 - val_accuracy: 0.6512\n",
      "Epoch 281/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6927 - accuracy: 0.7358 - val_loss: 7.1017 - val_accuracy: 0.6693\n",
      "Epoch 282/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6033 - accuracy: 0.7634 - val_loss: 7.0521 - val_accuracy: 0.6537\n",
      "Epoch 283/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5628 - accuracy: 0.7781 - val_loss: 7.1074 - val_accuracy: 0.6512\n",
      "Epoch 284/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5325 - accuracy: 0.7893 - val_loss: 7.4476 - val_accuracy: 0.5013\n",
      "Epoch 285/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6947 - accuracy: 0.7185 - val_loss: 7.6033 - val_accuracy: 0.5013\n",
      "Epoch 286/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7803 - accuracy: 0.7021 - val_loss: 6.9590 - val_accuracy: 0.7003\n",
      "Epoch 287/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6114 - accuracy: 0.7504 - val_loss: 7.0143 - val_accuracy: 0.6744\n",
      "Epoch 288/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5277 - accuracy: 0.7910 - val_loss: 6.9836 - val_accuracy: 0.7364\n",
      "Epoch 289/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5166 - accuracy: 0.8152 - val_loss: 7.0600 - val_accuracy: 0.6899\n",
      "Epoch 290/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5376 - accuracy: 0.7953 - val_loss: 7.9541 - val_accuracy: 0.4574\n",
      "Epoch 291/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.0074 - accuracy: 0.6278 - val_loss: 8.3638 - val_accuracy: 0.4341\n",
      "Epoch 292/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.9802 - accuracy: 0.6477 - val_loss: 7.2714 - val_accuracy: 0.5685\n",
      "Epoch 293/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8128 - accuracy: 0.6900 - val_loss: 7.0226 - val_accuracy: 0.6667\n",
      "Epoch 294/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6244 - accuracy: 0.7556 - val_loss: 6.9752 - val_accuracy: 0.7080\n",
      "Epoch 295/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5452 - accuracy: 0.7858 - val_loss: 7.0362 - val_accuracy: 0.6822\n",
      "Epoch 296/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5496 - accuracy: 0.7988 - val_loss: 7.0384 - val_accuracy: 0.7080\n",
      "Epoch 297/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5483 - accuracy: 0.7910 - val_loss: 7.1074 - val_accuracy: 0.7235\n",
      "Epoch 298/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4973 - accuracy: 0.8100 - val_loss: 6.8435 - val_accuracy: 0.6770\n",
      "Epoch 299/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6333 - accuracy: 0.7625 - val_loss: 7.2119 - val_accuracy: 0.7080\n",
      "Epoch 300/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5037 - accuracy: 0.8083 - val_loss: 7.4473 - val_accuracy: 0.6563\n",
      "Epoch 301/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5216 - accuracy: 0.8005 - val_loss: 7.3903 - val_accuracy: 0.7106\n",
      "Epoch 302/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4962 - accuracy: 0.8195 - val_loss: 7.3913 - val_accuracy: 0.6951\n",
      "Epoch 303/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5020 - accuracy: 0.8100 - val_loss: 7.3180 - val_accuracy: 0.7132\n",
      "Epoch 304/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5072 - accuracy: 0.7997 - val_loss: 7.3822 - val_accuracy: 0.6977\n",
      "Epoch 305/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5381 - accuracy: 0.7876 - val_loss: 7.3060 - val_accuracy: 0.6718\n",
      "Epoch 306/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4929 - accuracy: 0.7971 - val_loss: 7.1862 - val_accuracy: 0.6589\n",
      "Epoch 307/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4980 - accuracy: 0.7979 - val_loss: 7.2524 - val_accuracy: 0.7416\n",
      "Epoch 308/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4924 - accuracy: 0.8135 - val_loss: 7.2936 - val_accuracy: 0.7519\n",
      "Epoch 309/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.8092 - val_loss: 7.2615 - val_accuracy: 0.7106\n",
      "Epoch 310/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5190 - accuracy: 0.7945 - val_loss: 7.2467 - val_accuracy: 0.7158\n",
      "Epoch 311/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4972 - accuracy: 0.8092 - val_loss: 7.6366 - val_accuracy: 0.6537\n",
      "Epoch 312/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5753 - accuracy: 0.7789 - val_loss: 7.1856 - val_accuracy: 0.7080\n",
      "Epoch 313/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5000 - accuracy: 0.7997 - val_loss: 7.1796 - val_accuracy: 0.7209\n",
      "Epoch 314/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.8187 - val_loss: 7.2547 - val_accuracy: 0.7132\n",
      "Epoch 315/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4900 - accuracy: 0.7962 - val_loss: 6.9926 - val_accuracy: 0.7261\n",
      "Epoch 316/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5021 - accuracy: 0.8109 - val_loss: 7.2308 - val_accuracy: 0.7080\n",
      "Epoch 317/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5422 - accuracy: 0.7832 - val_loss: 7.0259 - val_accuracy: 0.7132\n",
      "Epoch 318/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4970 - accuracy: 0.8143 - val_loss: 7.0560 - val_accuracy: 0.6615\n",
      "Epoch 319/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5100 - accuracy: 0.7979 - val_loss: 7.1899 - val_accuracy: 0.6331\n",
      "Epoch 320/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6314 - accuracy: 0.7504 - val_loss: 7.2955 - val_accuracy: 0.6977\n",
      "Epoch 321/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5395 - accuracy: 0.7910 - val_loss: 7.0049 - val_accuracy: 0.6977\n",
      "Epoch 322/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4838 - accuracy: 0.7962 - val_loss: 7.1761 - val_accuracy: 0.7183\n",
      "Epoch 323/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4753 - accuracy: 0.8169 - val_loss: 7.3468 - val_accuracy: 0.6408\n",
      "Epoch 324/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5073 - accuracy: 0.8005 - val_loss: 7.1099 - val_accuracy: 0.7313\n",
      "Epoch 325/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5245 - accuracy: 0.7988 - val_loss: 7.3428 - val_accuracy: 0.6977\n",
      "Epoch 326/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6230 - accuracy: 0.7513 - val_loss: 6.9631 - val_accuracy: 0.7390\n",
      "Epoch 327/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7212 - accuracy: 0.7530 - val_loss: 6.8066 - val_accuracy: 0.4238\n",
      "Epoch 328/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8500 - accuracy: 0.6503 - val_loss: 5.2493 - val_accuracy: 0.7003\n",
      "Epoch 329/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.7031 - accuracy: 0.7496 - val_loss: 3.4949 - val_accuracy: 0.6899\n",
      "Epoch 330/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7570 - accuracy: 0.7263 - val_loss: 4.4004 - val_accuracy: 0.4884\n",
      "Epoch 331/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.5678 - accuracy: 0.5838 - val_loss: 3.2401 - val_accuracy: 0.5581\n",
      "Epoch 332/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6668 - accuracy: 0.7530 - val_loss: 3.4208 - val_accuracy: 0.7313\n",
      "Epoch 333/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5421 - accuracy: 0.8014 - val_loss: 3.4170 - val_accuracy: 0.6822\n",
      "Epoch 334/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6010 - accuracy: 0.7547 - val_loss: 3.5095 - val_accuracy: 0.6537\n",
      "Epoch 335/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5991 - accuracy: 0.7651 - val_loss: 3.2935 - val_accuracy: 0.7416\n",
      "Epoch 336/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5625 - accuracy: 0.7815 - val_loss: 3.4004 - val_accuracy: 0.7235\n",
      "Epoch 337/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5131 - accuracy: 0.8057 - val_loss: 3.5871 - val_accuracy: 0.5814\n",
      "Epoch 338/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6249 - accuracy: 0.7556 - val_loss: 3.4282 - val_accuracy: 0.7209\n",
      "Epoch 339/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5678 - accuracy: 0.7824 - val_loss: 3.5071 - val_accuracy: 0.6796\n",
      "Epoch 340/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7830 - accuracy: 0.6839 - val_loss: 3.4320 - val_accuracy: 0.7339\n",
      "Epoch 341/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5233 - accuracy: 0.7979 - val_loss: 3.5496 - val_accuracy: 0.7287\n",
      "Epoch 342/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5457 - accuracy: 0.7824 - val_loss: 3.7895 - val_accuracy: 0.5504\n",
      "Epoch 343/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5433 - accuracy: 0.7945 - val_loss: 3.4060 - val_accuracy: 0.7287\n",
      "Epoch 344/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5168 - accuracy: 0.7988 - val_loss: 3.4076 - val_accuracy: 0.7183\n",
      "Epoch 345/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5390 - accuracy: 0.8040 - val_loss: 3.4136 - val_accuracy: 0.6822\n",
      "Epoch 346/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4995 - accuracy: 0.8100 - val_loss: 3.4557 - val_accuracy: 0.7183\n",
      "Epoch 347/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5011 - accuracy: 0.8117 - val_loss: 3.7075 - val_accuracy: 0.5840\n",
      "Epoch 348/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5367 - accuracy: 0.8048 - val_loss: 3.4767 - val_accuracy: 0.7106\n",
      "Epoch 349/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.7988 - val_loss: 3.5094 - val_accuracy: 0.7080\n",
      "Epoch 350/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5142 - accuracy: 0.8083 - val_loss: 3.5400 - val_accuracy: 0.7209\n",
      "Epoch 351/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5137 - accuracy: 0.8066 - val_loss: 3.5126 - val_accuracy: 0.7442\n",
      "Epoch 352/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5117 - accuracy: 0.8066 - val_loss: 3.5345 - val_accuracy: 0.7235\n",
      "Epoch 353/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5443 - accuracy: 0.7824 - val_loss: 3.6158 - val_accuracy: 0.6873\n",
      "Epoch 354/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4883 - accuracy: 0.8057 - val_loss: 3.6324 - val_accuracy: 0.6770\n",
      "Epoch 355/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4634 - accuracy: 0.8212 - val_loss: 3.9699 - val_accuracy: 0.5633\n",
      "Epoch 356/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6289 - accuracy: 0.7651 - val_loss: 3.7057 - val_accuracy: 0.6848\n",
      "Epoch 357/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6701 - accuracy: 0.7617 - val_loss: 3.6835 - val_accuracy: 0.6718\n",
      "Epoch 358/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5238 - accuracy: 0.7953 - val_loss: 3.9010 - val_accuracy: 0.6098\n",
      "Epoch 359/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5685 - accuracy: 0.7815 - val_loss: 4.0748 - val_accuracy: 0.5065\n",
      "Epoch 360/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6574 - accuracy: 0.7401 - val_loss: 3.5785 - val_accuracy: 0.7106\n",
      "Epoch 361/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5038 - accuracy: 0.7936 - val_loss: 3.6990 - val_accuracy: 0.6667\n",
      "Epoch 362/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5025 - accuracy: 0.7988 - val_loss: 3.6179 - val_accuracy: 0.7106\n",
      "Epoch 363/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5073 - accuracy: 0.7876 - val_loss: 3.6788 - val_accuracy: 0.7313\n",
      "Epoch 364/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4818 - accuracy: 0.8083 - val_loss: 3.8028 - val_accuracy: 0.6615\n",
      "Epoch 365/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5942 - accuracy: 0.7737 - val_loss: 3.5403 - val_accuracy: 0.7235\n",
      "Epoch 366/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4858 - accuracy: 0.8187 - val_loss: 3.7203 - val_accuracy: 0.6667\n",
      "Epoch 367/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5031 - accuracy: 0.8074 - val_loss: 3.5861 - val_accuracy: 0.7235\n",
      "Epoch 368/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6066 - accuracy: 0.7625 - val_loss: 3.8237 - val_accuracy: 0.6977\n",
      "Epoch 369/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5041 - accuracy: 0.7997 - val_loss: 3.7791 - val_accuracy: 0.6589\n",
      "Epoch 370/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5732 - accuracy: 0.7617 - val_loss: 3.8348 - val_accuracy: 0.6563\n",
      "Epoch 371/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5709 - accuracy: 0.7737 - val_loss: 3.5493 - val_accuracy: 0.7028\n",
      "Epoch 372/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4583 - accuracy: 0.8221 - val_loss: 3.5730 - val_accuracy: 0.7313\n",
      "Epoch 373/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5054 - accuracy: 0.7997 - val_loss: 4.2442 - val_accuracy: 0.4935\n",
      "Epoch 374/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6400 - accuracy: 0.7349 - val_loss: 4.5390 - val_accuracy: 0.4367\n",
      "Epoch 375/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8510 - accuracy: 0.6865 - val_loss: 3.6356 - val_accuracy: 0.6899\n",
      "Epoch 376/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5902 - accuracy: 0.7694 - val_loss: 3.7899 - val_accuracy: 0.6512\n",
      "Epoch 377/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4943 - accuracy: 0.8100 - val_loss: 3.7651 - val_accuracy: 0.7132\n",
      "Epoch 378/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4966 - accuracy: 0.7945 - val_loss: 3.7660 - val_accuracy: 0.6693\n",
      "Epoch 379/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4731 - accuracy: 0.8100 - val_loss: 3.7243 - val_accuracy: 0.7339\n",
      "Epoch 380/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4805 - accuracy: 0.8092 - val_loss: 4.5725 - val_accuracy: 0.4496\n",
      "Epoch 381/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7112 - accuracy: 0.7297 - val_loss: 4.4712 - val_accuracy: 0.4522\n",
      "Epoch 382/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7544 - accuracy: 0.6839 - val_loss: 4.2394 - val_accuracy: 0.5607\n",
      "Epoch 383/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4954 - accuracy: 0.8014 - val_loss: 3.8551 - val_accuracy: 0.7080\n",
      "Epoch 384/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4562 - accuracy: 0.8264 - val_loss: 3.8741 - val_accuracy: 0.6770\n",
      "Epoch 385/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4590 - accuracy: 0.8282 - val_loss: 3.8154 - val_accuracy: 0.6873\n",
      "Epoch 386/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4703 - accuracy: 0.8282 - val_loss: 4.0423 - val_accuracy: 0.6512\n",
      "Epoch 387/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5004 - accuracy: 0.7997 - val_loss: 3.8224 - val_accuracy: 0.7054\n",
      "Epoch 388/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4925 - accuracy: 0.8135 - val_loss: 3.8664 - val_accuracy: 0.7261\n",
      "Epoch 389/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4540 - accuracy: 0.8143 - val_loss: 3.9946 - val_accuracy: 0.6770\n",
      "Epoch 390/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5835 - accuracy: 0.7746 - val_loss: 3.9411 - val_accuracy: 0.7390\n",
      "Epoch 391/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4436 - accuracy: 0.8282 - val_loss: 3.9924 - val_accuracy: 0.7106\n",
      "Epoch 392/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4912 - accuracy: 0.8230 - val_loss: 4.0739 - val_accuracy: 0.7183\n",
      "Epoch 393/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4964 - accuracy: 0.8100 - val_loss: 4.8635 - val_accuracy: 0.4367\n",
      "Epoch 394/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8783 - accuracy: 0.6615 - val_loss: 4.1122 - val_accuracy: 0.6796\n",
      "Epoch 395/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5054 - accuracy: 0.8040 - val_loss: 4.2911 - val_accuracy: 0.7028\n",
      "Epoch 396/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4665 - accuracy: 0.8256 - val_loss: 4.1391 - val_accuracy: 0.7339\n",
      "Epoch 397/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.8212 - val_loss: 4.1200 - val_accuracy: 0.7339\n",
      "Epoch 398/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.8264 - val_loss: 4.1959 - val_accuracy: 0.7364\n",
      "Epoch 399/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4581 - accuracy: 0.8299 - val_loss: 4.1033 - val_accuracy: 0.7339\n",
      "Epoch 400/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4426 - accuracy: 0.8325 - val_loss: 4.4087 - val_accuracy: 0.6486\n",
      "Epoch 401/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4738 - accuracy: 0.8048 - val_loss: 4.3621 - val_accuracy: 0.6512\n",
      "Epoch 402/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5891 - accuracy: 0.7876 - val_loss: 4.7054 - val_accuracy: 0.5375\n",
      "Epoch 403/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4597 - accuracy: 0.8273 - val_loss: 4.2546 - val_accuracy: 0.7313\n",
      "Epoch 404/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4285 - accuracy: 0.8342 - val_loss: 4.4169 - val_accuracy: 0.7287\n",
      "Epoch 405/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.8325 - val_loss: 4.3710 - val_accuracy: 0.7235\n",
      "Epoch 406/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4591 - accuracy: 0.8212 - val_loss: 4.3530 - val_accuracy: 0.6951\n",
      "Epoch 407/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4718 - accuracy: 0.8152 - val_loss: 4.6693 - val_accuracy: 0.6331\n",
      "Epoch 408/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5173 - accuracy: 0.8057 - val_loss: 4.4274 - val_accuracy: 0.7106\n",
      "Epoch 409/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4307 - accuracy: 0.8290 - val_loss: 4.4452 - val_accuracy: 0.7054\n",
      "Epoch 410/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.8368 - val_loss: 4.3372 - val_accuracy: 0.6977\n",
      "Epoch 411/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4471 - accuracy: 0.8117 - val_loss: 4.4855 - val_accuracy: 0.7390\n",
      "Epoch 412/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.8247 - val_loss: 5.0665 - val_accuracy: 0.6202\n",
      "Epoch 413/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5393 - accuracy: 0.7772 - val_loss: 4.3764 - val_accuracy: 0.7339\n",
      "Epoch 414/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4564 - accuracy: 0.8264 - val_loss: 5.1496 - val_accuracy: 0.5168\n",
      "Epoch 415/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6165 - accuracy: 0.7513 - val_loss: 4.6712 - val_accuracy: 0.6796\n",
      "Epoch 416/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4949 - accuracy: 0.8022 - val_loss: 5.0565 - val_accuracy: 0.4910\n",
      "Epoch 417/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.7841 - accuracy: 0.6891 - val_loss: 4.5676 - val_accuracy: 0.7183\n",
      "Epoch 418/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 1.0769 - accuracy: 0.6278 - val_loss: 5.1840 - val_accuracy: 0.5788\n",
      "Epoch 419/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6265 - accuracy: 0.7530 - val_loss: 4.9240 - val_accuracy: 0.6822\n",
      "Epoch 420/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4914 - accuracy: 0.8126 - val_loss: 4.9764 - val_accuracy: 0.6770\n",
      "Epoch 421/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.8221 - val_loss: 4.6757 - val_accuracy: 0.7364\n",
      "Epoch 422/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6752 - accuracy: 0.7444 - val_loss: 4.8813 - val_accuracy: 0.6305\n",
      "Epoch 423/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5422 - accuracy: 0.7841 - val_loss: 4.8294 - val_accuracy: 0.5943\n",
      "Epoch 424/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5367 - accuracy: 0.7703 - val_loss: 4.6709 - val_accuracy: 0.7261\n",
      "Epoch 425/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.8161 - val_loss: 4.7241 - val_accuracy: 0.7416\n",
      "Epoch 426/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4360 - accuracy: 0.8316 - val_loss: 4.8319 - val_accuracy: 0.6951\n",
      "Epoch 427/500\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4380 - accuracy: 0.8316 - val_loss: 4.7029 - val_accuracy: 0.7313\n",
      "Epoch 428/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4736 - accuracy: 0.8169 - val_loss: 5.3452 - val_accuracy: 0.4703\n",
      "Epoch 429/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4773 - accuracy: 0.8152 - val_loss: 4.7574 - val_accuracy: 0.6563\n",
      "Epoch 430/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4363 - accuracy: 0.8316 - val_loss: 4.5880 - val_accuracy: 0.7287\n",
      "Epoch 431/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5743 - accuracy: 0.7815 - val_loss: 4.7755 - val_accuracy: 0.6512\n",
      "Epoch 432/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4732 - accuracy: 0.8074 - val_loss: 4.7469 - val_accuracy: 0.7209\n",
      "Epoch 433/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4307 - accuracy: 0.8351 - val_loss: 4.8703 - val_accuracy: 0.6977\n",
      "Epoch 434/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4903 - accuracy: 0.7979 - val_loss: 4.8920 - val_accuracy: 0.6770\n",
      "Epoch 435/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4496 - accuracy: 0.8230 - val_loss: 4.6734 - val_accuracy: 0.7390\n",
      "Epoch 436/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4165 - accuracy: 0.8377 - val_loss: 4.6885 - val_accuracy: 0.7054\n",
      "Epoch 437/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4036 - accuracy: 0.8411 - val_loss: 4.7107 - val_accuracy: 0.7028\n",
      "Epoch 438/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4557 - accuracy: 0.8074 - val_loss: 4.6261 - val_accuracy: 0.7339\n",
      "Epoch 439/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4390 - accuracy: 0.8307 - val_loss: 4.7517 - val_accuracy: 0.7287\n",
      "Epoch 440/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4294 - accuracy: 0.8351 - val_loss: 5.0864 - val_accuracy: 0.5581\n",
      "Epoch 441/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4750 - accuracy: 0.8074 - val_loss: 4.7954 - val_accuracy: 0.7080\n",
      "Epoch 442/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4361 - accuracy: 0.8307 - val_loss: 4.8540 - val_accuracy: 0.7442\n",
      "Epoch 443/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5180 - accuracy: 0.8031 - val_loss: 4.6126 - val_accuracy: 0.7209\n",
      "Epoch 444/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4564 - accuracy: 0.8074 - val_loss: 4.7024 - val_accuracy: 0.6873\n",
      "Epoch 445/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.8428 - val_loss: 4.6663 - val_accuracy: 0.7261\n",
      "Epoch 446/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.8247 - val_loss: 4.7628 - val_accuracy: 0.6848\n",
      "Epoch 447/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5218 - accuracy: 0.7781 - val_loss: 4.8309 - val_accuracy: 0.6744\n",
      "Epoch 448/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4627 - accuracy: 0.8152 - val_loss: 5.1899 - val_accuracy: 0.5711\n",
      "Epoch 449/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5778 - accuracy: 0.7798 - val_loss: 4.9616 - val_accuracy: 0.6925\n",
      "Epoch 450/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4330 - accuracy: 0.8238 - val_loss: 5.4423 - val_accuracy: 0.5504\n",
      "Epoch 451/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.8057 - val_loss: 5.0089 - val_accuracy: 0.6951\n",
      "Epoch 452/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5125 - accuracy: 0.7841 - val_loss: 5.6882 - val_accuracy: 0.4625\n",
      "Epoch 453/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6683 - accuracy: 0.7340 - val_loss: 4.8823 - val_accuracy: 0.7080\n",
      "Epoch 454/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4208 - accuracy: 0.8333 - val_loss: 4.9747 - val_accuracy: 0.6925\n",
      "Epoch 455/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8411 - val_loss: 4.9440 - val_accuracy: 0.7080\n",
      "Epoch 456/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4352 - accuracy: 0.8264 - val_loss: 5.0185 - val_accuracy: 0.7261\n",
      "Epoch 457/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4216 - accuracy: 0.8325 - val_loss: 5.2509 - val_accuracy: 0.5685\n",
      "Epoch 458/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6289 - accuracy: 0.7539 - val_loss: 5.1318 - val_accuracy: 0.6873\n",
      "Epoch 459/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.5972 - accuracy: 0.7478 - val_loss: 4.9895 - val_accuracy: 0.7028\n",
      "Epoch 460/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4691 - accuracy: 0.8282 - val_loss: 5.4791 - val_accuracy: 0.5426\n",
      "Epoch 461/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4863 - accuracy: 0.7988 - val_loss: 5.0939 - val_accuracy: 0.6486\n",
      "Epoch 462/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4565 - accuracy: 0.8092 - val_loss: 5.5186 - val_accuracy: 0.6408\n",
      "Epoch 463/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.8238 - val_loss: 5.0573 - val_accuracy: 0.6977\n",
      "Epoch 464/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.8342 - val_loss: 5.0980 - val_accuracy: 0.7158\n",
      "Epoch 465/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4629 - accuracy: 0.8187 - val_loss: 5.4073 - val_accuracy: 0.6176\n",
      "Epoch 466/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.6056 - accuracy: 0.7539 - val_loss: 5.2249 - val_accuracy: 0.6899\n",
      "Epoch 467/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.7988 - val_loss: 5.2341 - val_accuracy: 0.6693\n",
      "Epoch 468/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5916 - accuracy: 0.7539 - val_loss: 5.7361 - val_accuracy: 0.6899\n",
      "Epoch 469/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5401 - accuracy: 0.8126 - val_loss: 5.7814 - val_accuracy: 0.7028\n",
      "Epoch 470/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.8152 - val_loss: 6.3585 - val_accuracy: 0.7235\n",
      "Epoch 471/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5570 - accuracy: 0.7902 - val_loss: 6.1472 - val_accuracy: 0.5245\n",
      "Epoch 472/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4962 - accuracy: 0.7936 - val_loss: 5.0602 - val_accuracy: 0.6486\n",
      "Epoch 473/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5106 - accuracy: 0.7867 - val_loss: 5.0446 - val_accuracy: 0.6977\n",
      "Epoch 474/500\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.4240 - accuracy: 0.8333 - val_loss: 5.0295 - val_accuracy: 0.7364\n",
      "Epoch 475/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3908 - accuracy: 0.8472 - val_loss: 5.0392 - val_accuracy: 0.7209\n",
      "Epoch 476/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.8187 - val_loss: 5.2851 - val_accuracy: 0.6589\n",
      "Epoch 477/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4961 - accuracy: 0.7988 - val_loss: 5.2344 - val_accuracy: 0.6822\n",
      "Epoch 478/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4916 - accuracy: 0.7936 - val_loss: 5.1047 - val_accuracy: 0.6873\n",
      "Epoch 479/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.8307 - val_loss: 5.5460 - val_accuracy: 0.6227\n",
      "Epoch 480/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6290 - accuracy: 0.7539 - val_loss: 5.3280 - val_accuracy: 0.6150\n",
      "Epoch 481/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5224 - accuracy: 0.7876 - val_loss: 5.1692 - val_accuracy: 0.7183\n",
      "Epoch 482/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.8204 - val_loss: 5.1252 - val_accuracy: 0.7106\n",
      "Epoch 483/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5319 - accuracy: 0.7919 - val_loss: 5.1268 - val_accuracy: 0.6744\n",
      "Epoch 484/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.8230 - val_loss: 5.3046 - val_accuracy: 0.7235\n",
      "Epoch 485/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.8394 - val_loss: 5.5034 - val_accuracy: 0.6072\n",
      "Epoch 486/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.8100 - val_loss: 5.2793 - val_accuracy: 0.7183\n",
      "Epoch 487/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8394 - val_loss: 5.2798 - val_accuracy: 0.6873\n",
      "Epoch 488/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3950 - accuracy: 0.8480 - val_loss: 5.1822 - val_accuracy: 0.7183\n",
      "Epoch 489/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3854 - accuracy: 0.8437 - val_loss: 5.2218 - val_accuracy: 0.6925\n",
      "Epoch 490/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.8048 - val_loss: 5.2480 - val_accuracy: 0.6899\n",
      "Epoch 491/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.8420 - val_loss: 5.2281 - val_accuracy: 0.7209\n",
      "Epoch 492/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.3745 - accuracy: 0.8610 - val_loss: 5.2146 - val_accuracy: 0.7183\n",
      "Epoch 493/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4891 - accuracy: 0.8100 - val_loss: 6.3221 - val_accuracy: 0.4703\n",
      "Epoch 494/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5316 - accuracy: 0.7919 - val_loss: 5.3951 - val_accuracy: 0.6848\n",
      "Epoch 495/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4058 - accuracy: 0.8351 - val_loss: 5.4789 - val_accuracy: 0.7287\n",
      "Epoch 496/500\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.8247 - val_loss: 5.9188 - val_accuracy: 0.6408\n",
      "Epoch 497/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.8290 - val_loss: 5.9565 - val_accuracy: 0.5065\n",
      "Epoch 498/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.8171 - accuracy: 0.7021 - val_loss: 5.7114 - val_accuracy: 0.6253\n",
      "Epoch 499/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5029 - accuracy: 0.7971 - val_loss: 5.7192 - val_accuracy: 0.6822\n",
      "Epoch 500/500\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.8221 - val_loss: 5.8758 - val_accuracy: 0.6744\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x19f5e0ece50>"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=500, batch_size=48, validation_data=(X_test, y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step\n",
      "Prediction 1: Class 18\n",
      "Prediction 2: Class 5\n",
      "Prediction 3: Class 6\n",
      "Prediction 4: Class 5\n",
      "Prediction 5: Class 5\n",
      "Prediction 6: Class 29\n",
      "Prediction 7: Class 7\n",
      "Prediction 8: Class 8\n",
      "Prediction 9: Class 18\n",
      "Prediction 10: Class 6\n",
      "Prediction 11: Class 33\n",
      "Prediction 12: Class 6\n",
      "Prediction 13: Class 5\n",
      "Prediction 14: Class 29\n",
      "Prediction 15: Class 18\n",
      "Prediction 16: Class 21\n",
      "Prediction 17: Class 5\n",
      "Prediction 18: Class 5\n",
      "Prediction 19: Class 29\n",
      "Prediction 20: Class 32\n",
      "Prediction 21: Class 5\n",
      "Prediction 22: Class 5\n",
      "Prediction 23: Class 7\n",
      "Prediction 24: Class 7\n",
      "Prediction 25: Class 18\n",
      "Prediction 26: Class 21\n",
      "Prediction 27: Class 5\n",
      "Prediction 28: Class 29\n",
      "Prediction 29: Class 5\n",
      "Prediction 30: Class 5\n",
      "Prediction 31: Class 18\n",
      "Prediction 32: Class 5\n",
      "Prediction 33: Class 18\n",
      "Prediction 34: Class 6\n",
      "Prediction 35: Class 21\n",
      "Prediction 36: Class 18\n",
      "Prediction 37: Class 6\n",
      "Prediction 38: Class 18\n",
      "Prediction 39: Class 18\n",
      "Prediction 40: Class 7\n",
      "Prediction 41: Class 6\n",
      "Prediction 42: Class 5\n",
      "Prediction 43: Class 21\n",
      "Prediction 44: Class 5\n",
      "Prediction 45: Class 6\n",
      "Prediction 46: Class 29\n",
      "Prediction 47: Class 18\n",
      "Prediction 48: Class 29\n",
      "Prediction 49: Class 5\n",
      "Prediction 50: Class 33\n",
      "Prediction 51: Class 18\n",
      "Prediction 52: Class 29\n",
      "Prediction 53: Class 29\n",
      "Prediction 54: Class 29\n",
      "Prediction 55: Class 6\n",
      "Prediction 56: Class 6\n",
      "Prediction 57: Class 29\n",
      "Prediction 58: Class 6\n",
      "Prediction 59: Class 18\n",
      "Prediction 60: Class 6\n",
      "Prediction 61: Class 5\n",
      "Prediction 62: Class 21\n",
      "Prediction 63: Class 33\n",
      "Prediction 64: Class 6\n",
      "Prediction 65: Class 18\n",
      "Prediction 66: Class 18\n",
      "Prediction 67: Class 6\n",
      "Prediction 68: Class 6\n",
      "Prediction 69: Class 7\n",
      "Prediction 70: Class 7\n",
      "Prediction 71: Class 21\n",
      "Prediction 72: Class 18\n",
      "Prediction 73: Class 18\n",
      "Prediction 74: Class 29\n",
      "Prediction 75: Class 18\n",
      "Prediction 76: Class 21\n",
      "Prediction 77: Class 18\n",
      "Prediction 78: Class 29\n",
      "Prediction 79: Class 5\n",
      "Prediction 80: Class 7\n",
      "Prediction 81: Class 6\n",
      "Prediction 82: Class 6\n",
      "Prediction 83: Class 6\n",
      "Prediction 84: Class 29\n",
      "Prediction 85: Class 29\n",
      "Prediction 86: Class 5\n",
      "Prediction 87: Class 5\n",
      "Prediction 88: Class 7\n",
      "Prediction 89: Class 18\n",
      "Prediction 90: Class 6\n",
      "Prediction 91: Class 5\n",
      "Prediction 92: Class 6\n",
      "Prediction 93: Class 6\n",
      "Prediction 94: Class 6\n",
      "Prediction 95: Class 7\n",
      "Prediction 96: Class 29\n",
      "Prediction 97: Class 29\n",
      "Prediction 98: Class 5\n",
      "Prediction 99: Class 18\n",
      "Prediction 100: Class 5\n",
      "Prediction 101: Class 6\n",
      "Prediction 102: Class 5\n",
      "Prediction 103: Class 18\n",
      "Prediction 104: Class 6\n",
      "Prediction 105: Class 18\n",
      "Prediction 106: Class 18\n",
      "Prediction 107: Class 8\n",
      "Prediction 108: Class 6\n",
      "Prediction 109: Class 29\n",
      "Prediction 110: Class 33\n",
      "Prediction 111: Class 7\n",
      "Prediction 112: Class 29\n",
      "Prediction 113: Class 6\n",
      "Prediction 114: Class 18\n",
      "Prediction 115: Class 5\n",
      "Prediction 116: Class 29\n",
      "Prediction 117: Class 5\n",
      "Prediction 118: Class 6\n",
      "Prediction 119: Class 7\n",
      "Prediction 120: Class 6\n",
      "Prediction 121: Class 33\n",
      "Prediction 122: Class 21\n",
      "Prediction 123: Class 18\n",
      "Prediction 124: Class 7\n",
      "Prediction 125: Class 5\n",
      "Prediction 126: Class 5\n",
      "Prediction 127: Class 7\n",
      "Prediction 128: Class 6\n",
      "Prediction 129: Class 21\n",
      "Prediction 130: Class 18\n",
      "Prediction 131: Class 18\n",
      "Prediction 132: Class 5\n",
      "Prediction 133: Class 5\n",
      "Prediction 134: Class 5\n",
      "Prediction 135: Class 18\n",
      "Prediction 136: Class 6\n",
      "Prediction 137: Class 5\n",
      "Prediction 138: Class 5\n",
      "Prediction 139: Class 8\n",
      "Prediction 140: Class 33\n",
      "Prediction 141: Class 33\n",
      "Prediction 142: Class 6\n",
      "Prediction 143: Class 18\n",
      "Prediction 144: Class 18\n",
      "Prediction 145: Class 29\n",
      "Prediction 146: Class 29\n",
      "Prediction 147: Class 21\n",
      "Prediction 148: Class 21\n",
      "Prediction 149: Class 8\n",
      "Prediction 150: Class 6\n",
      "Prediction 151: Class 18\n",
      "Prediction 152: Class 33\n",
      "Prediction 153: Class 18\n",
      "Prediction 154: Class 18\n",
      "Prediction 155: Class 18\n",
      "Prediction 156: Class 8\n",
      "Prediction 157: Class 7\n",
      "Prediction 158: Class 5\n",
      "Prediction 159: Class 29\n",
      "Prediction 160: Class 18\n",
      "Prediction 161: Class 29\n",
      "Prediction 162: Class 5\n",
      "Prediction 163: Class 5\n",
      "Prediction 164: Class 29\n",
      "Prediction 165: Class 18\n",
      "Prediction 166: Class 6\n",
      "Prediction 167: Class 18\n",
      "Prediction 168: Class 6\n",
      "Prediction 169: Class 18\n",
      "Prediction 170: Class 5\n",
      "Prediction 171: Class 6\n",
      "Prediction 172: Class 18\n",
      "Prediction 173: Class 29\n",
      "Prediction 174: Class 5\n",
      "Prediction 175: Class 6\n",
      "Prediction 176: Class 18\n",
      "Prediction 177: Class 5\n",
      "Prediction 178: Class 5\n",
      "Prediction 179: Class 6\n",
      "Prediction 180: Class 5\n",
      "Prediction 181: Class 8\n",
      "Prediction 182: Class 18\n",
      "Prediction 183: Class 21\n",
      "Prediction 184: Class 18\n",
      "Prediction 185: Class 21\n",
      "Prediction 186: Class 29\n",
      "Prediction 187: Class 18\n",
      "Prediction 188: Class 21\n",
      "Prediction 189: Class 33\n",
      "Prediction 190: Class 29\n",
      "Prediction 191: Class 5\n",
      "Prediction 192: Class 29\n",
      "Prediction 193: Class 14\n",
      "Prediction 194: Class 29\n",
      "Prediction 195: Class 7\n",
      "Prediction 196: Class 29\n",
      "Prediction 197: Class 5\n",
      "Prediction 198: Class 5\n",
      "Prediction 199: Class 18\n",
      "Prediction 200: Class 7\n",
      "Prediction 201: Class 18\n",
      "Prediction 202: Class 5\n",
      "Prediction 203: Class 6\n",
      "Prediction 204: Class 29\n",
      "Prediction 205: Class 8\n",
      "Prediction 206: Class 33\n",
      "Prediction 207: Class 5\n",
      "Prediction 208: Class 8\n",
      "Prediction 209: Class 5\n",
      "Prediction 210: Class 6\n",
      "Prediction 211: Class 29\n",
      "Prediction 212: Class 5\n",
      "Prediction 213: Class 5\n",
      "Prediction 214: Class 21\n",
      "Prediction 215: Class 33\n",
      "Prediction 216: Class 5\n",
      "Prediction 217: Class 29\n",
      "Prediction 218: Class 18\n",
      "Prediction 219: Class 21\n",
      "Prediction 220: Class 6\n",
      "Prediction 221: Class 18\n",
      "Prediction 222: Class 25\n",
      "Prediction 223: Class 18\n",
      "Prediction 224: Class 33\n",
      "Prediction 225: Class 33\n",
      "Prediction 226: Class 18\n",
      "Prediction 227: Class 7\n",
      "Prediction 228: Class 6\n",
      "Prediction 229: Class 18\n",
      "Prediction 230: Class 18\n",
      "Prediction 231: Class 29\n",
      "Prediction 232: Class 33\n",
      "Prediction 233: Class 7\n",
      "Prediction 234: Class 29\n",
      "Prediction 235: Class 7\n",
      "Prediction 236: Class 6\n",
      "Prediction 237: Class 29\n",
      "Prediction 238: Class 5\n",
      "Prediction 239: Class 5\n",
      "Prediction 240: Class 18\n",
      "Prediction 241: Class 18\n",
      "Prediction 242: Class 5\n",
      "Prediction 243: Class 5\n",
      "Prediction 244: Class 6\n",
      "Prediction 245: Class 7\n",
      "Prediction 246: Class 5\n",
      "Prediction 247: Class 5\n",
      "Prediction 248: Class 29\n",
      "Prediction 249: Class 18\n",
      "Prediction 250: Class 18\n",
      "Prediction 251: Class 6\n",
      "Prediction 252: Class 5\n",
      "Prediction 253: Class 5\n",
      "Prediction 254: Class 5\n",
      "Prediction 255: Class 33\n",
      "Prediction 256: Class 18\n",
      "Prediction 257: Class 5\n",
      "Prediction 258: Class 6\n",
      "Prediction 259: Class 7\n",
      "Prediction 260: Class 5\n",
      "Prediction 261: Class 5\n",
      "Prediction 262: Class 29\n",
      "Prediction 263: Class 5\n",
      "Prediction 264: Class 7\n",
      "Prediction 265: Class 21\n",
      "Prediction 266: Class 18\n",
      "Prediction 267: Class 18\n",
      "Prediction 268: Class 5\n",
      "Prediction 269: Class 33\n",
      "Prediction 270: Class 18\n",
      "Prediction 271: Class 6\n",
      "Prediction 272: Class 29\n",
      "Prediction 273: Class 6\n",
      "Prediction 274: Class 21\n",
      "Prediction 275: Class 5\n",
      "Prediction 276: Class 18\n",
      "Prediction 277: Class 33\n",
      "Prediction 278: Class 5\n",
      "Prediction 279: Class 29\n",
      "Prediction 280: Class 7\n",
      "Prediction 281: Class 6\n",
      "Prediction 282: Class 18\n",
      "Prediction 283: Class 29\n",
      "Prediction 284: Class 7\n",
      "Prediction 285: Class 6\n",
      "Prediction 286: Class 7\n",
      "Prediction 287: Class 7\n",
      "Prediction 288: Class 18\n",
      "Prediction 289: Class 21\n",
      "Prediction 290: Class 6\n",
      "Prediction 291: Class 33\n",
      "Prediction 292: Class 5\n",
      "Prediction 293: Class 5\n",
      "Prediction 294: Class 18\n",
      "Prediction 295: Class 29\n",
      "Prediction 296: Class 33\n",
      "Prediction 297: Class 29\n",
      "Prediction 298: Class 5\n",
      "Prediction 299: Class 5\n",
      "Prediction 300: Class 5\n",
      "Prediction 301: Class 6\n",
      "Prediction 302: Class 18\n",
      "Prediction 303: Class 21\n",
      "Prediction 304: Class 18\n",
      "Prediction 305: Class 5\n",
      "Prediction 306: Class 29\n",
      "Prediction 307: Class 7\n",
      "Prediction 308: Class 5\n",
      "Prediction 309: Class 6\n",
      "Prediction 310: Class 21\n",
      "Prediction 311: Class 18\n",
      "Prediction 312: Class 8\n",
      "Prediction 313: Class 33\n",
      "Prediction 314: Class 5\n",
      "Prediction 315: Class 18\n",
      "Prediction 316: Class 18\n",
      "Prediction 317: Class 5\n",
      "Prediction 318: Class 7\n",
      "Prediction 319: Class 7\n",
      "Prediction 320: Class 18\n",
      "Prediction 321: Class 18\n",
      "Prediction 322: Class 18\n",
      "Prediction 323: Class 5\n",
      "Prediction 324: Class 5\n",
      "Prediction 325: Class 5\n",
      "Prediction 326: Class 5\n",
      "Prediction 327: Class 5\n",
      "Prediction 328: Class 18\n",
      "Prediction 329: Class 5\n",
      "Prediction 330: Class 5\n",
      "Prediction 331: Class 5\n",
      "Prediction 332: Class 18\n",
      "Prediction 333: Class 18\n",
      "Prediction 334: Class 5\n",
      "Prediction 335: Class 29\n",
      "Prediction 336: Class 33\n",
      "Prediction 337: Class 21\n",
      "Prediction 338: Class 18\n",
      "Prediction 339: Class 18\n",
      "Prediction 340: Class 29\n",
      "Prediction 341: Class 21\n",
      "Prediction 342: Class 5\n",
      "Prediction 343: Class 18\n",
      "Prediction 344: Class 7\n",
      "Prediction 345: Class 18\n",
      "Prediction 346: Class 33\n",
      "Prediction 347: Class 29\n",
      "Prediction 348: Class 6\n",
      "Prediction 349: Class 18\n",
      "Prediction 350: Class 5\n",
      "Prediction 351: Class 32\n",
      "Prediction 352: Class 21\n",
      "Prediction 353: Class 21\n",
      "Prediction 354: Class 6\n",
      "Prediction 355: Class 18\n",
      "Prediction 356: Class 6\n",
      "Prediction 357: Class 5\n",
      "Prediction 358: Class 7\n",
      "Prediction 359: Class 5\n",
      "Prediction 360: Class 8\n",
      "Prediction 361: Class 18\n",
      "Prediction 362: Class 18\n",
      "Prediction 363: Class 6\n",
      "Prediction 364: Class 33\n",
      "Prediction 365: Class 33\n",
      "Prediction 366: Class 7\n",
      "Prediction 367: Class 29\n",
      "Prediction 368: Class 6\n",
      "Prediction 369: Class 33\n",
      "Prediction 370: Class 7\n",
      "Prediction 371: Class 6\n",
      "Prediction 372: Class 32\n",
      "Prediction 373: Class 5\n",
      "Prediction 374: Class 18\n",
      "Prediction 375: Class 6\n",
      "Prediction 376: Class 21\n",
      "Prediction 377: Class 21\n",
      "Prediction 378: Class 18\n",
      "Prediction 379: Class 6\n",
      "Prediction 380: Class 6\n",
      "Prediction 381: Class 33\n",
      "Prediction 382: Class 21\n",
      "Prediction 383: Class 18\n",
      "Prediction 384: Class 25\n",
      "Prediction 385: Class 18\n",
      "Prediction 386: Class 8\n",
      "Prediction 387: Class 7\n"
     ]
    }
   ],
   "source": [
    "# Reshape X_test to match the model's input shape\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], 10, 1)\n",
    "\n",
    "# Now, you can use model.predict() on the reshaped X_test data\n",
    "predictions = model.predict(X_test_reshaped)\n",
    "\n",
    "# Find the class with the highest probability for each prediction\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Print the predicted class as an integer\n",
    "for i, predicted_class in enumerate(predicted_classes):\n",
    "    print(f\"Prediction {i + 1}: Class {predicted_class}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
